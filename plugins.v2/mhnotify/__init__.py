import time
import re

from typing import List, Tuple, Dict, Any, Optional
from apscheduler.triggers.cron import CronTrigger

from app.core.config import settings
from app.core.event import eventmanager, Event
from app.schemas.types import EventType
from app.utils.http import RequestUtils
from app.log import logger
from app.plugins import _PluginBase
from app.db import SessionFactory
from app.db.subscribe_oper import SubscribeOper


class MHNotify(_PluginBase):
    # æ’ä»¶åç§°
    plugin_name = "MediaHelperå¢å¼º"
    # æ’ä»¶æè¿°
    plugin_desc = "ç›‘å¬115ç”Ÿæ´»äº‹ä»¶å’ŒMPæ•´ç†/åˆ®å‰Šäº‹ä»¶åï¼Œé€šçŸ¥MediaHelperæ‰§è¡Œstrmç”Ÿæˆä»»åŠ¡ï¼›æä¾›mhè®¢é˜…è¾…åŠ©ï¼›æ”¯æŒ115äº‘ä¸‹è½½ï¼ˆ/mholå‘½ä»¤ï¼‰ã€è‡ªåŠ¨åˆ é™¤å°æ–‡ä»¶åŠç§»åŠ¨æ•´ç†"
    # æ’ä»¶å›¾æ ‡
    plugin_icon = "https://raw.githubusercontent.com/ListeningLTG/MoviePilot-Plugins/refs/heads/main/icons/mh2.jpg"
    # æ’ä»¶ç‰ˆæœ¬
    plugin_version = "1.5.3"
    # æ’ä»¶ä½œè€…
    plugin_author = "ListeningLTG"
    # ä½œè€…ä¸»é¡µ
    author_url = "https://github.com/ListeningLTG"
    # æ’ä»¶é…ç½®é¡¹IDå‰ç¼€
    plugin_config_prefix = "mhnotify_"
    # åŠ è½½é¡ºåº
    plugin_order = 1
    # å¯ä½¿ç”¨çš„ç”¨æˆ·çº§åˆ«
    auth_level = 1

    # ç§æœ‰å±æ€§
    _mh_domain = None
    _mh_username = None
    _mh_password = None
    _mh_job_names = None
    _enabled = False
    _last_event_time = 0
    # ä¸‹ä¸€æ¬¡å…è®¸é€šçŸ¥çš„æ—¶é—´æˆ³ï¼ˆç”¨äºç­‰å¾…çª—å£ï¼‰
    _next_notify_time = 0
    # ç­‰å¾…é€šçŸ¥æ•°é‡
    _wait_notify_count = 0
    #ï¼ˆå·²åºŸå¼ƒï¼‰
    _wait_minutes = 5
    # mhè®¢é˜…è¾…åŠ©å¼€å…³
    _mh_assist_enabled: bool = False
    # mhè®¢é˜…è¾…åŠ©ï¼šMPè®¢é˜…å®Œæˆåè‡ªåŠ¨åˆ é™¤MHè®¢é˜…
    _mh_assist_auto_delete: bool = False
    # åŠ©æ‰‹ï¼šå¾…æ£€æŸ¥çš„mhè®¢é˜…æ˜ å°„ï¼ˆmp_sub_id -> {mh_uuid, created_at, type}ï¼‰
    _ASSIST_PENDING_KEY = "mhnotify_assist_pending"
    # åŠ©æ‰‹ï¼šç­‰å¾…MPå®Œæˆååˆ é™¤mhè®¢é˜…çš„ç›‘å¬æ˜ å°„ï¼ˆmp_sub_id -> {mh_uuid}ï¼‰
    _ASSIST_WATCH_KEY = "mhnotify_assist_watch"
    # HDHive é…ç½®
    _hdhive_enabled: bool = False
    _hdhive_query_mode: str = "playwright"  # playwright/api
    _hdhive_username: str = ""
    _hdhive_password: str = ""
    _hdhive_cookie: str = ""
    _hdhive_auto_refresh: bool = False
    _hdhive_refresh_before: int = 3600
    # MHç™»å½•ç¼“å­˜
    _mh_token: Optional[str] = None
    _mh_token_expire_ts: int = 0
    _mh_token_ttl_seconds: int = 600  # é»˜è®¤ç¼“å­˜10åˆ†é’Ÿ
    # åŠ©æ‰‹è°ƒåº¦å»¶è¿Ÿ/é‡è¯•å¸¸é‡ï¼ˆé¦–æ¬¡æŸ¥è¯¢2åˆ†é’Ÿï¼Œä¹‹åæ¯1åˆ†é’Ÿé‡è¯•ï¼‰
    _assist_initial_delay_seconds: int = 120
    _assist_retry_interval_seconds: int = 60
    # 115 ç”Ÿæ´»äº‹ä»¶ç›‘å¬
    _p115_life_enabled: bool = False
    _p115_cookie: str = ""
    _p115_events: List[str] = []  # å¯é€‰ï¼šupload/move/receive/create/copy/delete
    _p115_poll_cron: str = "* * * * *"  # æ¯åˆ†é’Ÿ
    _P115_LAST_TS_KEY = "mhnotify_p115_life_last_ts"
    _P115_LAST_ID_KEY = "mhnotify_p115_life_last_id"
    _p115_watch_dirs: List[str] = []  # ä»…å½“æ–‡ä»¶è·¯å¾„å‘½ä¸­è¿™äº›ç›®å½•å‰ç¼€æ—¶è§¦å‘
    _p115_watch_rules: List[Dict[str, Any]] = []  # [{path: '/ç›®å½•', events: ['upload', ...]}]
    _p115_wait_minutes: int = 5  # ç”Ÿæ´»äº‹ä»¶é™é»˜çª—å£ï¼ˆåˆ†é’Ÿï¼‰
    _p115_next_notify_time: int = 0  # ç”Ÿæ´»äº‹ä»¶ä¸‹ä¸€æ¬¡å…è®¸è§¦å‘çš„æ—¶é—´æˆ³
    _p115_dir_cache: Dict[int, str] = {}  # parent_id -> dir path ç¼“å­˜
    _rule_count: int = 3  # è§„åˆ™è¡Œæ•°ï¼ˆè¡¨å•åŠ¨æ€æ˜¾ç¤ºï¼‰
    #ï¼ˆå·²åºŸå¼ƒï¼‰æ˜¯å¦æ£€æµ‹ MP æ•´ç†è¿è¡Œ
    _check_mp_transfer_enabled: bool = False
    # MP æ•´ç†/åˆ®å‰Šäº‹ä»¶è§¦å‘å¼€å…³
    _mp_event_enabled: bool = False
    # MP äº‹ä»¶ç­‰å¾…æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
    _mp_event_wait_minutes: int = 5
    # MP äº‹ä»¶ç›‘å¬çš„å­˜å‚¨ç±»å‹ï¼ˆå¤šé€‰ï¼‰
    _mp_event_storages: List[str] = []
    # å¯ç”¨å­˜å‚¨åˆ—è¡¨ç¼“å­˜
    _available_storages: List[Dict[str, str]] = []
    # äº‘ä¸‹è½½å¼€å…³
    _cloud_download_enabled: bool = False
    # äº‘ä¸‹è½½ä¿å­˜è·¯å¾„
    _cloud_download_path: str = "/äº‘ä¸‹è½½"
    # äº‘ä¸‹è½½å‰”é™¤å°æ–‡ä»¶å¼€å…³
    _cloud_download_remove_small_files: bool = False
    # äº‘ä¸‹è½½ç§»åŠ¨æ•´ç†å¼€å…³
    _cloud_download_organize: bool = False

    def init_plugin(self, config: dict = None):
        if config:
            self._enabled = config.get("enabled")
            self._mh_domain = config.get("mh_domain")
            self._mh_username = config.get('mh_username')
            self._mh_password = config.get('mh_password')
            self._mh_job_names = config.get('mh_job_names') or ""
            # ç§»é™¤ MP æ•´ç†å»¶è¿Ÿçª—å£é…ç½®ï¼ˆä¿ç•™å ä½ä¸ç”Ÿæ•ˆï¼‰
            try:
                _ = int(config.get('wait_minutes') or 5)
            except Exception:
                pass
            # mhè®¢é˜…è¾…åŠ©å¼€å…³
            self._mh_assist_enabled = bool(config.get("mh_assist", False))
            # mhè®¢é˜…è¾…åŠ©ï¼šMPè®¢é˜…å®Œæˆåè‡ªåŠ¨åˆ é™¤MHè®¢é˜…ï¼ˆé»˜è®¤å…³é—­ï¼‰
            self._mh_assist_auto_delete = bool(config.get("mh_assist_auto_delete", False))

            # HDHive è®¾ç½®
            self._hdhive_enabled = bool(config.get("hdhive_enabled", False))
            self._hdhive_query_mode = config.get("hdhive_query_mode", "api") or "api"
            self._hdhive_username = config.get("hdhive_username", "") or ""
            self._hdhive_password = config.get("hdhive_password", "") or ""
            self._hdhive_cookie = config.get("hdhive_cookie", "") or ""
            self._hdhive_auto_refresh = bool(config.get("hdhive_auto_refresh", False))
            try:
                self._hdhive_refresh_before = int(config.get("hdhive_refresh_before", 3600) or 3600)
            except Exception:
                self._hdhive_refresh_before = 3600

            # æ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•ï¼ˆè¿è¡Œä¸€æ¬¡ï¼‰
            try:
                if bool(config.get("clear_once", False)):
                    logger.info("mhnotify: æ£€æµ‹åˆ°æ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•ï¼ˆè¿è¡Œä¸€æ¬¡ï¼‰å¼€å…³å·²å¼€å¯ï¼Œå¼€å§‹æ¸…ç†...")
                    self._clear_all_records()
                    # å¤ä½ä¸ºå…³é—­ï¼Œå¹¶æ›´æ–°é…ç½®
                    config["clear_once"] = False
                    self.update_config(config)
                    logger.info("mhnotify: åŠ©æ‰‹è®¢é˜…è®°å½•æ¸…ç†å®Œæˆï¼Œå·²è‡ªåŠ¨å¤ä½ä¸ºå…³é—­")
            except Exception:
                logger.error("mhnotify: æ‰§è¡Œæ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•å¤±è´¥", exc_info=True)
            
            # æ¸…ç†åŠ©æ‰‹äº‘ä¸‹è½½è®°å½•ï¼ˆè¿è¡Œä¸€æ¬¡ï¼‰
            try:
                if bool(config.get("clear_cloud_download_once", False)):
                    logger.info("mhnotify: æ£€æµ‹åˆ°æ¸…ç†åŠ©æ‰‹äº‘ä¸‹è½½è®°å½•ï¼ˆè¿è¡Œä¸€æ¬¡ï¼‰å¼€å…³å·²å¼€å¯ï¼Œå¼€å§‹æ¸…ç†...")
                    self._clear_cloud_download_records()
                    # å¤ä½ä¸ºå…³é—­ï¼Œå¹¶æ›´æ–°é…ç½®
                    config["clear_cloud_download_once"] = False
                    self.update_config(config)
                    logger.info("mhnotify: åŠ©æ‰‹äº‘ä¸‹è½½è®°å½•æ¸…ç†å®Œæˆï¼Œå·²è‡ªåŠ¨å¤ä½ä¸ºå…³é—­")
            except Exception:
                logger.error("mhnotify: æ‰§è¡Œæ¸…ç†åŠ©æ‰‹äº‘ä¸‹è½½è®°å½•å¤±è´¥", exc_info=True)

            # 115 ç”Ÿæ´»äº‹ä»¶
            self._p115_life_enabled = bool(config.get("p115_life_enabled", False))
            self._p115_cookie = config.get("p115_cookie", "") or ""
            self._p115_events = config.get("p115_life_events", []) or []
            # å…¼å®¹å­—ç¬¦ä¸²é€—å·åˆ†éš”
            if isinstance(self._p115_events, str):
                self._p115_events = [x.strip() for x in self._p115_events.split(',') if x.strip()]
            # è½®è¯¢é¢‘ç‡ï¼ˆä¿ç•™ä¸º cronï¼Œæš‚ä»…æ”¯æŒæ¯åˆ†é’Ÿï¼‰
            self._p115_poll_cron = config.get("p115_life_cron", "* * * * *") or "* * * * *"
            # ç›®å½•å‰ç¼€è¿‡æ»¤ï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
            watch_dirs = config.get("p115_watch_dirs", []) or []
            if isinstance(watch_dirs, str):
                watch_dirs = [x.strip() for x in watch_dirs.split(',') if x.strip()]
            # è§„èŒƒåŒ–ä¸ºä»¥ '/' å¼€å¤´çš„ Posix è·¯å¾„
            norm_dirs: List[str] = []
            for d in watch_dirs:
                d = d.replace('\\', '/').strip()
                if not d:
                    continue
                if not d.startswith('/'):
                    d = '/' + d
                # å»é™¤å°¾éš '/'
                d = d.rstrip('/')
                norm_dirs.append(d)
            self._p115_watch_dirs = norm_dirs
            
            # ç›®å½•äº‹ä»¶è§„åˆ™ï¼šä¼˜å…ˆä» rule_path_X / rule_events_X å­—æ®µè§£æï¼ˆæ–°è¡¨å•æ ¼å¼ï¼‰
            norm_rules: List[Dict[str, Any]] = []
            max_rules = 10
            
            # ä»æ–°æ ¼å¼è§£æï¼šrule_path_0, rule_events_0, ...
            for i in range(max_rules):
                path_key = f'rule_path_{i}'
                events_key = f'rule_events_{i}'
                p = (config.get(path_key) or '').replace('\\', '/').strip()
                if not p:
                    continue
                if not p.startswith('/'):
                    p = '/' + p
                p = p.rstrip('/')
                evs = config.get(events_key) or []
                if isinstance(evs, str):
                    evs = [x.strip().lower() for x in evs.split(',') if x.strip()]
                elif isinstance(evs, list):
                    evs = [str(x).strip().lower() for x in evs if str(x).strip()]
                norm_rules.append({'path': p, 'events': evs})
            
            # è‹¥æ–°æ ¼å¼ä¸ºç©ºï¼Œå°è¯•ä»æ—§çš„ JSON åˆ—è¡¨è§£æï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
            if not norm_rules:
                rules = config.get("p115_watch_rules", []) or []
                if isinstance(rules, list):
                    for r in rules:
                        try:
                            p = (r.get('path') or '').replace('\\', '/').strip()
                            if not p:
                                continue
                            if not p.startswith('/'):
                                p = '/' + p
                            p = p.rstrip('/')
                            evs = r.get('events') or []
                            if isinstance(evs, str):
                                evs = [x.strip().lower() for x in evs.split(',') if x.strip()]
                            elif isinstance(evs, list):
                                evs = [str(x).strip().lower() for x in evs if str(x).strip()]
                            norm_rules.append({'path': p, 'events': evs})
                        except Exception:
                            continue
            
            self._p115_watch_rules = norm_rules
            # åŒæ­¥æ›´æ–° p115_watch_rules é…ç½®ï¼ˆä¾› API ä½¿ç”¨ï¼‰
            config['p115_watch_rules'] = norm_rules
            
            # è§„åˆ™è¡Œæ•°ï¼ˆç”¨äºè¡¨å•åŠ¨æ€æ˜¾ç¤ºï¼‰
            try:
                self._rule_count = int(config.get('rule_count', 3) or 3)
                if self._rule_count < 1:
                    self._rule_count = 1
                if self._rule_count > 10:
                    self._rule_count = 10
            except Exception:
                self._rule_count = 3
            
            try:
                self._p115_wait_minutes = int(config.get('p115_wait_minutes', 5) or 5)
            except Exception:
                self._p115_wait_minutes = 5
            # ç§»é™¤ MP æ•´ç†æ£€æµ‹å¼€å…³ï¼ˆä¸å†ç”Ÿæ•ˆï¼‰
            self._check_mp_transfer_enabled = False
            
            # MP æ•´ç†/åˆ®å‰Šäº‹ä»¶è§¦å‘å¼€å…³
            self._mp_event_enabled = bool(config.get("mp_event_enabled", False))
            try:
                self._mp_event_wait_minutes = int(config.get('mp_event_wait_minutes', 5) or 5)
            except Exception:
                self._mp_event_wait_minutes = 5
            
            # MP äº‹ä»¶ç›‘å¬çš„å­˜å‚¨ç±»å‹
            self._mp_event_storages = config.get("mp_event_storages", []) or []
            if isinstance(self._mp_event_storages, str):
                self._mp_event_storages = [x.strip() for x in self._mp_event_storages.split(',') if x.strip()]
            
            # åˆå§‹åŒ–æ—¶è·å–å¯ç”¨å­˜å‚¨åˆ—è¡¨
            self._available_storages = self.__get_available_storages()
            
            # äº‘ä¸‹è½½é…ç½®
            self._cloud_download_enabled = bool(config.get("cloud_download_enabled", False))
            self._cloud_download_path = config.get("cloud_download_path", "/äº‘ä¸‹è½½") or "/äº‘ä¸‹è½½"
            self._cloud_download_remove_small_files = bool(config.get("cloud_download_remove_small_files", False))
            self._cloud_download_organize = bool(config.get("cloud_download_organize", False))

    def get_state(self) -> bool:
        return self._enabled

    def get_service(self) -> List[Dict[str, Any]]:
        """
        æ³¨å†Œæ’ä»¶å…¬å…±æœåŠ¡
        [{
            "id": "æœåŠ¡ID",
            "name": "æœåŠ¡åç§°",
            "trigger": "è§¦å‘å™¨ï¼šcron/interval/date/CronTrigger.from_crontab()",
            "func": self.xxx,
            "kwargs": {} # å®šæ—¶å™¨å‚æ•°
        }]
        """
        services = []
        if self._enabled:
            services.append({
                "id": "MHNotify",
                "name": "MediaHelperå¢å¼º",
                "trigger": CronTrigger.from_crontab("* * * * *"),
                "func": self.__notify_mh,
                "kwargs": {}
            })
        # mhè®¢é˜…è¾…åŠ©è°ƒåº¦
        if self._mh_assist_enabled:
            services.append({
                "id": "MHAssist",
                "name": "mhè®¢é˜…è¾…åŠ©",
                "trigger": CronTrigger.from_crontab("* * * * *"),
                "func": self.__assist_scheduler,
                "kwargs": {}
            })
        # 115 ç”Ÿæ´»äº‹ä»¶ç›‘å¬
        if self._p115_life_enabled and (self._p115_cookie or "").strip():
            try:
                services.append({
                    "id": "P115LifeWatch",
                    "name": "115ç”Ÿæ´»äº‹ä»¶ç›‘å¬",
                    "trigger": CronTrigger.from_crontab(self._p115_poll_cron),
                    "func": self.__watch_115_life,
                    "kwargs": {}
                })
            except Exception:
                # è‹¥ cron éæ³•ï¼Œå›é€€æ¯åˆ†é’Ÿ
                services.append({
                    "id": "P115LifeWatch",
                    "name": "115ç”Ÿæ´»äº‹ä»¶ç›‘å¬",
                    "trigger": CronTrigger.from_crontab("* * * * *"),
                    "func": self.__watch_115_life,
                    "kwargs": {}
                })
        return services

    @staticmethod
    def get_command() -> List[Dict[str, Any]]:
        """å®šä¹‰è¿œç¨‹æ§åˆ¶å‘½ä»¤"""
        return [
            {
                "cmd": "/mhol",
                "event": EventType.PluginAction,
                "desc": "æ·»åŠ 115äº‘ä¸‹è½½ä»»åŠ¡",
                "category": "ä¸‹è½½",
                "data": {
                    "action": "mh_add_offline"
                }
            }
        ]

    def get_api(self) -> List[Dict[str, Any]]:
        # æä¾› 115 ç›®å½•æµè§ˆ APIï¼Œä¾¿äºåšç›®å½•é€‰æ‹©å™¨
        return [
            {
                "path": "/p115/list_directories",
                "endpoint": self.api_p115_list_directories,
                "methods": ["GET"],
                "summary": "åˆ—å‡º115ç½‘ç›˜æŒ‡å®šè·¯å¾„ä¸‹çš„ç›®å½•"
            },
            {
                "path": "/p115/watch_rules",
                "endpoint": self.api_p115_watch_rules,
                "methods": ["GET"],
                "summary": "è·å–å½“å‰ç›®å½•äº‹ä»¶è§„åˆ™"
            },
            {
                "path": "/p115/add_watch_rule",
                "endpoint": self.api_p115_add_watch_rule,
                "methods": ["POST"],
                "summary": "æ·»åŠ ç›®å½•äº‹ä»¶è§„åˆ™ï¼ˆpath, eventsï¼‰"
            },
            {
                "path": "/p115/remove_watch_rule",
                "endpoint": self.api_p115_remove_watch_rule,
                "methods": ["POST"],
                "summary": "ç§»é™¤ç›®å½•äº‹ä»¶è§„åˆ™ï¼ˆpathï¼‰"
            }
        ]

    def api_p115_list_directories(self, path: str = "/", apikey: str = "") -> dict:
        try:
            if apikey != settings.API_TOKEN:
                return {"success": False, "error": "APIå¯†é’¥é”™è¯¯"}
            if not self._p115_cookie:
                return {"success": False, "error": "æœªé…ç½® 115 Cookie"}
            # å¤ç”¨ç°æœ‰çš„ P115 å®¢æˆ·ç«¯å°è£…
            try:
                from app.plugins.p115strgmsub.clients.p115 import P115ClientManager  # type: ignore
            except Exception:
                P115ClientManager = None
            if not P115ClientManager:
                return {"success": False, "error": "ç¼ºå°‘ P115 å®¢æˆ·ç«¯ä¾èµ–ï¼ˆp115strgmsubï¼‰"}
            mgr = P115ClientManager(cookies=self._p115_cookie)
            if not mgr.check_login():
                return {"success": False, "error": "115 ç™»å½•å¤±è´¥ï¼ŒCookie å¯èƒ½å·²è¿‡æœŸ"}
            # è§„èŒƒåŒ–è·¯å¾„
            path = (path or "/").replace("\\", "/")
            if not path.startswith("/"):
                path = "/" + path
            directories = mgr.list_directories(path)
            # æ„å»ºé¢åŒ…å±‘
            breadcrumbs = []
            if path and path != "/":
                parts = [p for p in path.split("/") if p]
                current_path = ""
                breadcrumbs.append({"name": "æ ¹ç›®å½•", "path": "/"})
                for part in parts:
                    current_path = f"{current_path}/{part}"
                    breadcrumbs.append({"name": part, "path": current_path})
            else:
                breadcrumbs.append({"name": "æ ¹ç›®å½•", "path": "/"})
            return {
                "success": True,
                "path": path,
                "breadcrumbs": breadcrumbs,
                "directories": directories
            }
        except Exception as e:
            logger.error(f"mhnotify: åˆ—å‡º115ç›®å½•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def _rules_to_text(self, rules: List[Dict[str, Any]]) -> str:
        """å°†è§„åˆ™åˆ—è¡¨è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
        lines = []
        for rule in rules:
            path = rule.get('path', '')
            events = rule.get('events', [])
            if path:
                if events:
                    lines.append(f"{path}:{','.join(events)}")
                else:
                    lines.append(path)
        return '\n'.join(lines)

    def api_p115_watch_rules(self, apikey: str = "") -> dict:
        try:
            if apikey != settings.API_TOKEN:
                return {"success": False, "error": "APIå¯†é’¥é”™è¯¯"}
            return {"success": True, "rules": self._p115_watch_rules}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def api_p115_add_watch_rule(self, path: str = "/", events: Any = None, apikey: str = "") -> dict:
        try:
            if apikey != settings.API_TOKEN:
                return {"success": False, "error": "APIå¯†é’¥é”™è¯¯"}
            if not path or path == "":
                return {"success": False, "error": "ç¼ºå°‘ç›®å½•è·¯å¾„"}
            p = path.replace('\\', '/').strip()
            if not p.startswith('/'):
                p = '/' + p
            p = p.rstrip('/')
            evs: List[str] = []
            if events:
                if isinstance(events, str):
                    evs = [x.strip().lower() for x in events.split(',') if x.strip()]
                elif isinstance(events, list):
                    evs = [str(x).strip().lower() for x in events if str(x).strip()]
            # æ›´æ–°å†…å­˜ä¸é…ç½®
            rules = [r for r in (self._p115_watch_rules or []) if r.get('path') != p]
            rules.append({'path': p, 'events': evs})
            self._p115_watch_rules = rules
            cfg = self.get_config()
            if isinstance(cfg, dict):
                cfg['p115_watch_rules'] = rules
                cfg['p115_watch_rules_text'] = self._rules_to_text(rules)
                self.update_config(cfg)
            return {"success": True, "rules": rules}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def api_p115_remove_watch_rule(self, path: str = "/", apikey: str = "") -> dict:
        try:
            if apikey != settings.API_TOKEN:
                return {"success": False, "error": "APIå¯†é’¥é”™è¯¯"}
            p = path.replace('\\', '/').strip()
            if not p.startswith('/'):
                p = '/' + p
            p = p.rstrip('/')
            rules = [r for r in (self._p115_watch_rules or []) if r.get('path') != p]
            self._p115_watch_rules = rules
            cfg = self.get_config()
            if isinstance(cfg, dict):
                cfg['p115_watch_rules'] = rules
                cfg['p115_watch_rules_text'] = self._rules_to_text(rules)
                self.update_config(cfg)
            return {"success": True, "rules": rules}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _build_rule_row(self, index: int) -> dict:
        """æ„å»ºå•æ¡ç›®å½•è§„åˆ™çš„è¡¨å•è¡Œ"""
        return {
            'component': 'VRow',
            'props': {'class': 'align-center'},
            'content': [
                {
                    'component': 'VCol',
                    'props': {'cols': 12, 'md': 6},
                    'content': [
                        {
                            'component': 'VTextField',
                            'props': {
                                'model': f'rule_path_{index}',
                                'label': f'ç›®å½• {index + 1}',
                                'placeholder': '/æˆ‘çš„æ¥æ”¶/ç”µå½±',
                                'density': 'compact',
                                'hide-details': True
                            }
                        }
                    ]
                },
                {
                    'component': 'VCol',
                    'props': {'cols': 12, 'md': 6},
                    'content': [
                        {
                            'component': 'VSelect',
                            'props': {
                                'model': f'rule_events_{index}',
                                'label': 'ç›‘å¬äº‹ä»¶',
                                'items': [
                                    {'title': 'ä¸Šä¼ ', 'value': 'upload'},
                                    {'title': 'ç§»åŠ¨', 'value': 'move'},
                                    {'title': 'æ¥æ”¶', 'value': 'receive'},
                                    {'title': 'æ–°å»º', 'value': 'create'},
                                    {'title': 'å¤åˆ¶', 'value': 'copy'},
                                    {'title': 'åˆ é™¤', 'value': 'delete'}
                                ],
                                'multiple': True,
                                'chips': True,
                                'closable-chips': True,
                                'clearable': True,
                                'density': 'compact',
                                'hide-details': True,
                                'hint': 'ç•™ç©ºç›‘å¬å…¨éƒ¨äº‹ä»¶'
                            }
                        }
                    ]
                }
            ]
        }

    def get_form(self) -> Tuple[List[dict], Dict[str, Any]]:
        """
        æ‹¼è£…æ’ä»¶é…ç½®é¡µé¢ï¼Œéœ€è¦è¿”å›ä¸¤å—æ•°æ®ï¼š1ã€é¡µé¢é…ç½®ï¼›2ã€æ•°æ®ç»“æ„
        """
        # å¦‚æœå­˜å‚¨åˆ—è¡¨ä¸ºç©ºï¼Œå°è¯•è·å–ä¸€æ¬¡
        if not self._available_storages:
            self._available_storages = self.__get_available_storages()
        
        # é¢„è®¾æœ€å¤š10æ¡è§„åˆ™
        max_rules = 10
        
        # è·å–å½“å‰é…ç½®çš„è§„åˆ™è¡Œæ•°ï¼ˆé»˜è®¤3è¡Œï¼‰
        current_rule_count = getattr(self, '_rule_count', 3)
        if current_rule_count < 1:
            current_rule_count = 1
        if current_rule_count > max_rules:
            current_rule_count = max_rules
        
        # æ„å»ºè§„åˆ™è¡Œï¼ˆåªæ˜¾ç¤º current_rule_count è¡Œï¼‰
        rule_rows = []
        for i in range(current_rule_count):
            rule_rows.append(self._build_rule_row(i))
        
        # æ„å»ºé»˜è®¤å€¼å­—å…¸ï¼ŒåŒ…å«ç°æœ‰è§„åˆ™
        defaults = {
            "enabled": False,
            "mh_username": "",
            "mh_password": "",
            "mh_job_names": "",
            "mh_domain": "",
            "wait_minutes": 5,
            "mh_assist": False,
            "mh_assist_auto_delete": False,
            "clear_once": False,
            "clear_cloud_download_once": False,
            "hdhive_enabled": False,
            "hdhive_query_mode": "api",
            "hdhive_username": "",
            "hdhive_password": "",
            "hdhive_cookie": "",
            "hdhive_auto_refresh": False,
            "hdhive_refresh_before": 3600,
            "p115_life_enabled": False,
            "p115_cookie": "",
            "p115_life_events": [],
            "p115_life_cron": "* * * * *",
            "p115_watch_dirs": [],
            "p115_watch_rules": [],
            "p115_wait_minutes": 5,
            "check_mp_transfer": False,
            "rule_count": current_rule_count,
            "mp_event_enabled": False,
            "mp_event_wait_minutes": 5,
            "mp_event_storages": [],
            "cloud_download_enabled": False,
            "cloud_download_path": "/äº‘ä¸‹è½½"
        }
        
        # å°†ç°æœ‰è§„åˆ™å¡«å……åˆ°å¯¹åº”çš„ rule_path_X å’Œ rule_events_X
        for i in range(max_rules):
            defaults[f'rule_path_{i}'] = ""
            defaults[f'rule_events_{i}'] = []
        
        if self._p115_watch_rules:
            for i, rule in enumerate(self._p115_watch_rules[:max_rules]):
                defaults[f'rule_path_{i}'] = rule.get('path', '')
                defaults[f'rule_events_{i}'] = rule.get('events', [])

        return [
            {
                'component': 'VForm',
                'content': [
                    # å¯ç”¨æ’ä»¶
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'enabled',
                                            'label': 'å¯ç”¨æ’ä»¶',
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'mh_assist',
                                            'label': 'mhè®¢é˜…è¾…åŠ©ï¼ˆä»…æ–°è®¢é˜…ç”Ÿæ•ˆï¼‰',
                                            'hint': 'å¼€å¯åï¼Œæ–°æ·»åŠ çš„è®¢é˜…å°†é»˜è®¤åœ¨MPä¸­æš‚åœï¼Œå¹¶ç”±æ’ä»¶åœ¨MHåˆ›å»ºè®¢é˜…ã€å»¶æ—¶æŸ¥è¯¢è¿›åº¦ã€æŒ‰è§„åˆ™åˆ é™¤æˆ–æ¢å¤MPè®¢é˜…ï¼›ä¸å½±å“å·²æœ‰è®¢é˜…'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    # MPå®Œæˆååˆ é™¤MHè®¢é˜…
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'mh_assist_auto_delete',
                                            'label': 'MPè®¢é˜…å®Œæˆåè‡ªåŠ¨åˆ é™¤MHè®¢é˜…',
                                            'hint': 'å¼€å¯åï¼Œå½“MPè®¢é˜…å®Œæˆæˆ–å–æ¶ˆæ—¶ï¼Œè‡ªåŠ¨åˆ é™¤æˆ–æ›´æ–°å¯¹åº”çš„MHè®¢é˜…ã€‚å…³é—­åˆ™ä¿ç•™MHè®¢é˜…'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'mp_event_enabled',
                                            'label': 'MPäº‹ä»¶è§¦å‘ï¼ˆæ•´ç†/åˆ®å‰Šå®Œæˆï¼‰',
                                            'hint': 'å¼€å¯åï¼Œå½“MPæ•´ç†æˆ–åˆ®å‰Šåª’ä½“å®Œæˆæ—¶ï¼Œè‡ªåŠ¨é€šçŸ¥MHæ‰§è¡Œstrmç”Ÿæˆä»»åŠ¡ï¼ˆæ— è¿è¡Œä»»åŠ¡åˆ™ç«‹å³è§¦å‘ï¼‰'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'mp_event_wait_minutes',
                                            'label': 'MPäº‹ä»¶ç­‰å¾…åˆ†é’Ÿæ•°',
                                            'type': 'number',
                                            'placeholder': 'é»˜è®¤ 5',
                                            'hint': 'MPæ•´ç†å®Œæˆåï¼Œç­‰å¾…è¯¥åˆ†é’Ÿæ•°ä»¥ç¡®ä¿æ‰€æœ‰æ•´ç†ä»»åŠ¡å®Œæˆåå†è§¦å‘MHä»»åŠ¡'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VSelect',
                                        'props': {
                                            'model': 'mp_event_storages',
                                            'label': 'ç›‘å¬çš„å­˜å‚¨ç±»å‹',
                                            'items': self._available_storages or [
                                                {'title': 'æœ¬åœ°', 'value': 'local'},
                                                {'title': '115ç½‘ç›˜', 'value': 'u115'},
                                                {'title': 'é˜¿é‡Œäº‘ç›˜', 'value': 'alipan'},
                                                {'title': 'RClone', 'value': 'rclone'},
                                                {'title': 'OpenList', 'value': 'alist'}
                                            ],
                                            'multiple': True,
                                            'chips': True,
                                            'closable-chips': True,
                                            'clearable': True,
                                            'density': 'compact',
                                            'hint': 'ç•™ç©ºåˆ™ç›‘å¬æ‰€æœ‰å­˜å‚¨ç±»å‹çš„æ•´ç†/åˆ®å‰Šäº‹ä»¶'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    # äº‘ä¸‹è½½é…ç½®
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'cloud_download_enabled',
                                            'label': 'å¯ç”¨115äº‘ä¸‹è½½åŠŸèƒ½',
                                            'hint': 'å¼€å¯åï¼Œå¯ä½¿ç”¨ /mhol å‘½ä»¤æ·»åŠ 115ç¦»çº¿ä¸‹è½½ä»»åŠ¡'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'cloud_download_path',
                                            'label': '115äº‘ä¸‹è½½ä¿å­˜è·¯å¾„',
                                            'placeholder': '/äº‘ä¸‹è½½',
                                            'hint': '115ç½‘ç›˜ä¸­ä¿å­˜ç¦»çº¿ä¸‹è½½æ–‡ä»¶çš„ç›®å½•è·¯å¾„'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 4},
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'cloud_download_remove_small_files',
                                            'label': 'å‰”é™¤å°æ–‡ä»¶',
                                            'hint': 'äº‘ä¸‹è½½å®Œæˆåè‡ªåŠ¨åˆ é™¤å°äº10MBçš„æ–‡ä»¶',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 4},
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'cloud_download_organize',
                                            'label': 'ç§»åŠ¨æ•´ç†',
                                            'hint': 'äº‘ä¸‹è½½å®Œæˆåè‡ªåŠ¨ç§»åŠ¨åˆ°MHé»˜è®¤ç›®å½•å¹¶æ•´ç†',
                                            'persistent-hint': True
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    # 115 Cookie
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'p115_cookie',
                                            'label': '115 Cookie',
                                            'type': 'password',
                                            'placeholder': 'UID=...; CID=...; SEID=...ï¼ˆç²˜è´´å®Œæ•´ Cookieï¼‰',
                                            'hint': 'ä» 115 ç½‘é¡µç‰ˆå¤åˆ¶å®Œæ•´ Cookieï¼›ä»…æœ¬åœ°ä½¿ç”¨ï¼Œä¸ä¼šå¯¹å¤–å‘é€'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    # åˆ†éš”çº¿
                    {
                        'component': 'VRow',
                        'props': {'class': 'mt-4'},
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12},
                                'content': [
                                    {
                                        'component': 'VDivider'
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'å¯é€‰ï¼šç›‘å¬ 115 ç”Ÿæ´»äº‹ä»¶ï¼ˆä¸Šä¼ /ç§»åŠ¨/æ¥æ”¶/æ–°å»º/å¤åˆ¶/åˆ é™¤ï¼‰ä»¥è§¦å‘ MH çš„ strm ä»»åŠ¡ã€‚'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'p115_life_enabled',
                                            'label': 'ç›‘å¬ 115 ç”Ÿæ´»äº‹ä»¶'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 9
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'warning',
                                            'variant': 'tonal',
                                            'density': 'compact',
                                            'text': 'ä¸‹æ–¹å¯é…ç½®æœ€å¤š10æ¡ç›®å½•è§„åˆ™ï¼Œæ¯æ¡è§„åˆ™åŒ…å«ç›®å½•è·¯å¾„å’Œè¦ç›‘å¬çš„äº‹ä»¶ç±»å‹ã€‚äº‹ä»¶ç•™ç©ºè¡¨ç¤ºç›‘å¬è¯¥ç›®å½•çš„æ‰€æœ‰äº‹ä»¶ã€‚'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    # ç›®å½•è§„åˆ™æ ‡é¢˜
                    {
                        'component': 'VRow',
                        'props': {'class': 'mt-4'},
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12},
                                'content': [
                                    {
                                        'component': 'VDivider'
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'span',
                                        'props': {'class': 'text-subtitle-1 font-weight-bold'},
                                        'text': 'ğŸ“ ç›®å½•ç›‘å¬è§„åˆ™'
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 6},
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'rule_count',
                                            'label': 'è§„åˆ™è¡Œæ•°',
                                            'type': 'number',
                                            'min': 1,
                                            'max': 10,
                                            'density': 'compact',
                                            'hint': 'ä¿®æ”¹åä¿å­˜å³å¯å¢å‡è§„åˆ™è¡Œï¼ˆ1-10ï¼‰'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    # è§„åˆ™è¡Œ
                    *rule_rows,
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'p115_wait_minutes',
                                            'label': '115 äº‹ä»¶ç­‰å¾…åˆ†é’Ÿæ•°',
                                            'type': 'number',
                                            'placeholder': 'é»˜è®¤ 5',
                                            'hint': 'æ£€æµ‹åˆ° 115 ç”Ÿæ´»äº‹ä»¶åï¼Œç­‰å¾…è¯¥åˆ†é’Ÿæ•°ï¼›ç­‰å¾…æœŸé—´å¦‚æœ‰æ–°ç”Ÿæ´»äº‹ä»¶å°†æ»šåŠ¨å»¶é•¿ï¼Œé™é»˜åæ‰è§¦å‘ç”Ÿæˆä»»åŠ¡'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'HDHiveèµ„æºæŸ¥è¯¢ï¼šæ”¯æŒ Playwright/API ä¸¤ç§æ¨¡å¼ï¼Œè·å–å…è´¹ 115 åˆ†äº«é“¾æ¥å¹¶è‡ªåŠ¨ä½œä¸ºè‡ªå®šä¹‰é“¾æ¥éšè®¢é˜…ä¼ å…¥'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'hdhive_enabled',
                                            'label': 'å¯ç”¨ HDHive'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VSelect',
                                        'props': {
                                            'model': 'hdhive_query_mode',
                                            'label': 'HDHive æŸ¥è¯¢æ¨¡å¼',
                                            'items': [
                                                { 'title': 'Playwright', 'value': 'playwright' },
                                                { 'title': 'API', 'value': 'api' }
                                            ],
                                            'clearable': False
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'hdhive_username',
                                            'label': 'HDHive ç”¨æˆ·å'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'hdhive_password',
                                            'label': 'HDHive å¯†ç ',
                                            'type': 'password'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'hdhive_cookie',
                                            'label': 'HDHive Cookieï¼ˆAPI æ¨¡å¼ï¼‰',
                                            'type': 'password'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'hdhive_auto_refresh',
                                            'label': 'è‡ªåŠ¨åˆ·æ–° Cookie'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 3
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'hdhive_refresh_before',
                                            'label': 'Cookieæå‰åˆ·æ–°ç§’æ•°',
                                            'type': 'number',
                                            'placeholder': 'é»˜è®¤ 3600'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'clear_once',
                                            'label': 'æ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•ï¼ˆè¿è¡Œä¸€æ¬¡ï¼‰',
                                            'hint': 'âš ï¸ å¼€å¯åç‚¹ä¿å­˜ç«‹å³æ¸…é™¤æœ¬åŠ©æ‰‹é‡Œçš„MHè®¢é˜…ç›‘å¬è®°å½•ï¼ˆpending/watchï¼‰ï¼Œæ¸…ç†åå°†æ— æ³•å†ç›‘å¬ä¹‹å‰æ·»åŠ çš„MHè®¢é˜…è®°å½•ã€‚ç”¨äºç§»é™¤è„æ•°æ®æˆ–é‡ç½®åŠ©æ‰‹çŠ¶æ€ï¼Œæ“ä½œåè‡ªåŠ¨å¤ä½ä¸ºå…³é—­'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'clear_cloud_download_once',
                                            'label': 'æ¸…ç†åŠ©æ‰‹äº‘ä¸‹è½½è®°å½•ï¼ˆè¿è¡Œä¸€æ¬¡ï¼‰',
                                            'hint': 'âš ï¸ å¼€å¯åç‚¹ä¿å­˜ç«‹å³æ¸…é™¤æœ¬åŠ©æ‰‹é‡Œçš„äº‘ä¸‹è½½ç›‘æ§è®°å½•ï¼Œæ¸…ç†åå°†æ— æ³•å†ç›‘å¬ä¹‹å‰æ·»åŠ çš„äº‘ä¸‹è½½ä»»åŠ¡è®°å½•ã€‚å½“å‰ç‰ˆæœ¬äº‘ä¸‹è½½ä½¿ç”¨å®æ—¶çº¿ç¨‹ç›‘æ§ï¼ˆé¢„ç•™æ¥å£ï¼‰ï¼Œæ“ä½œåè‡ªåŠ¨å¤ä½ä¸ºå…³é—­'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'mh_domain',
                                            'label': 'MediaHelperåœ°å€'
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'mh_username',
                                            'label': 'MediaHelper_ç”¨æˆ·å'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 6
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'mh_password',
                                            'label': 'MediaHelper_å¯†ç ',
                                            'type': 'password'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 12
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'mh_job_names',
                                            'label': 'strmä»»åŠ¡åç§°ï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼‰',
                                            'placeholder': 'ä¾‹å¦‚ï¼š115ç½‘ç›˜1,115ç½‘ç›˜2',
                                            'hint': 'å¡«å†™strmç”Ÿæˆä»»åŠ¡åç§°ï¼›ç•™ç©ºåˆ™é»˜è®¤åŒ¹é…åç§°å«â€œ115ç½‘ç›˜â€'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'å½“æ£€æµ‹åˆ°åŒ¹é…çš„ 115 ç”Ÿæ´»äº‹ä»¶åï¼Œå°†åœ¨é™é»˜æœŸç»“æŸæ—¶è§¦å‘ MediaHelper çš„ strm ä»»åŠ¡'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'ä¸ºé¿å…é¢‘ç¹è§¦å‘ï¼šå¯ç”¨ç”Ÿæ´»äº‹ä»¶é™é»˜çª—å£ï¼ˆé»˜è®¤5åˆ†é’Ÿï¼‰ï¼›çª—å£æœŸé—´å¦‚æœ‰æ–°äº‹ä»¶å°†æ»šåŠ¨å»¶é•¿ï¼Œé™é»˜ç»“æŸåå†è§¦å‘'
                                        }
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
        ], defaults

    def get_page(self) -> List[dict]:
        pass

    @eventmanager.register(EventType.TransferComplete)
    @eventmanager.register(EventType.DownloadAdded)
    def send(self, event):
        """
        ç›‘å¬ MP æ•´ç†å®Œæˆå’Œåˆ®å‰Šå®Œæˆäº‹ä»¶ï¼Œè§¦å‘ MH ç”Ÿæˆ strm ä»»åŠ¡
        éœ€è¦åœ¨é…ç½®ä¸­å¼€å¯ 'MPäº‹ä»¶è§¦å‘' å¼€å…³
        æ”¯æŒæŒ‰å­˜å‚¨ç±»å‹è¿‡æ»¤
        """
        if not self._enabled or not self._mp_event_enabled:
            return
        
        if not event or not event.event_type:
            return
        
        # è¾…åŠ©å‡½æ•°ï¼šå°†äº‹ä»¶å¯¹è±¡é€’å½’è½¬æ¢ä¸ºå­—å…¸
        def __to_dict(_event):
            if _event is None:
                return None
            elif isinstance(_event, dict):
                return {k: __to_dict(v) for k, v in _event.items()}
            elif isinstance(_event, list):
                return [__to_dict(item) for item in _event]
            elif isinstance(_event, tuple):
                return tuple(__to_dict(list(_event)))
            elif isinstance(_event, set):
                return set(__to_dict(list(_event)))
            elif hasattr(_event, 'to_dict'):
                return __to_dict(_event.to_dict())
            elif hasattr(_event, '__dict__'):
                return __to_dict(_event.__dict__)
            elif isinstance(_event, (int, float, str, bool, type(None))):
                return _event
            else:
                return str(_event)
        
        # è·å–äº‹ä»¶ç±»å‹
        version = getattr(settings, "VERSION_FLAG", "v1")
        event_type = event.event_type if version == "v1" else event.event_type.value
        
        # åªå¤„ç†æ•´ç†å®Œæˆå’Œåˆ®å‰Šå®Œæˆäº‹ä»¶
        if event_type not in ["transfer.complete", "metadata.scrape", EventType.TransferComplete, EventType.DownloadAdded]:
            return
        
        # è§£æäº‹ä»¶æ•°æ®
        event_data = __to_dict(event.event_data)
        storage = None
        name = None
        
        try:
            # æ•´ç†å®Œæˆäº‹ä»¶
            if event_type in ["transfer.complete", EventType.TransferComplete]:
                transferinfo = event_data.get("transferinfo", {})
                success = transferinfo.get("success", False)
                if not success:
                    return
                
                target_diritem = transferinfo.get("target_diritem", {})
                target_item = transferinfo.get("target_item", {})
                storage = target_diritem.get("storage")
                name = target_item.get("name")
            
            # åˆ®å‰Šå®Œæˆäº‹ä»¶
            elif event_type in ["metadata.scrape", EventType.DownloadAdded]:
                fileitem = event_data.get("fileitem", {})
                storage = fileitem.get("storage") if isinstance(fileitem, dict) else None
                name = event_data.get("name")
        
        except Exception as e:
            logger.error(f"mhnotify: è§£æäº‹ä»¶æ•°æ®å¤±è´¥: {e}")
            return
        
        # æ£€æŸ¥å­˜å‚¨ç±»å‹è¿‡æ»¤
        if self._mp_event_storages:
            if not storage or storage not in self._mp_event_storages:
                logger.debug(f"mhnotify: å­˜å‚¨ç±»å‹ [{storage}] ä¸åœ¨ç›‘å¬åˆ—è¡¨ä¸­ï¼Œå¿½ç•¥äº‹ä»¶")
                return
        
        logger.info(f"mhnotify: æ”¶åˆ° MP äº‹ä»¶ [{event_type}]ï¼Œå­˜å‚¨: [{storage}]ï¼Œæ–‡ä»¶: [{name}]")
        
        # å¢åŠ å¾…é€šçŸ¥è®¡æ•°
        self._wait_notify_count += 1
        self._last_event_time = self.__get_time()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„æ•´ç†ä»»åŠ¡
        if self.__has_running_transfers():
            logger.info("mhnotify: æ£€æµ‹åˆ°æ­£åœ¨è¿è¡Œçš„æ•´ç†ä»»åŠ¡ï¼Œå»¶è¿Ÿè§¦å‘")
            # è®¾ç½®ç­‰å¾…çª—å£
            now_ts = self.__get_time()
            wait_seconds = self._mp_event_wait_minutes * 60
            self._next_notify_time = now_ts + wait_seconds
        else:
            logger.info("mhnotify: æ— è¿è¡Œä¸­çš„æ•´ç†ä»»åŠ¡ï¼Œå°†åœ¨ä¸‹æ¬¡è°ƒåº¦æ—¶ç«‹å³è§¦å‘")
            # æ¸…é›¶ç­‰å¾…æ—¶é—´ï¼Œä¸‹æ¬¡è°ƒåº¦ç«‹å³è§¦å‘
            self._next_notify_time = 0

    def __get_time(self):
        return int(time.time())
    
    def __get_available_storages(self) -> List[Dict[str, str]]:
        """
        ä»MPç³»ç»Ÿè·å–å¯ç”¨çš„å­˜å‚¨åˆ—è¡¨
        """
        try:
            from app.helper.storage import StorageHelper
            from app.db.systemconfig_oper import SystemConfigOper
            from app.schemas.types import SystemConfigKey
            
            # ç›´æ¥ä»æ•°æ®åº“è¯»å–å­˜å‚¨é…ç½®
            storage_confs = SystemConfigOper().get(SystemConfigKey.Storages)
            if storage_confs:
                storage_list = []
                for storage in storage_confs:
                    storage_type = storage.get("type", "")
                    storage_name = storage.get("name", storage_type)
                    if storage_type:
                        storage_list.append({
                            "title": storage_name,
                            "value": storage_type
                        })
                logger.info(f"mhnotify: æˆåŠŸè·å–å­˜å‚¨åˆ—è¡¨ï¼Œå…± {len(storage_list)} ä¸ª")
                return storage_list
            logger.debug("mhnotify: æœªé…ç½®å­˜å‚¨ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨")
        except Exception as e:
            logger.error(f"mhnotify: è·å–å­˜å‚¨åˆ—è¡¨å¼‚å¸¸: {e}")
        
        # è¿”å›é»˜è®¤å­˜å‚¨åˆ—è¡¨
        return [
            {"title": "æœ¬åœ°", "value": "local"},
            {"title": "115ç½‘ç›˜", "value": "u115"},
            {"title": "é˜¿é‡Œäº‘ç›˜", "value": "alipan"},
            {"title": "RClone", "value": "rclone"},
            {"title": "OpenList", "value": "alist"}
        ]

    def __has_running_transfers(self) -> bool:
        """
        æ£€æµ‹æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„æ•´ç†ä»»åŠ¡
        """
        try:
            from app.chain.transfer import TransferChain
            # ä¸å‰ç«¯ä¸€è‡´ï¼Œä½¿ç”¨ get_queue_tasks()
            jobs = TransferChain().get_queue_tasks()
            if not jobs:
                logger.debug("mhnotify: å½“å‰æ•´ç†é˜Ÿåˆ—ä¸ºç©º []")
                return False
            for job in jobs:
                tasks = getattr(job, 'tasks', [])
                if any((getattr(t, 'state', '') == 'running') for t in tasks):
                    logger.debug("mhnotify: å‘ç° running ä»»åŠ¡ï¼Œåˆ¤å®šä¸ºæ­£åœ¨æ•´ç†")
                    return True
            logger.debug("mhnotify: é˜Ÿåˆ—éç©ºä½†æ—  running ä»»åŠ¡ï¼Œåˆ¤å®šä¸ºä¸åœ¨æ•´ç†")
            return False
        except Exception as e:
            # è®°å½•å¼‚å¸¸å¹¶è¿”å›ä¸åœ¨æ•´ç†ï¼Œé¿å…è¯¯æŠ¥
            logger.warning(f"mhnotify: æ£€æµ‹æ•´ç†ä»»åŠ¡çŠ¶æ€å¼‚å¸¸ï¼š{e}ï¼ŒæŒ‰æ— è¿è¡Œå¤„ç†")
            return False

    def __notify_mh(self):
        try:
            # å½“æœ‰å¾…é€šçŸ¥æ—¶ï¼Œæ ¹æ®æ˜¯å¦å­˜åœ¨è¿è¡Œä¸­æ•´ç†ä»»åŠ¡å†³å®šç«‹å³è§¦å‘æˆ–è¿›å…¥ç­‰å¾…çª—å£
            now_ts = self.__get_time()
            if self._wait_notify_count > 0:
                # è‹¥å¯ç”¨ 115 ç”Ÿæ´»äº‹ä»¶ç›‘å¬ï¼Œåˆ™å…ˆæ£€æŸ¥ç”Ÿæ´»äº‹ä»¶é™é»˜çª—å£
                if self._p115_life_enabled and self._p115_next_notify_time:
                    if now_ts < self._p115_next_notify_time:
                        logger.info(f"115 ç”Ÿæ´»äº‹ä»¶é™é»˜çª—å£æœªåˆ°æœŸï¼ˆ{self._p115_next_notify_time - now_ts}sï¼‰ï¼Œæš‚ä¸è§¦å‘é€šçŸ¥")
                        return
                    else:
                        # åˆ°æœŸåæ¸…é›¶çª—å£
                        self._p115_next_notify_time = 0
                
                # è‹¥å¯ç”¨ MP äº‹ä»¶è§¦å‘ï¼Œæ£€æŸ¥ MP äº‹ä»¶ç­‰å¾…çª—å£
                if self._mp_event_enabled and self._next_notify_time:
                    if now_ts < self._next_notify_time:
                        # å¦‚æœä»æœ‰è¿è¡Œä¸­çš„æ•´ç†ä»»åŠ¡ï¼Œå»¶é•¿ç­‰å¾…æ—¶é—´
                        if self.__has_running_transfers():
                            wait_seconds = self._mp_event_wait_minutes * 60
                            self._next_notify_time = now_ts + wait_seconds
                            logger.info(f"MPæ•´ç†ä»»åŠ¡ä»åœ¨è¿è¡Œï¼Œå»¶é•¿ç­‰å¾…çª—å£ {self._mp_event_wait_minutes} åˆ†é’Ÿ")
                        else:
                            logger.info(f"MPäº‹ä»¶ç­‰å¾…çª—å£æœªåˆ°æœŸï¼ˆ{self._next_notify_time - now_ts}sï¼‰ï¼Œæš‚ä¸è§¦å‘é€šçŸ¥")
                        return
                    else:
                        # åˆ°æœŸåæ¸…é›¶çª—å£
                        self._next_notify_time = 0
                # ç™»å½•è·å– access_token
                login_url = f"{self._mh_domain}/api/v1/auth/login"
                login_payload = {
                    "username": self._mh_username,
                    "password": self._mh_password
                }
                headers = {
                    "Accept": "application/json, text/plain, */*",
                    "Content-Type": "application/json;charset=UTF-8",
                    "Origin": self._mh_domain,
                    "Accept-Language": "zh-CN",
                    "User-Agent": "MoviePilot/Plugin MHNotify"
                }
                login_res = RequestUtils(headers=headers).post(login_url, json=login_payload)
                if not login_res or login_res.status_code != 200:
                    logger.error(f"MediaHelper ç™»å½•å¤±è´¥ï¼š{getattr(login_res, 'status_code', 'N/A')} - {getattr(login_res, 'text', '')}")
                    return
                try:
                    login_data = login_res.json()
                    access_token = (login_data or {}).get("data", {}).get("access_token")
                except Exception:
                    access_token = None
                if not access_token:
                    logger.error("MediaHelper ç™»å½•æˆåŠŸä½†æœªè·å–åˆ° access_token")
                    return
                # è·å–ä»»åŠ¡åˆ—è¡¨å¹¶ç­›é€‰ strm ä»»åŠ¡
                tasks_url = f"{self._mh_domain}/api/v1/scheduled/tasks"
                list_headers = {
                    "Accept": "application/json, text/plain, */*",
                    "Authorization": f"Bearer {access_token}",
                    "User-Agent": "MoviePilot/Plugin MHNotify",
                    "Accept-Language": "zh-CN"
                }
                list_res = RequestUtils(headers=list_headers).get_res(tasks_url)
                if not list_res or list_res.status_code != 200:
                    logger.error(f"è·å– MediaHelper ä»»åŠ¡åˆ—è¡¨å¤±è´¥ï¼š{getattr(list_res, 'status_code', 'N/A')} - {getattr(list_res, 'text', '')}")
                try:
                    list_data = list_res.json() or {}
                    tasks = list_data.get("data", [])
                except Exception:
                    tasks = []
                # è¿‡æ»¤ cloud_strm_sync ä»»åŠ¡
                strm_tasks = [t for t in tasks if t.get('task') == 'cloud_strm_sync' and t.get('enabled')]
                selected_uuids = []
                name_filters = []
                if self._mh_job_names:
                    name_filters = [n.strip() for n in self._mh_job_names.split(',') if n.strip()]
                if name_filters:
                    selected_uuids = [t.get('uuid') for t in strm_tasks if (t.get('name') or '') in name_filters]
                else:
                    selected_uuids = [t.get('uuid') for t in strm_tasks if '115ç½‘ç›˜' in (t.get('name') or '')]
                if not selected_uuids:
                    logger.warning("æœªæ‰¾åˆ°å¯æ‰§è¡Œçš„ strm ä»»åŠ¡ï¼ˆcloud_strm_syncï¼‰ï¼Œè¯·æ£€æŸ¥ä»»åŠ¡åç§°æˆ–åœ¨é…ç½®ä¸­å¡«å†™ä»»åŠ¡UUIDåˆ—è¡¨")
                    return
                # é€ä¸ªè§¦å‘ï¼Œé—´éš”5ç§’
                exec_headers = {
                    "Accept": "application/json, text/plain, */*",
                    "Content-Type": "application/json;charset=UTF-8",
                    "Authorization": f"Bearer {access_token}",
                    "Origin": self._mh_domain,
                    "Accept-Language": "zh-CN",
                    "User-Agent": "MoviePilot/Plugin MHNotify"
                }
                for uuid in selected_uuids:
                    exec_url = f"{self._mh_domain}/api/v1/scheduled/execute/{uuid}"
                    exec_res = RequestUtils(headers=exec_headers).post(exec_url, json={})
                    if exec_res and exec_res.status_code in (200, 204):
                        logger.info(f"å·²è§¦å‘ MediaHelper è®¡åˆ’ä»»åŠ¡ï¼š{uuid}")
                        success_any = True
                    elif exec_res is not None:
                        logger.error(f"è§¦å‘ä»»åŠ¡å¤±è´¥ï¼š{uuid} - {exec_res.status_code} - {exec_res.text}")
                    else:
                        logger.error(f"è§¦å‘ä»»åŠ¡å¤±è´¥ï¼š{uuid} - æœªè·å–åˆ°è¿”å›ä¿¡æ¯")
                    time.sleep(5)
                if success_any:
                    self._wait_notify_count = 0
            else:
                if self._wait_notify_count > 0:
                    logger.info(
                        f"ç­‰å¾…é€šçŸ¥æ•°é‡ï¼š{self._wait_notify_count}ï¼Œæœ€åäº‹ä»¶æ—¶é—´ï¼š{self._last_event_time}")
        except Exception as e:
            logger.error(f"é€šçŸ¥MediaHelperå‘ç”Ÿå¼‚å¸¸ï¼š{e}")

    def stop_service(self):
        """
        é€€å‡ºæ’ä»¶
        """
        pass

    def __watch_115_life(self):
        """ç›‘å¬ 115 ç”Ÿæ´»äº‹ä»¶ï¼Œæ»¡è¶³ç­›é€‰æ—¶è§¦å‘å¾…é€šçŸ¥è®¡æ•°"""
        try:
            if not self._p115_life_enabled:
                return
            cookie = (self._p115_cookie or "").strip()
            if not cookie:
                return
            # è¯»å–ä¸Šæ¬¡æŒ‡é’ˆ
            last_ts = int(self.get_data(self._P115_LAST_TS_KEY) or 0)
            last_id_raw = self.get_data(self._P115_LAST_ID_KEY)
            try:
                last_id = int(last_id_raw) if last_id_raw is not None else 0
            except Exception:
                last_id = 0
            
            # é¦–æ¬¡å¯ç”¨æ—¶ï¼Œä»å½“å‰æ—¶é—´å¼€å§‹ç›‘å¬ï¼Œé¿å…æ‹‰å–æ‰€æœ‰å†å²äº‹ä»¶
            if last_ts == 0:
                current_ts = int(time.time())
                logger.info(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶é¦–æ¬¡å¯ç”¨ï¼Œä»å½“å‰æ—¶é—´å¼€å§‹ç›‘å¬ (ts={current_ts})")
                self.save_data(self._P115_LAST_TS_KEY, current_ts)
                self.save_data(self._P115_LAST_ID_KEY, 0)
                return

            # ä¼˜å…ˆä½¿ç”¨ p115client çš„ life APIï¼ˆä¸ p115strmhelper ä¿æŒä¸€è‡´ï¼‰
            try:
                from p115client import P115Client  # type: ignore
                from p115client.tool.life import iter_life_behavior_once, life_show  # type: ignore
                client = P115Client(cookie, app="web")
                # ç¡®è®¤ç”Ÿæ´»äº‹ä»¶å·²å¼€å¯
                try:
                    resp = life_show(client)
                    if not (isinstance(resp, dict) and resp.get("state")):
                        logger.warning("mhnotify: 115 ç”Ÿæ´»äº‹ä»¶æœªå¼€å¯æˆ–è·å–å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
                        return
                except Exception:
                    # life_show å¤±è´¥ä¸è‡´å‘½ï¼Œç»§ç»­å°è¯•æ‹‰å–
                    pass

                # æ‹‰å–ä¸€æ¬¡ï¼ˆä»ä¸Šæ¬¡æŒ‡é’ˆå¼€å§‹ï¼‰
                events_iter = iter_life_behavior_once(
                    client=client,
                    from_time=last_ts,
                    from_id=last_id,
                    app="web",
                    cooldown=1,
                )
                # æ”¶é›†åˆ°å†…å­˜ï¼ˆé™åˆ¶ä¸€å®šæ•°é‡é¿å…è¿‡å¤§ï¼‰
                events: List[Dict[str, Any]] = []
                max_collect = 200
                for idx, ev in enumerate(events_iter):
                    if idx >= max_collect:
                        break
                    events.append(ev)

                if not events:
                    return

                # å°†äº‹ä»¶ç±»å‹æ˜ å°„åˆ°ç®€åŒ–ç±»åˆ«ï¼Œä¾› UI é€‰æ‹©åŒ¹é…
                def map_type_to_simple(t: int) -> str:
                    """
                    115ç”Ÿæ´»äº‹ä»¶ç±»å‹æ˜ å°„ï¼ˆå‚è€ƒ p115strmhelperï¼‰
                    å·²çŸ¥ç±»å‹ï¼š
                    - type 1,2 â†’ upload (ä¸Šä¼ )
                    - type 5,6 â†’ move (ç§»åŠ¨)
                    - type 14 â†’ receive (æ¥æ”¶)
                    - type 17 â†’ create (æ–°å»º)
                    - type 18 â†’ copy (å¤åˆ¶)
                    - type 22 â†’ delete (åˆ é™¤)
                    å¦‚é‡æœªæ˜ å°„ç±»å‹ï¼Œå°†åœ¨æ—¥å¿—ä¸­è®°å½•è­¦å‘Š
                    """
                    if t in (1, 2):
                        return "upload"
                    if t in (5, 6):
                        return "move"
                    if t == 14:
                        return "receive"
                    if t == 17:
                        return "create"
                    if t == 18:
                        return "copy"
                    if t == 22:
                        return "delete"
                    return ""

                selected = set([x.lower() for x in (self._p115_events or [])])
                def _match_rules(full_path: str, ev_simple: str) -> bool:
                    rules = self._p115_watch_rules or []
                    if not rules:
                        return False
                    try:
                        for r in rules:
                            rp = (r.get('path') or '').strip()
                            evs = [str(x).strip().lower() for x in (r.get('events') or [])]
                            if not rp:
                                continue
                            if full_path.startswith(rp + '/') or full_path == rp:
                                if not evs:
                                    return True
                                return bool(ev_simple) and (ev_simple in evs)
                        return False
                    except Exception:
                        return False
                has_new = False
                new_last_ts = last_ts
                new_last_id = last_id
                triggered_events = []  # æ”¶é›†è§¦å‘çš„äº‹ä»¶ä¿¡æ¯
                
                # åªå¤„ç†æœ€è¿‘10åˆ†é’Ÿå†…çš„äº‹ä»¶
                current_time = int(time.time())
                time_window = 10 * 60  # 10åˆ†é’Ÿ
                cutoff_time = current_time - time_window
                
                # p115strmhelper åœ¨ once_pull ä¸­æœ€ç»ˆä»¥æœ€æ–°äº‹ä»¶æ›´æ–°æŒ‡é’ˆï¼›è¿™é‡ŒæŒ‰æ—¶é—´/IDå–æœ€å¤§
                for it in events:
                    try:
                        t = int(it.get("type", 0))
                        ut = int(it.get("update_time", 0))
                        eid = int(it.get("id", 0))
                        pid = int(it.get("parent_id", 0))
                        fname = str(it.get("file_name", "") or "")
                    except Exception:
                        continue
                    # è·³è¿‡æ—§äº‹ä»¶
                    if ut < last_ts or (ut == last_ts and eid <= last_id):
                        continue
                    
                    # è·³è¿‡è¶…è¿‡10åˆ†é’Ÿçš„æ—§äº‹ä»¶
                    if ut < cutoff_time:
                        logger.debug(f"mhnotify: è·³è¿‡10åˆ†é’Ÿå‰çš„æ—§äº‹ä»¶: {fname}, æ—¶é—´: {ut}")
                        # æ›´æ–°æŒ‡é’ˆä½†ä¸è§¦å‘
                        if ut > new_last_ts or (ut == new_last_ts and eid > new_last_id):
                            new_last_ts = ut
                            new_last_id = eid
                        continue
                    
                    # è¾“å‡ºåŸå§‹äº‹ä»¶æ•°æ®ç”¨äºè°ƒè¯•ï¼ˆä»…è®°å½•æ–°äº‹ä»¶ï¼‰
                    logger.debug(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶åŸå§‹æ•°æ® type={t}, id={eid}, file={fname}, parent_id={pid}, update_time={ut}, å®Œæ•´æ•°æ®={it}")
                    
                    simple = map_type_to_simple(t)
                    # å¦‚æœäº‹ä»¶ç±»å‹æœªèƒ½æ˜ å°„ï¼Œè®°å½•è­¦å‘Š
                    if not simple:
                        logger.warning(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶æœªæ˜ å°„ç±»å‹ type={t}, file={fname}, åŸå§‹æ•°æ®={it}")
                    
                    # ç±»å‹åŒ¹é…
                    type_ok = (not selected) or (simple and simple in selected)
                    dir_ok = True
                    full_path = ""
                    # ç›®å½•äº‹ä»¶è§„åˆ™ä¼˜å…ˆï¼ˆè‹¥é…ç½®äº†ï¼‰
                    if type_ok and (self._p115_watch_rules or self._p115_watch_dirs):
                        try:
                            full_dir = self._p115_dir_cache.get(pid)
                            if not full_dir:
                                from p115client.tool.attr import get_path  # type: ignore
                                full_dir = get_path(client=client, attr=pid, root_id=None) or ''
                                if full_dir.startswith('æ ¹ç›®å½•'):
                                    full_dir = full_dir[3:]
                                full_dir = full_dir.replace('\\', '/').strip()
                                if not full_dir.startswith('/'):
                                    full_dir = '/' + full_dir
                                full_dir = full_dir.rstrip('/')
                                self._p115_dir_cache[pid] = full_dir
                            full_path = (full_dir + '/' + fname).replace('\\', '/')
                            if self._p115_watch_rules:
                                dir_ok = _match_rules(full_path=full_path, ev_simple=simple)
                            elif self._p115_watch_dirs:
                                dir_ok = any(full_path.startswith(d + '/') or full_path == d for d in self._p115_watch_dirs)
                        except Exception:
                            dir_ok = False
                    if type_ok and dir_ok:
                        has_new = True
                        # è®°å½•è§¦å‘çš„äº‹ä»¶è¯¦æƒ…
                        event_name_map = {
                            "upload": "ä¸Šä¼ ",
                            "move": "ç§»åŠ¨",
                            "receive": "æ¥æ”¶",
                            "create": "æ–°å»º",
                            "copy": "å¤åˆ¶",
                            "delete": "åˆ é™¤"
                        }
                        event_name = event_name_map.get(simple, simple or f"type_{t}")
                        triggered_events.append({"path": full_path or fname, "event": event_name, "type": t, "time": ut})
                    if ut > new_last_ts or (ut == new_last_ts and eid > new_last_id):
                        new_last_ts = ut
                        new_last_id = eid

                if has_new:
                    self._wait_notify_count += 1
                    self._last_event_time = int(time.time())
                    # è¾“å‡ºè¯¦ç»†çš„è§¦å‘ä¿¡æ¯ï¼ˆåŒ…å«äº‹ä»¶å‘ç”Ÿæ—¶é—´ï¼‰
                    from datetime import datetime
                    for evt in triggered_events:
                        evt_time = datetime.fromtimestamp(evt.get('time', 0)).strftime('%Y-%m-%d %H:%M:%S') if evt.get('time') else 'æœªçŸ¥'
                        logger.info(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶è§¦å‘ - ç›®å½•: {evt['path']} | äº‹ä»¶: {evt['event']} | å‘ç”Ÿæ—¶é—´: {evt_time}")
                    logger.info(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶è§¦å‘ï¼ˆp115client.lifeï¼‰ï¼Œå…± {len(triggered_events)} ä¸ªäº‹ä»¶ï¼Œè®¡å…¥ä¸€æ¬¡strmè§¦å‘ä¿¡å·")
                    # è®¾ç½®/å»¶é•¿ç”Ÿæ´»äº‹ä»¶é™é»˜çª—å£
                    try:
                        delay_seconds = max(int(self._p115_wait_minutes) * 60, 0)
                    except Exception:
                        delay_seconds = 300
                    self._p115_next_notify_time = int(time.time()) + delay_seconds

                # ä¿å­˜æŒ‡é’ˆ
                if new_last_ts:
                    self.save_data(self._P115_LAST_TS_KEY, int(new_last_ts))
                if new_last_id:
                    self.save_data(self._P115_LAST_ID_KEY, int(new_last_id))
                return
            except Exception:
                # è‹¥ p115client ä¸å¯ç”¨æˆ–å¼‚å¸¸ï¼Œé€€å›åˆ°ç®€æ˜“ HTTP æ–¹æ¡ˆ
                pass

            # å›é€€ï¼šHTTP æ–¹æ¡ˆï¼ˆå…¼å®¹æ€§è¾ƒå·®ï¼Œä»…ä½œä¸ºå…œåº•ï¼‰
            headers = {
                "Accept": "application/json, text/plain, */*",
                "Cookie": cookie,
                "User-Agent": "MoviePilot/Plugin MHNotify",
                "Referer": "https://115.com/"
            }
            candidate_urls = [
                "https://webapi.115.com/life/events?limit=50",
                "https://webapi.115.com/files/new?aid=1&cid=0&show_dir=1&offset=0&limit=50",
            ]
            hit_url = None
            items: List[Dict[str, Any]] = []
            for url in candidate_urls:
                try:
                    res = RequestUtils(headers=headers, timeout=20).get_res(url)
                    if not res or res.status_code != 200:
                        continue
                    data = res.json()
                    if "events" in data:
                        items = data.get("events") or []
                    elif "data" in data and isinstance(data.get("data"), dict) and ("list" in data["data"]):
                        items = data.get("data", {}).get("list", [])
                    elif "list" in data:
                        items = data.get("list") or []
                    else:
                        items = []
                    hit_url = url
                    if items:
                        break
                except Exception:
                    continue
            if not items:
                return

            def normalize_event_name(item: Dict[str, Any]) -> str:
                name = (item.get("action") or item.get("event") or item.get("type") or "").lower()
                text = (item.get("action_text") or item.get("event_text") or item.get("name") or "").lower()
                m = {
                    "ä¸Šä¼ ": "upload", "upload": "upload",
                    "ç§»åŠ¨": "move", "move": "move",
                    "æ¥æ”¶": "receive", "receive": "receive",
                    "æ–°å»º": "create", "åˆ›å»º": "create", "create": "create",
                    "å¤åˆ¶": "copy", "copy": "copy",
                    "åˆ é™¤": "delete", "ç§»åˆ°å›æ”¶ç«™": "delete", "delete": "delete",
                }
                for k, v in m.items():
                    if k in name or k in text:
                        return v
                return name or text or ""

            def extract_ts(item: Dict[str, Any]) -> int:
                for key in ("update_time", "utime", "time", "ctime", "created_time"):
                    val = item.get(key)
                    if isinstance(val, (int, float)):
                        return int(val)
                    if isinstance(val, str) and val.isdigit():
                        return int(val)
                return 0

            def extract_id(item: Dict[str, Any]) -> int:
                for key in ("id", "eid", "event_id"):
                    val = item.get(key)
                    if val is not None and str(val).isdigit():
                        return int(val)
                return 0

            selected = set([x.lower() for x in (self._p115_events or [])])
            def _match_rules(full_path: str, ev_simple: str) -> bool:
                rules = self._p115_watch_rules or []
                if not rules:
                    return False
                try:
                    for r in rules:
                        rp = (r.get('path') or '').strip()
                        evs = [str(x).strip().lower() for x in (r.get('events') or [])]
                        if not rp:
                            continue
                        if full_path.startswith(rp + '/') or full_path == rp:
                            if not evs:
                                return True
                            return bool(ev_simple) and (ev_simple in evs)
                    return False
                except Exception:
                    return False
            has_new = False
            new_last_ts = last_ts
            new_last_id = last_id
            triggered_events = []  # æ”¶é›†è§¦å‘çš„äº‹ä»¶ä¿¡æ¯
            for it in items:
                # è¾“å‡ºåŸå§‹äº‹ä»¶æ•°æ®ç”¨äºè°ƒè¯•
                logger.debug(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶HTTPåŸå§‹æ•°æ®={it}")
                
                ev = normalize_event_name(it)
                ts = extract_ts(it)
                eid = extract_id(it)
                if ts < last_ts or (ts == last_ts and eid <= last_id):
                    continue
                
                # å¦‚æœäº‹ä»¶ç±»å‹æœªèƒ½è¯†åˆ«ï¼Œè®°å½•è­¦å‘Š
                if not ev:
                    logger.warning(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶HTTPæœªè¯†åˆ«ç±»å‹ï¼ŒåŸå§‹æ•°æ®={it}")
                
                type_ok = (not selected) or (ev and ev in selected)
                dir_ok = True
                full_path = ""
                # ç›®å½•äº‹ä»¶è§„åˆ™ä¼˜å…ˆï¼ˆHTTP å…œåº•ä¸‹å°½åŠ›è·å–è·¯å¾„ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼‰
                if type_ok and (self._p115_watch_rules or self._p115_watch_dirs):
                    try:
                        pid = int(it.get('parent_id') or 0)
                        fname = str(it.get('file_name') or it.get('name') or '')
                        full_dir = self._p115_dir_cache.get(pid)
                        if not full_dir:
                            full_dir = ''
                        full_path = (full_dir + '/' + fname).replace('\\', '/')
                        if self._p115_watch_rules:
                            dir_ok = _match_rules(full_path=full_path, ev_simple=ev)
                        elif self._p115_watch_dirs:
                            dir_ok = any(full_path.startswith(d + '/') or full_path == d for d in self._p115_watch_dirs)
                    except Exception:
                        dir_ok = False
                if type_ok and dir_ok:
                    has_new = True
                    # è®°å½•è§¦å‘çš„äº‹ä»¶è¯¦æƒ…
                    event_name_map = {
                        "upload": "ä¸Šä¼ ",
                        "move": "ç§»åŠ¨",
                        "receive": "æ¥æ”¶",
                        "create": "æ–°å»º",
                        "copy": "å¤åˆ¶",
                        "delete": "åˆ é™¤"
                    }
                    event_name = event_name_map.get(ev, ev or "æœªçŸ¥")
                    fname = str(it.get('file_name') or it.get('name') or '')
                    triggered_events.append({"path": full_path or fname, "event": event_name})
                if ts > new_last_ts or (ts == new_last_ts and eid > new_last_id):
                    new_last_ts = ts
                    new_last_id = eid

            if has_new:
                self._wait_notify_count += 1
                self._last_event_time = int(time.time())
                # è¾“å‡ºè¯¦ç»†çš„è§¦å‘ä¿¡æ¯
                for evt in triggered_events:
                    logger.info(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶è§¦å‘ - ç›®å½•: {evt['path']} | äº‹ä»¶: {evt['event']}")
                logger.info(f"mhnotify: 115ç”Ÿæ´»äº‹ä»¶è§¦å‘ï¼ˆ{hit_url}ï¼‰ï¼Œå…± {len(triggered_events)} ä¸ªäº‹ä»¶ï¼Œè®¡å…¥ä¸€æ¬¡strmè§¦å‘ä¿¡å·")
                try:
                    delay_seconds = max(int(self._p115_wait_minutes) * 60, 0)
                except Exception:
                    delay_seconds = 300
                self._p115_next_notify_time = int(time.time()) + delay_seconds
            if new_last_ts:
                self.save_data(self._P115_LAST_TS_KEY, int(new_last_ts))
            if new_last_id:
                self.save_data(self._P115_LAST_ID_KEY, int(new_last_id))
        except Exception:
            logger.warning("mhnotify: ç›‘å¬115ç”Ÿæ´»äº‹ä»¶å¼‚å¸¸", exc_info=True)

    @eventmanager.register(EventType.SubscribeAdded)
    def _on_subscribe_added(self, event: Event):
        """
        mhè®¢é˜…è¾…åŠ©ï¼šä»…å¯¹æ–°è®¢é˜…ç”Ÿæ•ˆ
        - æš‚åœè¯¥è®¢é˜…ï¼ˆstate='S'ï¼Œä¸æ”¹åŠ¨å·²æœ‰è®¢é˜…ï¼‰
        - ç™»å½•MHå¹¶è¯»å–é»˜è®¤é…ç½®
        - æŒ‰åª’ä½“ç±»å‹åœ¨MHåˆ›å»ºè®¢é˜…
        - è®°å½•mh_uuidå¹¶åœ¨5åˆ†é’ŸåæŸ¥è¯¢è¿›åº¦ï¼ŒæŒ‰è§„åˆ™å¤„ç†ï¼ˆåˆ é™¤æˆ–æ¢å¤MPè®¢é˜…ï¼‰
        """
        try:
            if not event or not self._mh_assist_enabled:
                return
            event_data = event.event_data or {}
            try:
                mid = (event_data.get("mediainfo") or {}).get("tmdb_id") or (event_data.get("mediainfo") or {}).get("tmdbid")
                mtitle = (event_data.get("mediainfo") or {}).get("title") or (event_data.get("mediainfo") or {}).get("name")
                mseason = (event_data.get("mediainfo") or {}).get("season")
                logger.info(f"mhnotify: SubscribeAdded äº‹ä»¶: sub_id={event_data.get('subscribe_id')} tmdb_id={mid} title={mtitle} event.season={mseason}")
            except Exception:
                pass
            sub_id = event_data.get("subscribe_id")
            mediainfo_dict = event_data.get("mediainfo") or {}
            if not sub_id:
                return
            # æš‚åœè¯¥è®¢é˜…ï¼Œä»…é’ˆå¯¹æ–°è®¢é˜…
            with SessionFactory() as db:
                subscribe = SubscribeOper(db=db).get(sub_id)
                if not subscribe:
                    return
                SubscribeOper(db=db).update(sub_id, {"state": "S", "sites": [-1]})
                # é‡æ–°è·å–ï¼Œç¡®ä¿å­£å·ç­‰å­—æ®µå·²æ­£ç¡®åŠ è½½
                subscribe = SubscribeOper(db=db).get(sub_id)
                try:
                    logger.info(f"mhnotify: è®¢é˜…æš‚åœå®Œæˆ id={sub_id} type={getattr(subscribe,'type',None)} season={getattr(subscribe,'season',None)}")
                except Exception:
                    pass
            # ç™»å½• MH æ‹¿ token
            access_token = self.__mh_login()
            if not access_token:
                logger.error("mhnotify: ç™»å½•MediaHelperå¤±è´¥ï¼Œæ— æ³•åˆ›å»ºè®¢é˜…")
                return
            # è¯»å–é»˜è®¤é…ç½®
            defaults = self.__mh_get_defaults(access_token)
            # è‹¥ä¸ºå‰§é›†ï¼ŒèšåˆåŒä¸€ TMDB çš„å¤šå­£è®¢é˜…ï¼ˆç”µå½±ä¸éœ€è¦èšåˆå­£ï¼‰
            aggregate_seasons: Optional[List[int]] = None
            # åˆ¤æ–­åª’ä½“ç±»å‹
            sub_type = (getattr(subscribe, 'type', '') or '').strip().lower()
            is_tv = sub_type in ('tv', 'ç”µè§†å‰§')
            aggregate_seasons = []  # åˆå§‹åŒ–ï¼Œç”µå½±æ—¶ä¸ºç©º
            
            # åªæœ‰ç”µè§†å‰§æ‰è¿›è¡Œèšåˆå­£é€»è¾‘
            if is_tv:
                try:
                    # å– tmdb_id
                    tmdb_id = getattr(subscribe, 'tmdbid', None) or mediainfo_dict.get('tmdb_id') or mediainfo_dict.get('tmdbid')
                    # æŸ¥è¯¢ MP å†…ç›¸åŒ tmdb çš„è®¢é˜…ï¼Œèšåˆå­£
                    if tmdb_id:
                        logger.info(f"mhnotify: èšåˆå­£å¼€å§‹ï¼Œtmdb_id={tmdb_id}")
                        with SessionFactory() as db:
                            all_subs = SubscribeOper(db=db).list_by_tmdbid(tmdb_id)
                            logger.info(f"mhnotify: MPå†…åŒtmdbè®¢é˜…æ•°={len(all_subs or [])}")
                            seasons = []
                            for s in all_subs or []:
                                try:
                                    stype = (getattr(s, 'type', '') or '').strip()
                                    stype_lower = (stype or '').lower()
                                    if stype_lower == 'tv' or stype in {'ç”µè§†å‰§'}:
                                        # ä¼˜å…ˆä½¿ç”¨è®¢é˜…ä¸­çš„ seasonï¼Œå…¶æ¬¡ä»æ ‡é¢˜è§£æ
                                        s_season = getattr(s, 'season', None)
                                        if s_season is None:
                                            s_season = self.__extract_season_from_text(getattr(s, 'name', '') or '')
                                        seasons.append(s_season)
                                        logger.info(f"mhnotify: è®¢é˜…èšåˆå€™é€‰ id={getattr(s,'id',None)} type={stype} season={getattr(s,'season',None)} parsed={s_season}")
                                except Exception:
                                    pass
                        # è½¬æ¢å­£ä¸ºæ•´æ•°ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æ•°å­—ï¼‰
                        for x in seasons:
                            if isinstance(x, int):
                                aggregate_seasons.append(x)
                            elif isinstance(x, str) and x.isdigit():
                                aggregate_seasons.append(int(x))
                        # è¿‡æ»¤æ— æ•ˆå­£å·ï¼ˆNone/0/è´Ÿæ•°ï¼‰å¹¶å»é‡æ’åº
                        aggregate_seasons = sorted({s for s in aggregate_seasons if isinstance(s, int) and s > 0})
                        logger.info(f"mhnotify: èšåˆå­£ï¼ˆè½¬æ¢åï¼‰={aggregate_seasons}")
                        if aggregate_seasons:
                            logger.info(f"mhnotify: æ£€æµ‹åˆ°è¯¥å‰§å­˜åœ¨å¤šå­£è®¢é˜…ï¼Œèšåˆå­£ï¼š{aggregate_seasons}")
                        else:
                            logger.info("mhnotify: æœªèšåˆåˆ°å­£ä¿¡æ¯ï¼Œå°†å›é€€ä½¿ç”¨äº‹ä»¶æˆ–è®¢é˜…ä¸­çš„å­£")
                except Exception:
                    logger.warning("mhnotify: èšåˆå­£ä¿¡æ¯å¤±è´¥", exc_info=True)
            else:
                # ç”µå½±ç±»å‹ä¸éœ€è¦èšåˆå­£
                logger.debug(f"mhnotify: åª’ä½“ç±»å‹ä¸ºç”µå½±ï¼Œè·³è¿‡èšåˆå­£é€»è¾‘")
            # æ„å»ºåˆ›å»ºå‚æ•°ï¼ˆè‹¥ä¸ºTVå°†å¸¦å…¥èšåˆå­£ï¼‰
            create_payload = self.__build_mh_create_payload(subscribe, mediainfo_dict, defaults, aggregate_seasons=aggregate_seasons)
            if not create_payload:
                logger.error("mhnotify: æ„å»ºMHè®¢é˜…åˆ›å»ºå‚æ•°å¤±è´¥")
                return
            # è‹¥å·²å­˜åœ¨ç›¸åŒ tmdb_id çš„ MH è®¢é˜…ï¼Œåˆ™å¤ç”¨æˆ–é‡å»ºï¼ˆä»¥èšåˆå­£ä¸ºå‡†ï¼‰
            existing_uuid: Optional[str] = None
            existing_selected: List[int] = []
            existing_custom_links: List[str] = []  # ä¿ç•™ç°æœ‰è®¢é˜…çš„è‡ªå®šä¹‰é“¾æ¥
            try:
                lst = self.__mh_list_subscriptions(access_token)
                subs = (lst.get("data") or {}).get("subscriptions") or []
                for rec in subs:
                    params = rec.get("params") or {}
                    if params.get("tmdb_id") == create_payload.get("tmdb_id") and (params.get("media_type") or '').lower() == (create_payload.get("media_type") or '').lower():
                        existing_uuid = rec.get("uuid") or rec.get("task", {}).get("uuid")
                        try:
                            existing_selected = [int(x) for x in (params.get("selected_seasons") or [])]
                        except Exception:
                            existing_selected = []
                        # è·å–ç°æœ‰è®¢é˜…çš„è‡ªå®šä¹‰é“¾æ¥
                        existing_custom_links = params.get("user_custom_links") or []
                        if existing_custom_links:
                            logger.info(f"mhnotify: ç°æœ‰MHè®¢é˜…å·²æœ‰ {len(existing_custom_links)} ä¸ªè‡ªå®šä¹‰é“¾æ¥")
                        logger.info(f"mhnotify: ç°æœ‰MHè®¢é˜…å‘½ä¸­ tmdb_id={params.get('tmdb_id')} uuid={existing_uuid} seasons={existing_selected}")
                        break
                if existing_uuid:
                    agg_set = set(create_payload.get("selected_seasons") or [])
                    exist_set = set(existing_selected or [])
                    if agg_set and agg_set != exist_set:
                        # éœ€è¦åŒ…å«æ›´å¤šå­£ï¼šä¼˜å…ˆå°è¯•æ›´æ–°è®¢é˜…å­£é›†åˆï¼›å¤±è´¥åˆ™é‡å»º
                        # æ›´æ–°æ—¶ä¿ç•™ç°æœ‰çš„è‡ªå®šä¹‰é“¾æ¥
                        if existing_custom_links:
                            create_payload["user_custom_links"] = existing_custom_links
                        logger.info(f"mhnotify: å‘ç°ç°æœ‰MHè®¢é˜… {existing_uuid}ï¼Œå­£é›†åˆä¸ä¸€è‡´ï¼Œå°è¯•æ›´æ–°ä¸º {sorted(agg_set)}")
                        upd = self.__mh_update_subscription(access_token, existing_uuid, create_payload)
                        if upd:
                            logger.info(f"mhnotify: å·²æ›´æ–°ç°æœ‰è®¢é˜… {existing_uuid} ä¸ºèšåˆå­£ {sorted(agg_set)}")
                        else:
                            logger.info(f"mhnotify: æ›´æ–°å¤±è´¥ï¼Œæ”¹ä¸ºé‡å»ºè®¢é˜…ä¸ºèšåˆå­£ {sorted(agg_set)}")
                            self.__mh_delete_subscription(access_token, existing_uuid)
                            existing_uuid = None
                    else:
                        # å®Œå…¨ä¸€è‡´ï¼šç›´æ¥å¤ç”¨
                        logger.info(f"mhnotify: å‘ç°ç°æœ‰MHè®¢é˜… {existing_uuid}ï¼Œå­£é›†åˆä¸€è‡´ï¼Œå¤ç”¨è¯¥è®¢é˜…")
            except Exception:
                logger.warning("mhnotify: æ£€æŸ¥ç°æœ‰MHè®¢é˜…å¤±è´¥", exc_info=True)
            # HDHive æŸ¥è¯¢è‡ªå®šä¹‰é“¾æ¥
            links: List[str] = []
            try:
                links = self.__fetch_hdhive_links(
                    tmdb_id=create_payload.get("tmdb_id"),
                    media_type=create_payload.get("media_type")
                )
                if links:
                    logger.info(f"mhnotify: HDHive è·å–åˆ° {len(links)} ä¸ªå…è´¹115é“¾æ¥")
            except Exception:
                logger.error("mhnotify: HDHive æŸ¥è¯¢é“¾æ¥å¤±è´¥", exc_info=True)
            
            # åˆå¹¶ç°æœ‰è‡ªå®šä¹‰é“¾æ¥ä¸æ–°æŸ¥è¯¢çš„ HDHive é“¾æ¥ï¼ˆå»é‡ï¼‰
            merged_links: List[str] = list(existing_custom_links)  # ä¿ç•™ç°æœ‰é“¾æ¥
            if links:
                # æå–é“¾æ¥çš„æ ¸å¿ƒæ ‡è¯†ç”¨äºå»é‡ï¼ˆå»é™¤åè®®å‰ç¼€å’Œå°¾éƒ¨å‚æ•°å·®å¼‚ï¼‰
                def extract_link_key(link: str) -> str:
                    """æå–é“¾æ¥çš„æ ¸å¿ƒéƒ¨åˆ†ç”¨äºå»é‡æ¯”è¾ƒ"""
                    # ç§»é™¤åè®®å‰ç¼€
                    key = link.replace("https://", "").replace("http://", "")
                    # ç§»é™¤å°¾éƒ¨çš„ & æˆ– ç©ºæ ¼
                    key = key.rstrip("& ")
                    return key.lower()
                
                existing_keys = set(extract_link_key(l) for l in existing_custom_links)
                new_count = 0
                for link in links:
                    link_key = extract_link_key(link)
                    if link_key not in existing_keys:
                        merged_links.append(link)
                        existing_keys.add(link_key)
                        new_count += 1
                if new_count > 0:
                    logger.info(f"mhnotify: åˆå¹¶åå…± {len(merged_links)} ä¸ªè‡ªå®šä¹‰é“¾æ¥ï¼ˆæ–°å¢ {new_count} ä¸ªï¼‰")
                else:
                    logger.info(f"mhnotify: HDHive é“¾æ¥å·²å­˜åœ¨äºç°æœ‰è‡ªå®šä¹‰é“¾æ¥ä¸­ï¼Œæ— éœ€æ·»åŠ ")
            
            # è®¾ç½® create_payload çš„è‡ªå®šä¹‰é“¾æ¥ï¼ˆç”¨äºæ–°å»ºè®¢é˜…ï¼‰
            if merged_links:
                create_payload["user_custom_links"] = merged_links
            
            # åˆ›å»ºè®¢é˜…ï¼ˆæˆ–å¤ç”¨ç°æœ‰ï¼‰
            mh_uuid = None
            if existing_uuid:
                mh_uuid = existing_uuid
                # å¦‚æœæœ‰æ–°çš„ HDHive é“¾æ¥éœ€è¦æ·»åŠ ï¼Œæ›´æ–°ç°æœ‰è®¢é˜…
                if links and len(merged_links) > len(existing_custom_links):
                    try:
                        update_payload = {"user_custom_links": merged_links}
                        upd_resp = self.__mh_update_subscription(access_token, existing_uuid, update_payload)
                        if upd_resp:
                            logger.info(f"mhnotify: å·²å°†è‡ªå®šä¹‰é“¾æ¥æ›´æ–°åˆ°ç°æœ‰è®¢é˜… {existing_uuid}ï¼ˆå…± {len(merged_links)} ä¸ªï¼‰")
                        else:
                            logger.warning(f"mhnotify: æ›´æ–°ç°æœ‰è®¢é˜…çš„è‡ªå®šä¹‰é“¾æ¥å¤±è´¥")
                    except Exception as e:
                        logger.warning(f"mhnotify: æ›´æ–°ç°æœ‰è®¢é˜…çš„è‡ªå®šä¹‰é“¾æ¥å¼‚å¸¸: {e}")
            else:
                resp = self.__mh_create_subscription(access_token, create_payload)
                mh_uuid = (resp or {}).get("data", {}).get("subscription_id") or (resp or {}).get("data", {}).get("task", {}).get("uuid")
            if not mh_uuid:
                logger.error(f"mhnotify: MHè®¢é˜…åˆ›å»ºå¤±è´¥ï¼š{resp}")
                return
            # ä¸è°ƒåº¦ä¿æŒä¸€è‡´ï¼šé¦–æ¬¡æŸ¥è¯¢å»¶è¿Ÿï¼ˆé»˜è®¤2åˆ†é’Ÿï¼‰
            delay_mins = max(1, int(self._assist_initial_delay_seconds / 60))
            if existing_uuid:
                logger.info(f"mhnotify: å¤ç”¨ç°æœ‰MHè®¢é˜…ï¼Œuuid={mh_uuid}ï¼›{delay_mins}åˆ†é’ŸåæŸ¥è¯¢è¿›åº¦")
                # å¤ç”¨ç°æœ‰è®¢é˜…æ—¶ï¼Œè§¦å‘ç«‹å³æ‰§è¡ŒæŸ¥è¯¢ï¼ˆMHä¸ä¼šè‡ªåŠ¨è§¦å‘ï¼‰
                try:
                    access_token = self.__mh_login()
                    if access_token and self.__mh_execute_subscription(access_token, mh_uuid):
                        logger.info(f"mhnotify: å·²è§¦å‘å¤ç”¨è®¢é˜… {mh_uuid} ç«‹å³æ‰§è¡ŒæŸ¥è¯¢")
                    else:
                        logger.warning(f"mhnotify: è§¦å‘å¤ç”¨è®¢é˜…æ‰§è¡Œå¤±è´¥")
                except Exception as e:
                    logger.warning(f"mhnotify: è§¦å‘å¤ç”¨è®¢é˜…æ‰§è¡Œå¼‚å¸¸: {e}")
            else:
                logger.info(f"mhnotify: å·²åœ¨MHåˆ›å»ºè®¢é˜…ï¼Œuuid={mh_uuid}ï¼›{delay_mins}åˆ†é’ŸåæŸ¥è¯¢è¿›åº¦")
            # è®°å½•å¾…æ£€æŸ¥é¡¹
            pending: Dict[str, dict] = self.get_data(self._ASSIST_PENDING_KEY) or {}
            pending[str(sub_id)] = {
                "mh_uuid": mh_uuid,
                "created_at": int(time.time()),
                "type": (create_payload.get("media_type") or mediainfo_dict.get("type") or "movie")
            }
            self.save_data(self._ASSIST_PENDING_KEY, pending)
        except Exception as e:
            logger.error(f"mhnotify: å¤„ç†æ–°å¢è®¢é˜…äº‹ä»¶å¤±è´¥: {e}")

    # æ—§å±è”½é€»è¾‘ç§»é™¤

    # æ—§å±è”½é€»è¾‘ç§»é™¤

    def __mh_login(self) -> Optional[str]:
        """ç™»å½• MH è·å– access_token"""
        try:
            # ä½¿ç”¨ç¼“å­˜tokenï¼Œé¿å…æ¯åˆ†é’Ÿé‡å¤ç™»å½•
            now_ts = int(time.time())
            if self._mh_token and now_ts < self._mh_token_expire_ts:
                logger.debug("mhnotify: ä½¿ç”¨ç¼“å­˜çš„MH access_token")
                return self._mh_token
            logger.info(f"mhnotify: å‡†å¤‡ç™»å½•MHï¼Œdomain={self._mh_domain}, username={self._mh_username}")
            if not self._mh_domain or not self._mh_username or not self._mh_password:
                logger.error("mhnotify: ç™»å½•MHå¤±è´¥ï¼Œç¼ºå°‘åŸŸåæˆ–ç”¨æˆ·åæˆ–å¯†ç é…ç½®")
                return None
            login_url = f"{self._mh_domain}/api/v1/auth/login"
            payload = {"username": self._mh_username, "password": self._mh_password}
            headers = {
                "Accept": "application/json, text/plain, */*",
                "Content-Type": "application/json;charset=UTF-8",
                "Origin": self._mh_domain,
                "Accept-Language": "zh-CN",
                "User-Agent": "MoviePilot/Plugin MHNotify"
            }
            res = RequestUtils(headers=headers).post(login_url, json=payload)
            if res is None:
                logger.error("mhnotify: ç™»å½•MHæœªè·å–åˆ°ä»»ä½•å“åº”")
            else:
                logger.info(f"mhnotify: ç™»å½•MHå“åº” status={res.status_code}")
            if not res or res.status_code != 200:
                return None
            data = res.json() or {}
            token = (data.get("data") or {}).get("access_token")
            logger.info(f"mhnotify: ç™»å½•MHæˆåŠŸï¼Œaccess_tokenè·å–={'yes' if token else 'no'}")
            if token:
                # å†™å…¥ç¼“å­˜
                self._mh_token = token
                self._mh_token_expire_ts = now_ts + max(60, self._mh_token_ttl_seconds)
            return token
        except Exception:
            logger.error("mhnotify: ç™»å½•MHå‡ºç°å¼‚å¸¸", exc_info=True)
            return None

    def __auth_headers(self, access_token: str) -> Dict[str, str]:
        return {
            "Accept": "application/json, text/plain, */*",
            "Authorization": f"Bearer {access_token}",
            "User-Agent": "MoviePilot/Plugin MHNotify",
            "Accept-Language": "zh-CN"
        }

    def __mh_get_defaults(self, access_token: str) -> Dict[str, Any]:
        try:
            url = f"{self._mh_domain}/api/v1/subscription/config/defaults"
            logger.info(f"mhnotify: è·å–MHé»˜è®¤é…ç½® GET {url}")
            res = RequestUtils(headers=self.__auth_headers(access_token)).get_res(url)
            if res is None:
                logger.error("mhnotify: è·å–MHé»˜è®¤é…ç½®æœªè¿”å›å“åº”")
            elif res.status_code != 200:
                logger.error(f"mhnotify: è·å–MHé»˜è®¤é…ç½®å¤±è´¥ status={res.status_code} body={getattr(res, 'text', '')[:200]}")
            else:
                data = res.json() or {}
                core = (data or {}).get("data") or {}
                logger.info(
                    "mhnotify: é»˜è®¤é…ç½®æ‘˜è¦ cloud_type=%s account=%s target_directory=%s quality_preference=%s",
                    core.get("cloud_type"), core.get("account_identifier"), core.get("target_directory"), core.get("quality_preference")
                )
                return data
        except Exception:
            logger.error("mhnotify: è·å–MHé»˜è®¤é…ç½®å¼‚å¸¸", exc_info=True)
            pass
        return {}

    def __normalize_media_type(self, sub_type: Optional[str], info_type: Optional[str]) -> str:
        try:
            st = (sub_type or "").strip().lower()
            it = (info_type or "").strip().lower() if isinstance(info_type, str) else ""
            movie_alias = {"movie", "mov", "å½±ç‰‡", "ç”µå½±"}
            tv_alias = {"tv", "television", "ç”µè§†å‰§", "å‰§é›†", "series"}
            if st in movie_alias or it in movie_alias:
                return "movie"
            if st in tv_alias or it in tv_alias:
                return "tv"
            # å…œåº•ï¼šä¼˜å…ˆæŒ‰ info_typeï¼Œå…¶æ¬¡æŒ‰ sub_type
            if it in {"movie", "tv"}:
                return it
            return "movie"
        except Exception:
            return "movie"

    def __build_mh_create_payload(self, subscribe, mediainfo_dict: Dict[str, Any], defaults: Dict[str, Any], aggregate_seasons: Optional[List[int]] = None) -> Optional[Dict[str, Any]]:
        try:
            data = (defaults or {}).get("data") or {}
            quality_pref = data.get("quality_preference") or "auto"
            target_dir = data.get("target_directory") or "/å½±è§†"
            cron = data.get("cron") or "0 */6 * * *"
            cloud_type = data.get("cloud_type") or "drive115"
            account_identifier = data.get("account_identifier") or ""
            # å–è®¢é˜…å­—æ®µï¼ˆå…¼å®¹å¯¹è±¡æˆ–å­—å…¸ï¼‰
            def _get(field: str):
                try:
                    if hasattr(subscribe, field):
                        return getattr(subscribe, field)
                    if isinstance(subscribe, dict):
                        return subscribe.get(field)
                except Exception:
                    return None
                return None
            # åª’ä½“ä¿¡æ¯
            tmdb_id = _get('tmdbid') or mediainfo_dict.get('tmdb_id') or mediainfo_dict.get('tmdbid')
            title = _get('name') or mediainfo_dict.get('title')
            sub_type = _get('type')
            info_type = mediainfo_dict.get('type')
            mtype_norm = self.__normalize_media_type(sub_type, info_type)
            release_date = mediainfo_dict.get('release_date')
            overview = mediainfo_dict.get('overview')
            poster_path = mediainfo_dict.get('poster_path')
            vote_average = mediainfo_dict.get('vote_average')
            search_keywords = _get('keyword') or mediainfo_dict.get('search_keywords') or title
            if not title:
                title = mediainfo_dict.get('original_title') or mediainfo_dict.get('name') or "æœªçŸ¥æ ‡é¢˜"
            payload: Dict[str, Any] = {
                "tmdb_id": tmdb_id,
                "title": title,
                "original_title": mediainfo_dict.get('original_title'),
                "media_type": mtype_norm,
                "release_date": release_date,
                "overview": overview,
                "poster_path": poster_path,
                "vote_average": vote_average,
                "search_keywords": search_keywords,
                "quality_preference": quality_pref,
                "target_directory": target_dir,
                "target_dir_id": "",
                "target_path": "",
                "cron": cron,
                "cloud_type": cloud_type,
                "account_identifier": account_identifier,
                "custom_name": title,
                "user_custom_links": []
            }
            if payload["media_type"] == "tv":
                logger.info(f"mhnotify: è§£æå­£ä¿¡æ¯: event.season={mediainfo_dict.get('season')} subscribe.season={_get('season')}")
                # èšåˆå­£ä¿¡æ¯ï¼šè‹¥æä¾› aggregate_seasonsï¼Œåˆ™ä½¿ç”¨å…¶ä½œä¸ºè®¢é˜…çš„å­£é›†åˆ
                if aggregate_seasons:
                    # å»é‡å¹¶æ’åº
                    seasons = sorted({int(s) for s in aggregate_seasons if s is not None}) or [1]
                    src = "èšåˆ"
                else:
                    # ä»äº‹ä»¶æˆ–è®¢é˜…ä¸­è§£æå­£å·ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æ•°å­—ï¼‰ï¼›å¤±è´¥åˆ™ä»æ ‡é¢˜è§£æï¼›ä»å¤±è´¥åˆ™é»˜è®¤1
                    raw_season = mediainfo_dict.get('season') or _get('season')
                    def _to_int(v):
                        if isinstance(v, int):
                            return v
                        if isinstance(v, str) and v.isdigit():
                            return int(v)
                        return None
                    season_num = _to_int(raw_season)
                    src = "äº‹ä»¶/è®¢é˜…"
                    if not season_num:
                        season_num = self.__extract_season_from_text(title or '')
                        src = "æ ‡é¢˜è§£æ" if season_num else "é»˜è®¤1"
                    season_num = season_num or 1
                    seasons = [season_num]
                payload["selected_seasons"] = seasons
                payload["episode_ranges"] = {str(s): {"min_episode": None, "max_episode": None, "exclude_episodes": [], "exclude_text": ""} for s in seasons}
                logger.info(f"mhnotify: TVè®¢é˜…å­£é€‰å®š: {seasons}; æ¥æº={src}")
            else:
                payload["selected_seasons"] = []
            # æ—¥å¿—æ‘˜è¦
            logger.info(
                "mhnotify: æ„å»ºMHè®¢é˜…åˆ›å»ºå‚æ•° tmdb_id=%s title=%s media_type=%s target_dir=%s cloud_type=%s account=%s",
                payload.get("tmdb_id"), payload.get("title"), payload.get("media_type"), target_dir, cloud_type, account_identifier
            )
            return payload
        except Exception:
            logger.error("mhnotify: __build_mh_create_payload å¼‚å¸¸ï¼Œsubscribeæˆ–mediainfoç¼ºå¤±å…³é”®å­—æ®µ")
            return None

    def __extract_season_from_text(self, text: str) -> Optional[int]:
        """ä»æ ‡é¢˜/æ–‡æœ¬ä¸­è§£æå­£å·ï¼Œæ”¯æŒä¸­æ–‡ä¸è‹±æ–‡å¸¸è§æ ¼å¼
        ä¾‹ï¼š"ç¬¬äºŒå­£"ã€"ç¬¬2å­£"ã€"Season 2"ã€"S02"ã€"2å­£"ã€"ç¬¬åå­£"ã€"ç¬¬åä¸€å­£"
        è¿”å›æ­£æ•´æ•°ï¼›æ— æ³•è§£æè¿”å› None
        """
        if not text:
            return None
        try:
            t = text.strip()
            # è‹±æ–‡æ ¼å¼ Season X / SXX
            m = re.search(r"(?:Season\s*)(\d{1,2})", t, re.IGNORECASE)
            if m:
                return int(m.group(1))
            m = re.search(r"\bS(\d{1,2})\b", t, re.IGNORECASE)
            if m:
                return int(m.group(1))
            # ä¸­æ–‡æ ¼å¼ ç¬¬Xå­£ / Xå­£
            m = re.search(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶ã€‡ä¸¤\d]{1,3})å­£", t)
            if m:
                num = m.group(1)
                return self.__parse_chinese_numeral(num)
            m = re.search(r"([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶ã€‡ä¸¤\d]{1,3})å­£", t)
            if m:
                num = m.group(1)
                return self.__parse_chinese_numeral(num)
            # å…¶å®ƒï¼šç¬¬XæœŸ/éƒ¨ æœ‰æ—¶ä¹ŸæŒ‡å­£ï¼ˆå°½é‡è§£æä½†ä¸å¼ºåˆ¶ä½¿ç”¨ï¼‰
            m = re.search(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶ã€‡ä¸¤\d]{1,3})(?:æœŸ|éƒ¨)", t)
            if m:
                num = m.group(1)
                val = self.__parse_chinese_numeral(num)
                return val if val and val > 0 else None
        except Exception:
            pass
        return None

    def __parse_chinese_numeral(self, s: str) -> Optional[int]:
        """è§£æä¸­æ–‡æ•°å­—åˆ°æ•´æ•°ï¼Œæ”¯æŒåˆ° 99 å·¦å³ï¼›ä¹Ÿæ”¯æŒçº¯æ•°å­—å­—ç¬¦ä¸²"""
        if not s:
            return None
        try:
            if s.isdigit():
                return int(s)
            mapping = {
                'é›¶': 0, 'ã€‡': 0,
                'ä¸€': 1, 'äºŒ': 2, 'ä¸¤': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
                'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9,
                'å': 10
            }
            total = 0
            # å¤„ç†åƒ "åä¸€"ã€"äºŒå"ã€"äºŒåä¸€"
            if 'å' in s:
                parts = s.split('å')
                if parts[0] == '':
                    total += 10
                else:
                    total += mapping.get(parts[0], 0) * 10
                if len(parts) > 1 and parts[1] != '':
                    total += mapping.get(parts[1], 0)
                return total if total > 0 else None
            # å•å­—æ•°å­—
            return mapping.get(s, None)
        except Exception:
            return None

    def __mh_create_subscription(self, access_token: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        try:
            url = f"{self._mh_domain}/api/v1/subscription/create"
            headers = self.__auth_headers(access_token)
            headers.update({"Content-Type": "application/json;charset=UTF-8", "Origin": self._mh_domain})
            logger.info(f"mhnotify: åˆ›å»ºMHè®¢é˜… POST {url} media_type={payload.get('media_type')} tmdb_id={payload.get('tmdb_id')} title={str(payload.get('title'))[:50]}")
            # å¢åŠ æ˜¾å¼è¶…æ—¶ä¸å°æ¬¡æ•°é‡è¯•ï¼Œç¼“è§£ç¬æ—¶ç½‘ç»œæŠ–åŠ¨
            timeout_seconds = 30
            max_retries = 2  # æ€»å…±å°è¯• 1+2 æ¬¡
            for attempt in range(1, max_retries + 2):
                res = RequestUtils(headers=headers, timeout=timeout_seconds).post(url, json=payload)
                if res is None:
                    logger.error(f"mhnotify: åˆ›å»ºMHè®¢é˜…æœªè¿”å›å“åº”ï¼ˆç¬¬{attempt}æ¬¡ï¼Œå¯èƒ½è¶…æ—¶{timeout_seconds}sï¼‰")
                elif res.status_code not in (200, 204):
                    body_text = getattr(res, 'text', '')
                    logger.error(f"mhnotify: åˆ›å»ºMHè®¢é˜…å¤±è´¥ï¼ˆç¬¬{attempt}æ¬¡ï¼‰ status={res.status_code} body={body_text[:200]}")
                    # å¦‚æœå·²å­˜åœ¨ç›¸åŒé…ç½®çš„è®¢é˜…ï¼Œå°è¯•æŸ¥è¯¢å¹¶å¤ç”¨
                    try:
                        if res.status_code == 400 and ('å·²å­˜åœ¨ç›¸åŒé…ç½®' in body_text or 'already exists' in body_text.lower()):
                            lst = self.__mh_list_subscriptions(access_token)
                            subs = (lst.get("data") or {}).get("subscriptions") or []
                            cand_uuid = None
                            want_tmdb = payload.get('tmdb_id')
                            want_type = (payload.get('media_type') or '').lower()
                            want_seasons = set(payload.get('selected_seasons') or [])
                            for rec in subs:
                                params = rec.get('params') or {}
                                if params.get('tmdb_id') == want_tmdb and (params.get('media_type') or '').lower() == want_type:
                                    try:
                                        cur_seasons = set(int(x) for x in (params.get('selected_seasons') or []))
                                    except Exception:
                                        cur_seasons = set()
                                    if not want_seasons or cur_seasons == want_seasons:
                                        cand_uuid = rec.get('uuid') or rec.get('task', {}).get('uuid')
                                        break
                            if cand_uuid:
                                logger.info(f"mhnotify: å¤ç”¨å·²å­˜åœ¨çš„MHè®¢é˜… uuid={cand_uuid}")
                                return {"data": {"subscription_id": cand_uuid, "task": {"uuid": cand_uuid}}}
                    except Exception:
                        logger.warning("mhnotify: æ£€ç´¢å·²å­˜åœ¨çš„MHè®¢é˜…å¤±è´¥", exc_info=True)
                else:
                    data = res.json() or {}
                    uuid = (data.get("data") or {}).get("subscription_id") or (data.get("data") or {}).get("task", {}).get("uuid")
                    logger.info(f"mhnotify: åˆ›å»ºMHè®¢é˜…æˆåŠŸ uuid={uuid}")
                    return data
                # è¿˜æœ‰é‡è¯•æ¬¡æ•°æ—¶ï¼Œè¿›è¡ŒæŒ‡æ•°çº§çŸ­æš‚åœé¡¿
                if attempt <= max_retries:
                    time.sleep(2 * attempt)
        except Exception:
            logger.error("mhnotify: åˆ›å»ºMHè®¢é˜…å¼‚å¸¸", exc_info=True)
            pass
        return {}

    def __mh_list_subscriptions(self, access_token: str) -> Dict[str, Any]:
        try:
            url = f"{self._mh_domain}/api/v1/subscription/list?page=1&page_size=2000"
            logger.info(f"mhnotify: æŸ¥è¯¢MHè®¢é˜…åˆ—è¡¨ GET {url}")
            res = RequestUtils(headers=self.__auth_headers(access_token)).get_res(url)
            if res is None:
                logger.error("mhnotify: æŸ¥è¯¢MHè®¢é˜…åˆ—è¡¨æœªè¿”å›å“åº”")
            elif res.status_code != 200:
                logger.error(f"mhnotify: æŸ¥è¯¢MHè®¢é˜…åˆ—è¡¨å¤±è´¥ status={res.status_code} body={getattr(res, 'text', '')[:200]}")
            else:
                data = res.json() or {}
                subs = (data.get("data") or {}).get("subscriptions") or []
                logger.info(f"mhnotify: æŸ¥è¯¢MHè®¢é˜…åˆ—è¡¨æˆåŠŸ count={len(subs)}")
                return data
        except Exception:
            logger.error("mhnotify: æŸ¥è¯¢MHè®¢é˜…åˆ—è¡¨å¼‚å¸¸", exc_info=True)
            pass
        return {}

    def __mh_delete_subscription(self, access_token: str, uuid: str) -> bool:
        try:
            url = f"{self._mh_domain}/api/v1/subscription/{uuid}"
            headers = self.__auth_headers(access_token)
            headers.update({"Origin": self._mh_domain})
            logger.info(f"mhnotify: åˆ é™¤MHè®¢é˜… DELETE {url}")
            res = RequestUtils(headers=headers).delete_res(url)
            ok = bool(res and res.status_code in (200, 204))
            if res is None:
                logger.error("mhnotify: åˆ é™¤MHè®¢é˜…æœªè¿”å›å“åº”")
            else:
                logger.info(f"mhnotify: åˆ é™¤MHè®¢é˜…å“åº” status={res.status_code} ok={ok}")
            return ok
        except Exception:
            logger.error("mhnotify: åˆ é™¤MHè®¢é˜…å¼‚å¸¸", exc_info=True)
            return False

    def __mh_update_subscription(self, access_token: str, uuid: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°MHè®¢é˜…ï¼ˆä¿®æ”¹å­£é›†åˆç­‰å‚æ•°ï¼‰
        å…¼å®¹ç¤ºä¾‹ï¼šPUT /api/v1/subscription/{uuid}ï¼Œbody åŒ…å« name/cron/params
        params ä¸­åŒ…å« selected_seasons ä¸ episode_ranges ä»¥åŠå…¶ä»–å­—æ®µ
        """
        try:
            url = f"{self._mh_domain}/api/v1/subscription/{uuid}"
            headers = self.__auth_headers(access_token)
            headers.update({"Content-Type": "application/json;charset=UTF-8", "Origin": self._mh_domain})
            # ç»„è£…æ›´æ–°ä½“ï¼šå°½é‡å¤ç”¨åˆ›å»ºå‚æ•°ä½œä¸º paramsï¼Œç¡®ä¿å­—æ®µå®Œæ•´
            update_body = {
                "name": f"[è®¢é˜…] {payload.get('title')}",
                "cron": payload.get("cron") or "0 */6 * * *",
                "params": payload
            }
            logger.info(f"mhnotify: æ›´æ–°MHè®¢é˜… PUT {url} seasons={payload.get('selected_seasons')}")
            res = RequestUtils(headers=headers, timeout=30).put_res(url, json=update_body)
            if res is None:
                logger.error("mhnotify: æ›´æ–°MHè®¢é˜…æœªè¿”å›å“åº”")
            elif res.status_code not in (200, 204):
                logger.error(f"mhnotify: æ›´æ–°MHè®¢é˜…å¤±è´¥ status={res.status_code} body={getattr(res, 'text', '')[:200]}")
            else:
                data = res.json() or {}
                logger.info("mhnotify: æ›´æ–°MHè®¢é˜…æˆåŠŸ")
                return data
        except Exception:
            logger.error("mhnotify: æ›´æ–°MHè®¢é˜…å¼‚å¸¸", exc_info=True)
        return {}

    def __mh_execute_subscription(self, access_token: str, uuid: str) -> bool:
        """è§¦å‘MHè®¢é˜…ç«‹å³æ‰§è¡ŒæŸ¥è¯¢
        POST /api/v1/subscription/{uuid}/execute
        """
        try:
            url = f"{self._mh_domain}/api/v1/subscription/{uuid}/execute"
            headers = self.__auth_headers(access_token)
            headers.update({"Content-Length": "0", "Origin": self._mh_domain})
            logger.info(f"mhnotify: è§¦å‘MHè®¢é˜…æ‰§è¡Œ POST {url}")
            res = RequestUtils(headers=headers, timeout=30).post_res(url)
            if res is None:
                logger.error("mhnotify: è§¦å‘MHè®¢é˜…æ‰§è¡Œæœªè¿”å›å“åº”")
                return False
            elif res.status_code != 200:
                logger.error(f"mhnotify: è§¦å‘MHè®¢é˜…æ‰§è¡Œå¤±è´¥ status={res.status_code} body={getattr(res, 'text', '')[:200]}")
                return False
            else:
                data = res.json() or {}
                logger.info(f"mhnotify: è§¦å‘MHè®¢é˜…æ‰§è¡ŒæˆåŠŸï¼š{data.get('message', '')}")
                return True
        except Exception:
            logger.error("mhnotify: è§¦å‘MHè®¢é˜…æ‰§è¡Œå¼‚å¸¸", exc_info=True)
        return False

    def __compute_progress(self, sub_rec: Dict[str, Any]) -> Tuple[str, int, int]:
        """è¿”å› (media_type, saved, expected_total)"""
        params = (sub_rec or {}).get("params") or {}
        mtype = (params.get("media_type") or (sub_rec.get("subscription_info") or {}).get("media_type") or "movie").lower()
        saved = int(params.get("saved_resources") or (sub_rec.get("params") or {}).get("saved_resources") or (sub_rec.get("saved_resources") if isinstance(sub_rec.get("saved_resources"), int) else 0))
        # episodes_count åœ¨ episodes[0].episodes_count
        expected_total = 1 if mtype == 'movie' else 0
        try:
            episodes = (sub_rec.get("episodes") or [])
            if episodes:
                counts = (episodes[0] or {}).get("episodes_count") or {}
                if mtype == 'tv':
                    for s in counts.values():
                        expected_total += int(s.get("count") or 0)
                else:
                    # movie: å¦‚æœå­˜åœ¨ä¹ŸæŒ‰1å¤„ç†
                    expected_total = 1
        except Exception:
            pass
        return mtype, saved, expected_total

    def __assist_scheduler(self):
        """æ¯åˆ†é’Ÿæ‰§è¡Œï¼šå…ˆç­‰å¾…2åˆ†é’Ÿè¿›è¡Œé¦–æ¬¡æŸ¥è¯¢ï¼›æœªæŸ¥è¯¢åˆ°åˆ™æ¯1åˆ†é’Ÿé‡è¯•ï¼Œç›´åˆ°æŸ¥è¯¢åˆ°ï¼›å¹¶å¤„ç†MPå®Œæˆç›‘å¬"""
        try:
            # å¤„ç†å¾…æ£€æŸ¥
            pending: Dict[str, dict] = self.get_data(self._ASSIST_PENDING_KEY) or {}
            if pending:
                now_ts = int(time.time())
                # æ”¶é›†å·²åˆ°æŸ¥è¯¢æ—¶é—´çš„æ¡ç›®ï¼ˆé¦–æ¬¡æŸ¥è¯¢å»¶è¿Ÿï¼‰
                matured_items = {sid: info for sid, info in pending.items() if now_ts - int(info.get("created_at") or 0) >= self._assist_initial_delay_seconds}
                if matured_items:
                    token = self.__mh_login()
                    if not token:
                        logger.error("mhnotify: ç™»å½•MHå¤±è´¥ï¼Œæ— æ³•æŸ¥è¯¢è®¢é˜…è¿›åº¦")
                    else:
                        lst = self.__mh_list_subscriptions(token)
                        subs = (lst.get("data") or {}).get("subscriptions") or []
                        subs_map = {}
                        for rec in subs:
                            uid = rec.get("uuid") or rec.get("task", {}).get("uuid")
                            if uid:
                                subs_map[uid] = rec
                        for sid, info in list(matured_items.items()):
                            mh_uuid = info.get("mh_uuid")
                            target = subs_map.get(mh_uuid)
                            if not target:
                                # æœªæ‰¾åˆ°ï¼Œè®°å½•é‡è¯•æ¬¡æ•°ï¼Œè¶…è¿‡30æ¬¡åˆ™ç§»é™¤è®°å½•
                                attempts = int(info.get("attempts") or 0) + 1
                                info["attempts"] = attempts
                                info["last_attempt"] = now_ts
                                if attempts >= 30:
                                    logger.warning(f"mhnotify: è®¢é˜… {mh_uuid} æœªåœ¨MHåˆ—è¡¨ä¸­æ‰¾åˆ°ï¼Œå·²é‡è¯•{attempts}æ¬¡ï¼Œç§»é™¤è®°å½•")
                                    pending.pop(sid, None)
                                    self.save_data(self._ASSIST_PENDING_KEY, pending)
                                    continue
                                else:
                                    retry_mins = max(1, int(self._assist_retry_interval_seconds / 60))
                                    logger.warning(f"mhnotify: æœªåœ¨MHåˆ—è¡¨ä¸­æ‰¾åˆ°è®¢é˜… {mh_uuid}ï¼Œç¬¬{attempts}æ¬¡é‡è¯•ï¼Œ{retry_mins}åˆ†é’Ÿåç»§ç»­")
                                    pending[str(sid)] = info
                                    self.save_data(self._ASSIST_PENDING_KEY, pending)
                                    continue
                            mtype, saved, expected = self.__compute_progress(target)
                            logger.info(f"mhnotify: è®¢é˜… {mh_uuid} è¿›åº¦ saved={saved}/{expected} type={mtype}")
                            with SessionFactory() as db:
                                subscribe = SubscribeOper(db=db).get(int(sid))
                            if not subscribe:
                                # MPè®¢é˜…å·²ä¸å­˜åœ¨ï¼ˆå¯èƒ½ä¸ºå–æ¶ˆå•å­£ï¼‰
                                # ä¼˜å…ˆå°è¯•ï¼šæŒ‰åŒ TMDB çš„å‰©ä½™å­£æ›´æ–° MH è®¢é˜…ï¼›è‹¥æ— å‰©ä½™å­£åˆ™åˆ é™¤ MH
                                try:
                                    del_token = self.__mh_login()
                                except Exception:
                                    del_token = None
                                if del_token and mh_uuid:
                                    try:
                                        lst2 = self.__mh_list_subscriptions(del_token)
                                        subs2 = (lst2.get("data") or {}).get("subscriptions") or []
                                        rec2 = None
                                        for r in subs2:
                                            uid2 = r.get("uuid") or (r.get("task") or {}).get("uuid")
                                            if uid2 == mh_uuid:
                                                rec2 = r
                                                break
                                        tmdb_id = None
                                        if rec2:
                                            params2 = rec2.get("params") or {}
                                            tmdb_id = params2.get("tmdb_id")
                                        remaining_seasons: List[int] = []
                                        if tmdb_id:
                                            try:
                                                with SessionFactory() as db2:
                                                    all_subs = SubscribeOper(db=db2).list_by_tmdbid(tmdb_id)
                                                seasons = []
                                                for s in all_subs or []:
                                                    try:
                                                        stype = (getattr(s, 'type', '') or '').strip()
                                                        stype_lower = (stype or '').lower()
                                                        if stype_lower == 'tv' or stype in {'ç”µè§†å‰§'}:
                                                            s_season = getattr(s, 'season', None)
                                                            if s_season is None:
                                                                s_season = self.__extract_season_from_text(getattr(s, 'name', '') or '')
                                                            seasons.append(s_season)
                                                    except Exception:
                                                        pass
                                                tmp: List[int] = []
                                                for x in seasons:
                                                    if isinstance(x, int):
                                                        tmp.append(x)
                                                    elif isinstance(x, str) and x.isdigit():
                                                        tmp.append(int(x))
                                                remaining_seasons = sorted({s for s in tmp if isinstance(s, int) and s > 0})
                                            except Exception:
                                                remaining_seasons = []
                                        if remaining_seasons:
                                            # æ›´æ–° MH è®¢é˜…å­£é›†åˆä¸ºå‰©ä½™å­£
                                            try:
                                                base_params = (rec2 or {}).get("params") or {}
                                                base_params["selected_seasons"] = remaining_seasons
                                                base_params["episode_ranges"] = {str(s): {"min_episode": None, "max_episode": None, "exclude_episodes": [], "exclude_text": ""} for s in remaining_seasons}
                                                self.__mh_update_subscription(del_token, mh_uuid, base_params)
                                                logger.info(f"mhnotify: å–æ¶ˆå•å­£åæ›´æ–°MHè®¢é˜… seasons={remaining_seasons}")
                                            except Exception:
                                                logger.warning("mhnotify: æ›´æ–°MHè®¢é˜…å­£é›†åˆå¤±è´¥ï¼Œé™çº§ä¸ºåˆ é™¤", exc_info=True)
                                                self.__mh_delete_subscription(del_token, mh_uuid)
                                        else:
                                            # æ— å‰©ä½™å­£ï¼Œåˆ é™¤ MH è®¢é˜…
                                            self.__mh_delete_subscription(del_token, mh_uuid)
                                    except Exception:
                                        # é™çº§ç­–ç•¥ï¼šå‡ºç°å¼‚å¸¸åˆ™å°½é‡åˆ é™¤å¯¹åº” MH è®¢é˜…ï¼Œé¿å…é—ç•™æ— ä¸»è®¢é˜…
                                        try:
                                            self.__mh_delete_subscription(del_token, mh_uuid)
                                        except Exception:
                                            logger.warning("mhnotify: å¤„ç†å‰©ä½™å­£æ—¶å¼‚å¸¸ä¸”åˆ é™¤å¤±è´¥", exc_info=True)
                                pending.pop(sid, None)
                                self.save_data(self._ASSIST_PENDING_KEY, pending)
                                continue
                            if mtype == 'movie':
                                if expected <= 1 and saved >= 1:
                                    # å®Œæˆï¼šåˆ é™¤MHï¼Œå®ŒæˆMPè®¢é˜…
                                    if token:
                                        self.__mh_delete_subscription(token, mh_uuid)
                                    self.__finish_mp_subscribe(subscribe)
                                    pending.pop(sid, None)
                                    self.save_data(self._ASSIST_PENDING_KEY, pending)
                                else:
                                    # æœªå®Œæˆï¼šæ¢å¤MPè®¢é˜…å¹¶ç›‘å¬MPå®Œæˆååˆ é™¤MH
                                    with SessionFactory() as db:
                                        SubscribeOper(db=db).update(subscribe.id, {"state": "R", "sites": []})
                                    watch: Dict[str, dict] = self.get_data(self._ASSIST_WATCH_KEY) or {}
                                    watch[sid] = {"mh_uuid": mh_uuid}
                                    self.save_data(self._ASSIST_WATCH_KEY, watch)
                                    pending.pop(sid, None)
                                    self.save_data(self._ASSIST_PENDING_KEY, pending)
                            else:
                                # TV
                                if expected > 0 and saved >= expected:
                                    # å®Œæˆï¼šåˆ é™¤MHï¼Œå®ŒæˆMPè®¢é˜…
                                    if token:
                                        self.__mh_delete_subscription(token, mh_uuid)
                                    self.__finish_mp_subscribe(subscribe)
                                    pending.pop(sid, None)
                                    self.save_data(self._ASSIST_PENDING_KEY, pending)
                                else:
                                    # æœªå®Œæˆï¼šä¸åˆ é™¤MHï¼Œå¯ç”¨MPè®¢é˜…ï¼Œå¹¶åŠ å…¥watchç­‰å¾…MPå®Œæˆ/å–æ¶ˆååˆ é™¤MH
                                    with SessionFactory() as db:
                                        SubscribeOper(db=db).update(subscribe.id, {"state": "R", "sites": []})
                                    watch: Dict[str, dict] = self.get_data(self._ASSIST_WATCH_KEY) or {}
                                    watch[sid] = {"mh_uuid": mh_uuid}
                                    self.save_data(self._ASSIST_WATCH_KEY, watch)
                                    pending.pop(sid, None)
                                    self.save_data(self._ASSIST_PENDING_KEY, pending)
            # ç›‘å¬MPå®Œæˆååˆ é™¤MHï¼ˆå¯é€‰ï¼‰
            watch: Dict[str, dict] = self.get_data(self._ASSIST_WATCH_KEY) or {}
            if watch and self._mh_assist_auto_delete:
                for sid, info in list(watch.items()):
                    with SessionFactory() as db:
                        sub = SubscribeOper(db=db).get(int(sid))
                    if not sub:
                        # MPè®¢é˜…ä¸å­˜åœ¨ï¼ˆå–æ¶ˆ/å®Œæˆï¼‰ï¼Œå¤„ç†å¯¹åº”MHï¼šä¼˜å…ˆæ›´æ–°å‰©ä½™å­£ï¼Œå¦åˆ™åˆ é™¤
                        mh_uuid = info.get("mh_uuid")
                        try:
                            del_token = self.__mh_login()
                        except Exception:
                            del_token = None
                        if mh_uuid and del_token:
                            try:
                                lst2 = self.__mh_list_subscriptions(del_token)
                                subs2 = (lst2.get("data") or {}).get("subscriptions") or []
                                rec2 = None
                                for r in subs2:
                                    uid2 = r.get("uuid") or (r.get("task") or {}).get("uuid")
                                    if uid2 == mh_uuid:
                                        rec2 = r
                                        break
                                tmdb_id = None
                                if rec2:
                                    params2 = rec2.get("params") or {}
                                    tmdb_id = params2.get("tmdb_id")
                                remaining_seasons: List[int] = []
                                if tmdb_id:
                                    try:
                                        with SessionFactory() as db2:
                                            all_subs = SubscribeOper(db=db2).list_by_tmdbid(tmdb_id)
                                        seasons = []
                                        for s in all_subs or []:
                                            try:
                                                stype = (getattr(s, 'type', '') or '').strip()
                                                stype_lower = (stype or '').lower()
                                                if stype_lower == 'tv' or stype in {'ç”µè§†å‰§'}:
                                                    s_season = getattr(s, 'season', None)
                                                    if s_season is None:
                                                        s_season = self.__extract_season_from_text(getattr(s, 'name', '') or '')
                                                    seasons.append(s_season)
                                            except Exception:
                                                pass
                                        tmp: List[int] = []
                                        for x in seasons:
                                            if isinstance(x, int):
                                                tmp.append(x)
                                            elif isinstance(x, str) and x.isdigit():
                                                tmp.append(int(x))
                                        remaining_seasons = sorted({s for s in tmp if isinstance(s, int) and s > 0})
                                    except Exception:
                                        remaining_seasons = []
                                if remaining_seasons:
                                    try:
                                        base_params = (rec2 or {}).get("params") or {}
                                        base_params["selected_seasons"] = remaining_seasons
                                        base_params["episode_ranges"] = {str(s): {"min_episode": None, "max_episode": None, "exclude_episodes": [], "exclude_text": ""} for s in remaining_seasons}
                                        self.__mh_update_subscription(del_token, mh_uuid, base_params)
                                        logger.info(f"mhnotify: å–æ¶ˆå•å­£åæ›´æ–°MHè®¢é˜… seasons={remaining_seasons}")
                                    except Exception:
                                        logger.warning("mhnotify: æ›´æ–°MHè®¢é˜…å­£é›†åˆå¤±è´¥ï¼Œé™çº§ä¸ºåˆ é™¤", exc_info=True)
                                        self.__mh_delete_subscription(del_token, mh_uuid)
                                else:
                                    self.__mh_delete_subscription(del_token, mh_uuid)
                            except Exception:
                                # é™çº§ç­–ç•¥ï¼šå‡ºç°å¼‚å¸¸åˆ™å°½é‡åˆ é™¤å¯¹åº” MH è®¢é˜…ï¼Œé¿å…é—ç•™æ— ä¸»è®¢é˜…
                                try:
                                    self.__mh_delete_subscription(del_token, mh_uuid)
                                except Exception:
                                    logger.warning("mhnotify: watch åˆ†æ”¯å¤„ç†å‰©ä½™å­£æ—¶å¼‚å¸¸ä¸”åˆ é™¤å¤±è´¥", exc_info=True)
                        # æ¸…ç†å½“å‰ç›‘å¬é¡¹
                        watch.pop(sid, None)
                        self.save_data(self._ASSIST_WATCH_KEY, watch)
        except Exception as e:
            logger.error(f"mhnotify: åŠ©æ‰‹è°ƒåº¦å¼‚å¸¸: {e}")

    def _clear_all_records(self) -> Dict[str, Any]:
        """æ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•ï¼ˆpending/watchï¼‰ï¼Œç§»é™¤è„æ•°æ®"""
        try:
            self.save_data(self._ASSIST_PENDING_KEY, {})
            self.save_data(self._ASSIST_WATCH_KEY, {})
            logger.info("mhnotify: å·²æ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•ï¼ˆpending/watchï¼‰")
            return {"success": True}
        except Exception as e:
            logger.error(f"mhnotify: æ¸…ç†åŠ©æ‰‹è®¢é˜…è®°å½•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _clear_cloud_download_records(self) -> Dict[str, Any]:
        """æ¸…ç†åŠ©æ‰‹äº‘ä¸‹è½½è®°å½•ï¼ˆé¢„ç•™æ¥å£ï¼‰"""
        try:
            # å½“å‰ç‰ˆæœ¬äº‘ä¸‹è½½ä½¿ç”¨daemonçº¿ç¨‹ï¼Œæ— æŒä¹…åŒ–æ•°æ®éœ€è¦æ¸…ç†
            # æ­¤æ–¹æ³•ä¸ºå°†æ¥å¯èƒ½çš„äº‘ä¸‹è½½è®°å½•åŠŸèƒ½é¢„ç•™æ¥å£
            logger.info("mhnotify: äº‘ä¸‹è½½è®°å½•æ¸…ç†å®Œæˆï¼ˆå½“å‰ç‰ˆæœ¬æ— éœ€æ¸…ç†ï¼‰")
            return {"success": True}
        except Exception as e:
            logger.error(f"mhnotify: æ¸…ç†äº‘ä¸‹è½½è®°å½•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def _add_offline_download(self, url: str, start_monitor: bool = True) -> Tuple[bool, str, Dict[str, Any]]:
        """
        æ·»åŠ 115ç¦»çº¿ä¸‹è½½ä»»åŠ¡
        å‚è€ƒ p115client å®˜æ–¹åº“çš„ P115Offline.add æ–¹æ³•å®ç°
        :param url: ä¸‹è½½é“¾æ¥ï¼ˆç£åŠ›é“¾æ¥ã€ç§å­URLç­‰ï¼‰
        :param start_monitor: æ˜¯å¦å¯åŠ¨åå°ç›‘æ§çº¿ç¨‹ï¼ˆæ‰¹é‡ä¸‹è½½æ—¶è®¾ä¸ºFalseï¼Œç»Ÿä¸€ç›‘æ§ï¼‰
        :return: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯æ–‡æœ¬, ä»»åŠ¡ä¿¡æ¯å­—å…¸)
        """
        task_info = {}  # ç”¨äºè¿”å›ä»»åŠ¡ä¿¡æ¯ï¼Œä¾›æ‰¹é‡å¤„ç†ä½¿ç”¨
        try:
            # å¯¼å…¥p115client
            try:
                from p115client import P115Client
            except ImportError:
                return False, "p115client æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–", task_info

            # åˆ›å»º115å®¢æˆ·ç«¯
            client = P115Client(self._p115_cookie, app="web")
            
            # è·å–æˆ–åˆ›å»ºç›®æ ‡ç›®å½•ID
            target_path = self._cloud_download_path or "/äº‘ä¸‹è½½"
            # æ ‡å‡†åŒ–è·¯å¾„
            target_path = target_path.strip()
            if not target_path.startswith('/'):
                target_path = '/' + target_path
            target_path = target_path.rstrip('/')
            if not target_path:
                target_path = "/"
            
            target_cid = 0
            
            try:
                if target_path != "/":
                    # ä½¿ç”¨ fs_dir_getid è·å–ç›®å½•ID
                    resp = client.fs_dir_getid(target_path)
                    logger.debug(f"mhnotify: fs_dir_getid å“åº”: {resp}")
                    if resp and resp.get("id"):
                        target_cid = int(resp.get("id"))
                        logger.info(f"mhnotify: ç›®æ ‡ç›®å½• {target_path} ID: {target_cid}")
                    elif resp and resp.get("id") == 0:
                        # ç›®å½•ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º
                        logger.info(f"mhnotify: ç›®å½• {target_path} ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º...")
                        mkdir_resp = client.fs_makedirs_app(target_path, pid=0)
                        logger.debug(f"mhnotify: fs_makedirs_app å“åº”: {mkdir_resp}")
                        if mkdir_resp and mkdir_resp.get("cid"):
                            target_cid = int(mkdir_resp.get("cid"))
                            logger.info(f"mhnotify: åˆ›å»ºç›®å½•æˆåŠŸï¼ŒID: {target_cid}")
                        else:
                            logger.warning(f"mhnotify: åˆ›å»ºç›®å½•å¤±è´¥: {mkdir_resp}")
                            target_cid = 0
                    else:
                        logger.warning(f"mhnotify: è·å–ç›®å½•IDå¤±è´¥: {resp}")
                        target_cid = 0
            except Exception as e:
                logger.warning(f"mhnotify: è·å–ç›®å½•IDå¼‚å¸¸: {e}", exc_info=True)
                target_cid = 0

            # æ„å»ºç¦»çº¿ä¸‹è½½payload
            # å‚è€ƒ p115client æºç ï¼šå•ä¸ªURLä½¿ç”¨ "url" é”®ï¼Œè°ƒç”¨ offline_add_url
            download_url = url.strip()
            payload = {"url": download_url}
            if target_cid:
                payload["wp_path_id"] = target_cid
            
            logger.info(f"mhnotify: æ·»åŠ ç¦»çº¿ä¸‹è½½ä»»åŠ¡ï¼Œç›®æ ‡ç›®å½•ID: {target_cid}, URL: {download_url[:80]}...")
            
            # è°ƒç”¨115ç¦»çº¿ä¸‹è½½APIï¼ˆå•ä¸ªURLç”¨ offline_add_urlï¼‰
            resp = client.offline_add_url(payload)
            logger.debug(f"mhnotify: offline_add_url å“åº”: {resp}")
            
            # æ£€æŸ¥å“åº”
            if not resp:
                return False, "115 API å“åº”ä¸ºç©º"
            
            # å“åº”å¯èƒ½æ˜¯dictæˆ–å…¶ä»–ç±»å‹
            if isinstance(resp, dict):
                state = resp.get('state', False)
                
                # è§£æè¿”å›çš„ä»»åŠ¡ä¿¡æ¯ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œdataä¸­å¯èƒ½éƒ½æœ‰info_hashï¼‰
                data = resp.get('data', {})
                if isinstance(data, dict):
                    info_hash = data.get('info_hash', '')
                    task_name = data.get('name', '')
                    files_list = data.get('files', [])
                else:
                    info_hash = ''
                    task_name = ''
                    files_list = []
                
                if not state:
                    error_msg = resp.get('error_msg', '') or resp.get('error', 'æœªçŸ¥é”™è¯¯')
                    error_code = resp.get('errcode', '')
                    
                    # ç‰¹æ®Šå¤„ç†é”™è¯¯ç 10008ï¼šä»»åŠ¡å·²å­˜åœ¨
                    if error_code == 10008:
                        logger.warning(f"mhnotify: ç¦»çº¿ä¸‹è½½ä»»åŠ¡å·²å­˜åœ¨: {info_hash}")
                        
                        # æ„é€ è¯¦ç»†çš„æç¤ºä¿¡æ¯
                        exist_msg = "âš ï¸ äº‘ä¸‹è½½ä»»åŠ¡å·²å­˜åœ¨\n"
                        exist_msg += f"é”™è¯¯ä¿¡æ¯: {error_msg}\n"
                        if info_hash:
                            exist_msg += f"ä»»åŠ¡Hash: {info_hash[:16]}...\n"
                        if files_list:
                            exist_msg += f"åŒ…å«æ–‡ä»¶: {len(files_list)} ä¸ª\n"
                            # æ˜¾ç¤ºä¸»è¦æ–‡ä»¶åï¼ˆè·³è¿‡å°å›¾ç‰‡ï¼‰
                            main_files = [f for f in files_list if f.get('size', 0) > 10*1024*1024]
                            if main_files:
                                exist_msg += f"ä¸»è¦æ–‡ä»¶: {main_files[0].get('name', 'æœªçŸ¥')[:50]}...\n"
                        exist_msg += f"ä¿å­˜è·¯å¾„: {target_path}\n"
                        exist_msg += "\nâ„¹ï¸ ä»»åŠ¡å·²å­˜åœ¨ï¼Œè¯·åœ¨115ç½‘ç›˜æŸ¥çœ‹ä¸‹è½½è¿›åº¦"
                        
                        # ä»»åŠ¡å·²å­˜åœ¨æ—¶ä¸å¯åŠ¨ç›‘æ§çº¿ç¨‹ï¼Œé¿å…é‡å¤ç›‘æ§
                        # ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨åœ¨115ç½‘ç›˜æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
                        
                        return True, exist_msg, task_info
                    else:
                        # å…¶ä»–é”™è¯¯
                        logger.error(f"mhnotify: ç¦»çº¿ä¸‹è½½å¤±è´¥ï¼Œå“åº”: {resp}")
                        fail_msg = f"âŒ æ·»åŠ å¤±è´¥\n"
                        fail_msg += f"é”™è¯¯ä¿¡æ¯: {error_msg}\n"
                        fail_msg += f"é”™è¯¯ç : {error_code}"
                        if info_hash:
                            fail_msg += f"\nHash: {info_hash[:16]}..."
                        return False, fail_msg, task_info
                
                # æˆåŠŸæ·»åŠ 
                # å•ä¸ªURLè¿”å›çš„ç»“æ„å¯èƒ½ä¸åŒ
                
                if not task_name:
                    # å°è¯•ä»å…¶ä»–å­—æ®µè·å–
                    task_name = data.get('file_name', '') or data.get('title', '') or 'ä»»åŠ¡å·²æ·»åŠ '
                
                success_msg = f"ä»»åŠ¡å·²æ·»åŠ åˆ°115äº‘ä¸‹è½½\n"
                if task_name:
                    success_msg += f"ä»»åŠ¡åç§°: {task_name}\n"
                success_msg += f"ä¿å­˜è·¯å¾„: {target_path}"
                if info_hash:
                    success_msg += f"\nHash: {info_hash[:16]}..."
                
                logger.info(f"mhnotify: 115ç¦»çº¿ä¸‹è½½ä»»åŠ¡æ·»åŠ æˆåŠŸ: {task_name or info_hash or 'æœªçŸ¥'}")
                
                # å¡«å……ä»»åŠ¡ä¿¡æ¯ï¼Œä¾›æ‰¹é‡å¤„ç†ä½¿ç”¨
                task_info = {
                    "client": client,
                    "info_hash": info_hash,
                    "target_cid": target_cid,
                    "task_name": task_name,
                    "target_path": target_path
                }
                
                # å¦‚æœå¼€å¯äº†å‰”é™¤å°æ–‡ä»¶æˆ–ç§»åŠ¨æ•´ç†åŠŸèƒ½ï¼Œä¸”éœ€è¦å¯åŠ¨ç›‘æ§
                if (self._cloud_download_remove_small_files or self._cloud_download_organize) and info_hash and start_monitor:
                    try:
                        if self._cloud_download_remove_small_files:
                            logger.info(f"mhnotify: äº‘ä¸‹è½½å‰”é™¤å°æ–‡ä»¶å·²å¯ç”¨ï¼Œå°†ç­‰å¾…ä»»åŠ¡å®Œæˆåå¤„ç†...")
                        if self._cloud_download_organize:
                            logger.info(f"mhnotify: äº‘ä¸‹è½½ç§»åŠ¨æ•´ç†å·²å¯ç”¨ï¼Œå°†ç­‰å¾…ä»»åŠ¡å®Œæˆåå¤„ç†...")
                        
                        # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡ç›‘æ§ä¸‹è½½å®Œæˆå¹¶å¤„ç†
                        import threading
                        threading.Thread(
                            target=self._monitor_and_remove_small_files,
                            args=(client, info_hash, target_cid, task_name, target_path),
                            daemon=True
                        ).start()
                    except Exception as e:
                        logger.warning(f"mhnotify: å¯åŠ¨åå¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
                
                return True, success_msg, task_info
            else:
                # å¯èƒ½è¿”å›çš„æ˜¯å…¶ä»–ç±»å‹
                logger.info(f"mhnotify: ç¦»çº¿ä¸‹è½½å“åº”ç±»å‹: {type(resp)}, å†…å®¹: {resp}")
                return True, f"ä»»åŠ¡å·²æäº¤åˆ°115äº‘ä¸‹è½½\nä¿å­˜è·¯å¾„: {target_path}", task_info
            
        except ImportError as e:
            logger.error(f"mhnotify: å¯¼å…¥p115clientå¤±è´¥: {e}")
            return False, f"ä¾èµ–åº“å¯¼å…¥å¤±è´¥: {str(e)}", task_info
        except Exception as e:
            logger.error(f"mhnotify: æ·»åŠ 115ç¦»çº¿ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            return False, f"æ·»åŠ å¤±è´¥: {str(e)}", task_info

    def _monitor_batch_downloads(self, tasks: List[Dict[str, Any]]):
        """
        æ‰¹é‡ç›‘æ§å¤šä¸ªç¦»çº¿ä¸‹è½½ä»»åŠ¡ï¼Œç­‰å¾…å…¨éƒ¨å®Œæˆåç»Ÿä¸€æ¸…ç†å’Œæ•´ç†
        å¦‚æœæŸä¸ªä»»åŠ¡10åˆ†é’Ÿå†…ä»åœ¨ä¸‹è½½ä¸­ï¼Œå°†å…¶ç‹¬ç«‹å‡ºå»å•ç‹¬ç›‘æ§
        :param tasks: ä»»åŠ¡ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« client, info_hash, target_cid, task_name, target_path
        """
        import time
        import threading
        
        if not tasks:
            return
        
        logger.info(f"mhnotify: å¼€å§‹æ‰¹é‡ç›‘æ§ {len(tasks)} ä¸ªç¦»çº¿ä¸‹è½½ä»»åŠ¡")
        
        # ç­‰å¾…15ç§’ï¼Œè®©ä»»åŠ¡è¿›å…¥ä¸‹è½½é˜Ÿåˆ—
        logger.info(f"mhnotify: ç­‰å¾…15ç§’ï¼Œè®©ä»»åŠ¡è¿›å…¥ä¸‹è½½é˜Ÿåˆ—...")
        time.sleep(15)
        
        # ä»»åŠ¡çŠ¶æ€è·Ÿè¸ª
        task_status = {}  # info_hash -> {"completed": bool, "success": bool, "actual_cid": int, "is_directory": bool, "split_out": bool}
        task_first_seen_downloading = {}  # info_hash -> é¦–æ¬¡å‘ç°åœ¨ä¸‹è½½ä¸­çš„æ—¶é—´æˆ³
        
        for task in tasks:
            task_status[task["info_hash"]] = {
                "completed": False,
                "success": False,
                "actual_cid": task["target_cid"],
                "is_directory": False,
                "task_name": task["task_name"],
                "split_out": False  # æ˜¯å¦å·²è¢«ç‹¬ç«‹å‡ºå»
            }
        
        client = tasks[0]["client"]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªä»»åŠ¡çš„client
        target_path = tasks[0]["target_path"]  # å‡è®¾æ‰€æœ‰ä»»åŠ¡ä¿å­˜åˆ°åŒä¸€ç›®å½•
        
        # è¶…æ—¶é…ç½®
        split_timeout = 600  # 10åˆ†é’Ÿåå°†æ…¢ä»»åŠ¡ç‹¬ç«‹å‡ºå»
        check_interval = 30  # æ£€æŸ¥é—´éš”ï¼š30ç§’ï¼ˆä¸ºäº†æ›´å¿«æ£€æµ‹è¶…æ—¶ï¼‰
        max_checks = 1440  # æœ€å¤šæ£€æŸ¥12å°æ—¶ï¼ˆ30ç§’ * 1440 = 12å°æ—¶ï¼‰
        
        # ========== ç¬¬ä¸€é˜¶æ®µï¼šç›‘æ§æ‰€æœ‰ä»»åŠ¡ä¸‹è½½å®Œæˆ ==========
        logger.info(f"mhnotify: ç¬¬ä¸€é˜¶æ®µ - ç›‘æ§æ‰€æœ‰ä»»åŠ¡ä¸‹è½½çŠ¶æ€ï¼ˆ10åˆ†é’Ÿè¶…æ—¶åç‹¬ç«‹æ…¢ä»»åŠ¡ï¼‰...")
        
        for check_round in range(max_checks):
            all_done = True  # æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆæˆ–è¢«ç‹¬ç«‹å‡ºå»
            current_time = time.time()
            
            for task in tasks:
                info_hash = task["info_hash"]
                status = task_status[info_hash]
                
                # å·²å®Œæˆæˆ–å·²ç‹¬ç«‹å‡ºå»çš„ä»»åŠ¡è·³è¿‡
                if status["completed"] or status["split_out"]:
                    continue
                
                all_done = False
                
                try:
                    # å…ˆæŸ¥æ­£åœ¨ä¸‹è½½åˆ—è¡¨
                    downloading_task = self._query_downloading_task_by_hash(client, info_hash)
                    
                    if downloading_task and downloading_task.get('status', 0) == 1:
                        # ä»åœ¨ä¸‹è½½ä¸­
                        percent = downloading_task.get('percentDone', 0)
                        
                        # è®°å½•é¦–æ¬¡å‘ç°ä¸‹è½½ä¸­çš„æ—¶é—´
                        if info_hash not in task_first_seen_downloading:
                            task_first_seen_downloading[info_hash] = current_time
                            logger.info(f"mhnotify: ä»»åŠ¡å¼€å§‹ä¸‹è½½: {task['task_name']}")
                        
                        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡10åˆ†é’Ÿ
                        downloading_duration = current_time - task_first_seen_downloading[info_hash]
                        if downloading_duration >= split_timeout:
                            # è¶…è¿‡10åˆ†é’Ÿï¼Œç‹¬ç«‹å‡ºå»å•ç‹¬ç›‘æ§
                            logger.info(f"mhnotify: ä»»åŠ¡ {task['task_name']} ä¸‹è½½è¶…è¿‡10åˆ†é’Ÿï¼ˆ{percent:.1f}%ï¼‰ï¼Œç‹¬ç«‹å‡ºå»å•ç‹¬ç›‘æ§")
                            status["split_out"] = True
                            
                            # å¯åŠ¨ç‹¬ç«‹çš„ç›‘æ§çº¿ç¨‹
                            threading.Thread(
                                target=self._monitor_and_remove_small_files,
                                args=(client, info_hash, task["target_cid"], task["task_name"], task["target_path"]),
                                daemon=True
                            ).start()
                        else:
                            # æ¯2åˆ†é’Ÿè®°å½•ä¸€æ¬¡è¿›åº¦
                            if check_round % 4 == 0:
                                remaining = int((split_timeout - downloading_duration) / 60)
                                logger.info(f"mhnotify: æ­£åœ¨ä¸‹è½½: {task['task_name']} - {percent:.1f}%ï¼ˆ{remaining}åˆ†é’Ÿåç‹¬ç«‹ï¼‰")
                        continue
                    
                    # ä¸åœ¨ä¸‹è½½åˆ—è¡¨ï¼ŒæŸ¥å·²å®Œæˆåˆ—è¡¨
                    current_task = self._query_offline_task_by_hash(client, info_hash)
                    
                    if current_task and isinstance(current_task, dict):
                        task_api_status = current_task.get('status', 0)
                        if task_api_status == 2:
                            # å·²å®Œæˆ
                            status["completed"] = True
                            status["success"] = True
                            actual_cid = current_task.get('file_id', '')
                            if actual_cid:
                                try:
                                    status["actual_cid"] = int(actual_cid)
                                except:
                                    pass
                            file_category = current_task.get('file_category', 1)
                            status["is_directory"] = (file_category == 0)
                            logger.info(f"mhnotify: ä»»åŠ¡å·²å®Œæˆ: {task['task_name']}")
                        elif task_api_status == 1:
                            # å¤±è´¥
                            status["completed"] = True
                            status["success"] = False
                            logger.warning(f"mhnotify: ä»»åŠ¡å¤±è´¥: {task['task_name']}")
                    else:
                        # ä¸¤å¤„éƒ½æ‰¾ä¸åˆ°ï¼Œå¯èƒ½è¢«åˆ é™¤
                        status["completed"] = True
                        status["success"] = False
                        logger.warning(f"mhnotify: ä»»åŠ¡å¯èƒ½å·²è¢«åˆ é™¤: {task['task_name']}")
                        
                except Exception as e:
                    logger.warning(f"mhnotify: æŸ¥è¯¢ä»»åŠ¡ {task['task_name']} å¼‚å¸¸: {e}")
            
            if all_done:
                logger.info(f"mhnotify: æ‰¹é‡ç›‘æ§çš„ä»»åŠ¡å·²å…¨éƒ¨å¤„ç†å®Œæˆ")
                break
            
            time.sleep(check_interval)
        
        # ========== ç¬¬äºŒé˜¶æ®µï¼šç»Ÿè®¡ç»“æœï¼ˆåªç»Ÿè®¡æœªè¢«ç‹¬ç«‹å‡ºå»çš„ä»»åŠ¡ï¼‰ ==========
        batch_tasks = [t for t in tasks if not task_status[t["info_hash"]]["split_out"]]
        success_tasks = [t["info_hash"] for t in batch_tasks if task_status[t["info_hash"]]["success"]]
        failed_tasks = [t["info_hash"] for t in batch_tasks if task_status[t["info_hash"]]["completed"] and not task_status[t["info_hash"]]["success"]]
        split_tasks = [t for t in tasks if task_status[t["info_hash"]]["split_out"]]
        
        logger.info(f"mhnotify: æ‰¹é‡ä»»åŠ¡ç»Ÿè®¡ - æˆåŠŸ: {len(success_tasks)}, å¤±è´¥: {len(failed_tasks)}, ç‹¬ç«‹ç›‘æ§: {len(split_tasks)}")
        
        # å¦‚æœæ²¡æœ‰æˆåŠŸçš„ä»»åŠ¡ï¼Œç›´æ¥å‘é€é€šçŸ¥å¹¶ç»“æŸ
        if not success_tasks:
            if split_tasks:
                # æœ‰ä»»åŠ¡è¢«ç‹¬ç«‹å‡ºå»ï¼Œå‘é€éƒ¨åˆ†é€šçŸ¥
                self._send_batch_cloud_download_notification(
                    tasks=batch_tasks,
                    task_status=task_status,
                    removed_count=0,
                    removed_size_mb=0,
                    split_count=len(split_tasks)
                )
            logger.info(f"mhnotify: æ‰¹é‡ç›‘æ§æ— æˆåŠŸä»»åŠ¡ï¼Œç»“æŸ")
            return
        
        # ========== ç¬¬ä¸‰é˜¶æ®µï¼šç»Ÿä¸€æ¸…ç†å°æ–‡ä»¶ ==========
        total_removed_count = 0
        total_removed_size = 0
        
        if self._cloud_download_remove_small_files and success_tasks:
            logger.info(f"mhnotify: å¼€å§‹ç»Ÿä¸€æ¸…ç†å°æ–‡ä»¶...")
            time.sleep(5)  # ç­‰å¾…æ–‡ä»¶åˆ—è¡¨åŒæ­¥
            
            for info_hash in success_tasks:
                status = task_status[info_hash]
                if status["is_directory"]:
                    try:
                        removed_count, removed_size = self._remove_small_files_in_directory(client, status["actual_cid"])
                        total_removed_count += removed_count
                        total_removed_size += removed_size
                        if removed_count > 0:
                            logger.info(f"mhnotify: ä»»åŠ¡ {status['task_name']} æ¸…ç†äº† {removed_count} ä¸ªå°æ–‡ä»¶")
                    except Exception as e:
                        logger.warning(f"mhnotify: æ¸…ç†ä»»åŠ¡ {status['task_name']} å°æ–‡ä»¶å¼‚å¸¸: {e}")
        
        # ========== ç¬¬å››é˜¶æ®µï¼šç»Ÿä¸€æ‰§è¡Œä¸€æ¬¡ç§»åŠ¨æ•´ç† ==========
        if self._cloud_download_organize and target_path and success_tasks:
            logger.info(f"mhnotify: å¼€å§‹ç»Ÿä¸€ç§»åŠ¨æ•´ç†...")
            try:
                access_token = self._get_mh_access_token()
                if access_token:
                    self._organize_cloud_download(access_token, target_path)
                else:
                    logger.error(f"mhnotify: æ— æ³•è·å–MH access tokenï¼Œè·³è¿‡ç§»åŠ¨æ•´ç†")
            except Exception as e:
                logger.error(f"mhnotify: ç§»åŠ¨æ•´ç†å¼‚å¸¸: {e}")
        
        # ========== ç¬¬äº”é˜¶æ®µï¼šå‘é€æ±‡æ€»é€šçŸ¥ ==========
        self._send_batch_cloud_download_notification(
            tasks=batch_tasks,
            task_status=task_status,
            removed_count=total_removed_count,
            removed_size_mb=total_removed_size / 1024 / 1024,
            split_count=len(split_tasks)
        )
        
        logger.info(f"mhnotify: æ‰¹é‡ç¦»çº¿ä¸‹è½½ç›‘æ§ä»»åŠ¡ç»“æŸ")

    def _send_batch_cloud_download_notification(self, tasks: List[Dict[str, Any]], 
                                                  task_status: Dict[str, Dict],
                                                  removed_count: int, removed_size_mb: float,
                                                  split_count: int = 0):
        """
        å‘é€æ‰¹é‡äº‘ä¸‹è½½å®Œæˆçš„æ±‡æ€»é€šçŸ¥
        :param split_count: è¢«ç‹¬ç«‹å‡ºå»å•ç‹¬ç›‘æ§çš„ä»»åŠ¡æ•°é‡
        """
        try:
            success_count = sum(1 for s in task_status.values() if s.get("success"))
            fail_count = sum(1 for s in task_status.values() if s.get("completed") and not s.get("success") and not s.get("split_out"))
            
            title = f"âœ… 115äº‘ä¸‹è½½æ‰¹é‡ä»»åŠ¡å®Œæˆ"
            if fail_count > 0:
                title = f"âš ï¸ 115äº‘ä¸‹è½½æ‰¹é‡ä»»åŠ¡å®Œæˆï¼ˆ{fail_count}ä¸ªå¤±è´¥ï¼‰"
            
            text_parts = [f"ğŸ“¦ å…± {len(tasks) + split_count} ä¸ªä»»åŠ¡"]
            status_line = f"âœ… æˆåŠŸ: {success_count} | âŒ å¤±è´¥: {fail_count}"
            if split_count > 0:
                status_line += f" | â³ ç‹¬ç«‹ç›‘æ§: {split_count}"
            text_parts.append(status_line)
            
            # åˆ—å‡ºä»»åŠ¡åç§°
            if tasks:
                text_parts.append("")
                for task in tasks:
                    info_hash = task["info_hash"]
                    status = task_status.get(info_hash, {})
                    if status.get("success"):
                        text_parts.append(f"âœ… {task['task_name'][:30]}")
                    elif status.get("split_out"):
                        text_parts.append(f"â³ {task['task_name'][:30]}")
                    else:
                        text_parts.append(f"âŒ {task['task_name'][:30]}")
            
            if split_count > 0:
                text_parts.append("")
                text_parts.append(f"â„¹ï¸ {split_count} ä¸ªæ…¢ä»»åŠ¡å·²ç‹¬ç«‹ç›‘æ§ï¼Œå®Œæˆåå°†å•ç‹¬é€šçŸ¥")
            
            if removed_count > 0:
                text_parts.append("")
                text_parts.append(f"ğŸ§¹ æ¸…ç†å°æ–‡ä»¶: {removed_count} ä¸ª")
                text_parts.append(f"ğŸ’¾ é‡Šæ”¾ç©ºé—´: {removed_size_mb:.2f} MB")
            
            text = "\n".join(text_parts)
            
            self.post_message(
                mtype=None,
                title=title,
                text=text
            )
            logger.info(f"mhnotify: æ‰¹é‡äº‘ä¸‹è½½å®Œæˆé€šçŸ¥å·²å‘é€")
        except Exception as e:
            logger.error(f"mhnotify: å‘é€æ‰¹é‡äº‘ä¸‹è½½é€šçŸ¥å¤±è´¥: {e}", exc_info=True)

    def _monitor_and_remove_small_files(self, client, info_hash: str, target_cid: int, task_name: str, target_path: str = ""):
        """
        ç›‘æ§ç¦»çº¿ä¸‹è½½ä»»åŠ¡å®Œæˆååˆ é™¤å°æ–‡ä»¶
        :param client: P115Clientå®ä¾‹
        :param info_hash: ä»»åŠ¡hash
        :param target_cid: ç›®æ ‡ç›®å½•ID
        :param task_name: ä»»åŠ¡åç§°
        :param target_path: äº‘ä¸‹è½½ç›®æ ‡è·¯å¾„
        """
        try:
            import time
            logger.info(f"mhnotify: å¼€å§‹ç›‘æ§ç¦»çº¿ä¸‹è½½ä»»åŠ¡: {task_name}")
            
            # æ·»åŠ ä»»åŠ¡åç­‰å¾…15ç§’ï¼Œè®©ä»»åŠ¡æœ‰æ—¶é—´å‡ºç°åœ¨ä¸‹è½½åˆ—è¡¨ä¸­
            logger.info(f"mhnotify: ç­‰å¾…15ç§’ï¼Œè®©ä»»åŠ¡è¿›å…¥ä¸‹è½½é˜Ÿåˆ—...")
            time.sleep(15)
            
            # ========== ç¬¬ä¸€é˜¶æ®µï¼šç›‘æ§æ­£åœ¨ä¸‹è½½ ==========
            # ä½¿ç”¨ stat=12 æŸ¥è¯¢æ­£åœ¨ä¸‹è½½çš„ä»»åŠ¡
            logger.info(f"mhnotify: ç¬¬ä¸€é˜¶æ®µ - ç›‘æ§æ­£åœ¨ä¸‹è½½çŠ¶æ€...")
            
            normal_check_interval = 120  # æ­£å¸¸æ£€æŸ¥é—´éš”ï¼š2åˆ†é’Ÿ
            max_downloading_checks = 720  # æœ€å¤šæ£€æŸ¥24å°æ—¶
            
            task_found = False  # æ ‡è®°æ˜¯å¦è‡³å°‘æ‰¾åˆ°è¿‡ä¸€æ¬¡ä»»åŠ¡
            not_found_count = 0  # è¿ç»­æœªæ‰¾åˆ°ä»»åŠ¡çš„æ¬¡æ•°
            max_not_found_after_found = 3  # ä»»åŠ¡å‡ºç°åæœ€å¤šå®¹å¿3æ¬¡æœªæ‰¾åˆ°æ‰è®¤ä¸ºå·²å®Œæˆ
            
            for i in range(max_downloading_checks):
                try:
                    # æŸ¥è¯¢æ­£åœ¨ä¸‹è½½çš„ä»»åŠ¡ï¼ˆstat=12ï¼‰
                    downloading_task = self._query_downloading_task_by_hash(client, info_hash)
                    
                    if downloading_task:
                        # æ‰¾åˆ°ä»»åŠ¡äº†
                        task_found = True
                        not_found_count = 0  # é‡ç½®æœªæ‰¾åˆ°è®¡æ•°
                        
                        percent = downloading_task.get('percentDone', 0)
                        status = downloading_task.get('status', 0)
                        
                        # status=1 è¡¨ç¤ºæ­£åœ¨ä¸‹è½½
                        if status == 1:
                            # ä½¿ç”¨æ­£å¸¸æ£€æŸ¥é—´éš”ï¼ˆ2åˆ†é’Ÿï¼‰
                            if i % 5 == 0:  # æ¯10åˆ†é’Ÿè®°å½•ä¸€æ¬¡è¿›åº¦
                                logger.info(f"mhnotify: æ­£åœ¨ä¸‹è½½: {task_name} - {percent:.1f}%")
                            time.sleep(normal_check_interval)
                            continue
                        else:
                            # status != 1ï¼Œå¯èƒ½ä¸‹è½½å®Œæˆæˆ–å¤±è´¥ï¼Œè·³å‡ºå¾ªç¯
                            logger.info(f"mhnotify: ä»»åŠ¡çŠ¶æ€å˜åŒ– (status={status})ï¼Œè¿›å…¥ä¸‹ä¸€é˜¶æ®µ...")
                            break
                    else:
                        # æ­£åœ¨ä¸‹è½½åˆ—è¡¨ä¸­æœªæ‰¾åˆ°ä»»åŠ¡
                        not_found_count += 1
                        
                        if not task_found:
                            # ä»»åŠ¡ä»æœªåœ¨ä¸‹è½½åˆ—è¡¨ä¸­æ‰¾åˆ°è¿‡ï¼Œç›´æ¥è¿›å…¥ç¬¬äºŒé˜¶æ®µæŸ¥æ‰¾å·²å®Œæˆä»»åŠ¡
                            logger.info(f"mhnotify: æœªåœ¨ä¸‹è½½åˆ—è¡¨ä¸­æ‰¾åˆ°ä»»åŠ¡ï¼Œè¿›å…¥å·²å®Œæˆæ£€æŸ¥é˜¶æ®µ...")
                            break
                        else:
                            # ä»»åŠ¡ä¹‹å‰æ‰¾åˆ°è¿‡ï¼Œç°åœ¨æ‰¾ä¸åˆ°äº†
                            if not_found_count >= max_not_found_after_found:
                                # è¿ç»­å¤šæ¬¡æ‰¾ä¸åˆ°ï¼Œè¯´æ˜å·²å®Œæˆæˆ–å¤±è´¥ï¼Œè¿›å…¥ç¬¬äºŒé˜¶æ®µ
                                logger.info(f"mhnotify: ä»»åŠ¡å·²ä¸åœ¨ä¸‹è½½åˆ—è¡¨ä¸­ï¼Œè¿›å…¥å·²å®Œæˆæ£€æŸ¥é˜¶æ®µ...")
                                break
                            else:
                                logger.debug(f"mhnotify: æš‚æ—¶æœªæ‰¾åˆ°ä»»åŠ¡ ({not_found_count}/{max_not_found_after_found})ï¼Œç»§ç»­ç­‰å¾…...")
                                time.sleep(normal_check_interval)
                                continue
                        
                except Exception as e:
                    logger.warning(f"mhnotify: æŸ¥è¯¢æ­£åœ¨ä¸‹è½½ä»»åŠ¡å¼‚å¸¸: {e}")
                    # å‡ºç°å¼‚å¸¸ç›´æ¥è¿›å…¥ç¬¬äºŒé˜¶æ®µ
                    logger.info(f"mhnotify: æŸ¥è¯¢å¼‚å¸¸ï¼Œè¿›å…¥å·²å®Œæˆæ£€æŸ¥é˜¶æ®µ...")
                    break
            
            # ========== ç¬¬äºŒé˜¶æ®µï¼šæ£€æŸ¥å·²å®Œæˆä»»åŠ¡ ==========
            logger.info(f"mhnotify: ç¬¬äºŒé˜¶æ®µ - æ£€æŸ¥å·²å®Œæˆä»»åŠ¡...")
            
            # ç­‰å¾…3ç§’ï¼Œç¡®ä¿ä»»åŠ¡çŠ¶æ€åŒæ­¥
            time.sleep(3)
            
            # ä½¿ç”¨ stat=11 æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬å·²å®Œæˆï¼‰
            max_completed_checks = 5  # æœ€å¤šæ£€æŸ¥5æ¬¡
            completed_check_interval = 10  # 10ç§’
            consecutive_failures = 0
            max_consecutive_failures = 3
            
            for i in range(max_completed_checks):
                try:
                    # ä½¿ç”¨115 Web APIæŸ¥è¯¢ç¦»çº¿ä»»åŠ¡åˆ—è¡¨ï¼ˆstat=11 æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡ï¼‰
                    current_task = self._query_offline_task_by_hash(client, info_hash)
                    
                    # ç±»å‹æ£€æŸ¥ï¼šç¡®ä¿è¿”å›çš„æ˜¯å­—å…¸
                    if current_task and not isinstance(current_task, dict):
                        logger.warning(f"mhnotify: æŸ¥è¯¢ä»»åŠ¡è¿”å›ç±»å‹é”™è¯¯: {type(current_task)}")
                        current_task = None
                    
                    if not current_task:
                        # æœªæ‰¾åˆ°ä»»åŠ¡
                        consecutive_failures += 1
                        logger.warning(f"mhnotify: æœªæ‰¾åˆ°å·²å®Œæˆä»»åŠ¡ {info_hash[:16]}... (å°è¯• {consecutive_failures}/{max_consecutive_failures})")
                        
                        if consecutive_failures >= max_consecutive_failures:
                            # è¿ç»­å¤šæ¬¡æœªæ‰¾åˆ°ï¼Œå¯èƒ½è¢«åˆ é™¤äº†
                            logger.error(f"mhnotify: ä»»åŠ¡ {info_hash[:16]}... å¯èƒ½å·²è¢«åˆ é™¤")
                            self._send_cloud_download_deleted_notification(task_name)
                            break
                        
                        time.sleep(completed_check_interval)
                        continue
                    
                    # æŸ¥è¯¢æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                    consecutive_failures = 0
                    
                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼š2=å·²å®Œæˆ, 1=å¤±è´¥, 0=ä¸‹è½½ä¸­
                    status = current_task.get('status', 0)
                    if status == 2:
                        logger.info(f"mhnotify: ç¦»çº¿ä¸‹è½½ä»»åŠ¡å·²å®Œæˆ: {task_name}")
                        
                        # ä»ä»»åŠ¡ä¿¡æ¯ä¸­è·å–å®é™…æ–‡ä»¶/æ–‡ä»¶å¤¹IDï¼ˆfile_idï¼‰
                        # file_id æ˜¯ä¸‹è½½å®Œæˆåçš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„å®é™…ID
                        actual_cid = current_task.get('file_id', '')
                        if actual_cid:
                            try:
                                actual_cid = int(actual_cid)
                            except:
                                actual_cid = target_cid
                        else:
                            actual_cid = target_cid
                        
                        logger.info(f"mhnotify: å®é™…æ–‡ä»¶/æ–‡ä»¶å¤¹ID: {actual_cid}")
                        
                        # æ£€æŸ¥ file_categoryï¼Œåªæœ‰æ–‡ä»¶å¤¹æ‰éœ€è¦æ¸…ç†å°æ–‡ä»¶
                        file_category = current_task.get('file_category', 1)
                        is_directory = (file_category == 0)
                        
                        # è®°å½•æ¸…ç†ç»“æœç”¨äºé€šçŸ¥
                        removed_count = 0
                        removed_size_mb = 0.0
                        
                        # å¦‚æœå¼€å¯äº†å‰”é™¤å°æ–‡ä»¶ï¼Œå…ˆåˆ é™¤å°æ–‡ä»¶
                        if self._cloud_download_remove_small_files:
                            if is_directory:
                                logger.info(f"mhnotify: æ£€æµ‹åˆ°æ–‡ä»¶å¤¹ï¼Œå¼€å§‹æ¸…ç†å°æ–‡ä»¶...")
                                time.sleep(5)  # ç­‰å¾…5ç§’ç¡®ä¿æ–‡ä»¶åˆ—è¡¨åŒæ­¥
                                removed_count, removed_size = self._remove_small_files_in_directory(client, actual_cid)
                                removed_size_mb = removed_size / 1024 / 1024
                            else:
                                logger.info(f"mhnotify: æ£€æµ‹åˆ°å•ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡å°æ–‡ä»¶æ¸…ç†")
                        
                        # å¦‚æœå¼€å¯äº†ç§»åŠ¨æ•´ç†ï¼Œæ‰§è¡Œç§»åŠ¨æ•´ç†
                        if self._cloud_download_organize and target_path:
                            logger.info(f"mhnotify: å¼€å§‹ç§»åŠ¨æ•´ç†...")
                            # è·å–MH access token
                            access_token = self._get_mh_access_token()
                            if access_token:
                                self._organize_cloud_download(access_token, target_path)
                            else:
                                logger.error(f"mhnotify: æ— æ³•è·å–MH access tokenï¼Œè·³è¿‡ç§»åŠ¨æ•´ç†")
                        
                        # å‘é€äº‘ä¸‹è½½å®Œæˆé€šçŸ¥
                        self._send_cloud_download_notification(task_name, removed_count, removed_size_mb)
                        
                        break
                    elif status == 1:
                        logger.warning(f"mhnotify: ç¦»çº¿ä¸‹è½½ä»»åŠ¡å¤±è´¥: {task_name}")
                        self._send_cloud_download_failed_notification(task_name)
                        break
                    else:
                        # status ä¸ä¸º 2 ä¹Ÿä¸ä¸º 1ï¼Œç»§ç»­ç­‰å¾…
                        logger.info(f"mhnotify: ä»»åŠ¡çŠ¶æ€: {status}ï¼Œç»§ç»­ç­‰å¾…...")
                        time.sleep(completed_check_interval)
                        
                except Exception as e:
                    consecutive_failures += 1
                    logger.warning(f"mhnotify: æ£€æŸ¥å·²å®Œæˆä»»åŠ¡å¼‚å¸¸ ({consecutive_failures}/{max_consecutive_failures}): {e}")
                    
                    if consecutive_failures >= max_consecutive_failures:
                        logger.error(f"mhnotify: è¿ç»­{max_consecutive_failures}æ¬¡æ£€æŸ¥å¤±è´¥ï¼Œåœæ­¢ç›‘æ§ä»»åŠ¡: {task_name}")
                        break
                    
                    time.sleep(completed_check_interval)
            
            logger.info(f"mhnotify: ç¦»çº¿ä¸‹è½½ç›‘æ§ä»»åŠ¡ç»“æŸ: {task_name} (Hash: {info_hash[:16]}...)")
            
        except Exception as e:
            logger.error(f"mhnotify: ç›‘æ§ç¦»çº¿ä¸‹è½½ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
    
    def _query_offline_task_by_hash(self, client, info_hash: str) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨115 Web APIæŸ¥è¯¢ç¦»çº¿ä»»åŠ¡ï¼ˆé€šè¿‡info_hashåŒ¹é…ï¼‰
        :param client: P115Clientå®ä¾‹
        :param info_hash: ä»»åŠ¡hash
        :return: ä»»åŠ¡ä¿¡æ¯å­—å…¸æˆ–None
        """
        try:
            # æ„é€ è¯·æ±‚å‚æ•°
            # å‚è€ƒ 115-ol-list.txtï¼Œéœ€è¦ page, stat, uid, sign, time å‚æ•°
            import time as time_module
            import hashlib
            
            # è·å–ç”¨æˆ·IDï¼ˆä»cookieæˆ–clientä¸­è·å–ï¼‰
            uid = None
            try:
                # å°è¯•ä»clientè·å–ç”¨æˆ·ä¿¡æ¯
                user_info = client.fs_userinfo()
                if user_info and isinstance(user_info, dict):
                    uid = user_info.get('user_id')
            except:
                pass
            
            if not uid:
                # ä»cookieä¸­è§£æUID
                cookie_dict = {}
                for item in self._p115_cookie.split(';'):
                    item = item.strip()
                    if '=' in item:
                        k, v = item.split('=', 1)
                        cookie_dict[k.strip()] = v.strip()
                uid_str = cookie_dict.get('UID', '')
                if uid_str and '_' in uid_str:
                    uid = uid_str.split('_')[0]
            
            if not uid:
                logger.warning(f"mhnotify: æ— æ³•è·å–115ç”¨æˆ·ID")
                return None
            
            # æ„é€ ç­¾åï¼ˆå‚è€ƒ115-ol-list APIï¼‰
            timestamp = int(time_module.time())
            # ç­¾åç®—æ³•ï¼šmd5(uid + time)ï¼Œå®é™…ç®—æ³•å¯èƒ½ä¸åŒï¼Œè¿™é‡Œå…ˆå°è¯•ç®€å•æ–¹å¼
            sign_str = f"{uid}{timestamp}"
            sign = hashlib.md5(sign_str.encode()).hexdigest()
            
            # è°ƒç”¨ç¦»çº¿ä»»åŠ¡åˆ—è¡¨API
            # stat=11è¡¨ç¤ºæŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬å·²å®Œæˆï¼‰
            url = "https://115.com/web/lixian/?ct=lixian&ac=task_lists"
            params = {
                'page': 1,
                'stat': 11,  # 11=æ‰€æœ‰ä»»åŠ¡
                'uid': uid,
                'sign': sign,
                'time': timestamp
            }
            
            # ä½¿ç”¨RequestUtilså‘é€è¯·æ±‚
            headers = {
                "Accept": "application/json, text/javascript, */*; q=0.01",
                "Cookie": self._p115_cookie,
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            
            response = RequestUtils(headers=headers).post_res(url, data=params)
            if not response or response.status_code != 200:
                logger.debug(f"mhnotify: æŸ¥è¯¢ç¦»çº¿ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {response.status_code if response else 'No response'}")
                return None
            
            result = response.json()
            if not result or not result.get('state'):
                logger.debug(f"mhnotify: ç¦»çº¿ä»»åŠ¡åˆ—è¡¨å“åº”å¼‚å¸¸: {result}")
                return None
            
            # æŸ¥æ‰¾åŒ¹é…çš„ä»»åŠ¡
            tasks = result.get('tasks', [])
            for task in tasks:
                if task.get('info_hash', '').lower() == info_hash.lower():
                    return task
            
            return None
            
        except Exception as e:
            logger.debug(f"mhnotify: æŸ¥è¯¢ç¦»çº¿ä»»åŠ¡å¼‚å¸¸: {e}")
            return None

    def _remove_small_files_in_directory(self, client, cid: int) -> Tuple[int, int]:
        """
        åˆ é™¤ç›®å½•ä¸­å°äº10MBçš„æ–‡ä»¶ï¼ˆé€’å½’éå†å­ç›®å½•ï¼‰
        :param client: P115Clientå®ä¾‹
        :param cid: ç›®å½•ID (æ–‡ä»¶å¤¹çš„file_id)
        :return: (åˆ é™¤æ–‡ä»¶æ•°é‡, åˆ é™¤æ–‡ä»¶æ€»å¤§å°å­—èŠ‚æ•°)
        """
        try:
            logger.info(f"mhnotify: å¼€å§‹é€’å½’æ¸…ç†å°æ–‡ä»¶ï¼Œæ ¹ç›®å½•cid={cid}")
            
            min_size = 10 * 1024 * 1024  # 10MB
            removed_count = 0
            removed_size = 0
            
            # ä½¿ç”¨ p115client.tool.iterdir çš„ iter_files é€’å½’éå†æ‰€æœ‰æ–‡ä»¶
            try:
                from p115client.tool.iterdir import iter_files  # type: ignore
                logger.info("mhnotify: ä½¿ç”¨ iter_files é€’å½’éå†ç›®å½•...")
                
                # iter_files ä¼šé€’å½’è¿”å›æ‰€æœ‰æ–‡ä»¶ï¼ˆä¸å«ç›®å½•ï¼‰
                for attr in iter_files(client, cid):
                    try:
                        # attr æ˜¯ä¸€ä¸ª dictï¼ŒåŒ…å« id, parent_id, name, size, is_dir ç­‰
                        if not isinstance(attr, dict):
                            continue
                        
                        # iter_files åªè¿”å›æ–‡ä»¶ï¼Œä½†è¿˜æ˜¯æ£€æŸ¥ä¸€ä¸‹
                        is_dir = attr.get('is_dir', False)
                        if is_dir:
                            continue
                        
                        file_id = attr.get('id') or attr.get('fid') or attr.get('file_id')
                        file_name = attr.get('name') or attr.get('n') or attr.get('fn') or ''
                        file_size = attr.get('size') or attr.get('fs') or attr.get('s') or 0
                        
                        if isinstance(file_size, str):
                            try:
                                file_size = int(file_size)
                            except:
                                file_size = 0
                        
                        if not file_id:
                            logger.debug(f"mhnotify: æ–‡ä»¶æ— IDï¼Œè·³è¿‡: {file_name}")
                            continue
                        
                        logger.debug(f"mhnotify: æ£€æŸ¥æ–‡ä»¶: {file_name}, å¤§å°: {file_size/1024/1024:.2f}MB")
                        
                        # å¦‚æœæ–‡ä»¶å°äº10MBï¼Œåˆ é™¤
                        if file_size < min_size:
                            try:
                                logger.info(f"mhnotify: å‡†å¤‡åˆ é™¤å°æ–‡ä»¶: {file_name} ({file_size/1024/1024:.2f}MB)")
                                client.fs_delete(file_id)
                                removed_count += 1
                                removed_size += file_size
                                logger.info(f"mhnotify: æˆåŠŸåˆ é™¤å°æ–‡ä»¶: {file_name}")
                            except Exception as e:
                                logger.warning(f"mhnotify: åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_name}: {e}")
                    except Exception as e:
                        logger.debug(f"mhnotify: å¤„ç†æ–‡ä»¶é¡¹å¼‚å¸¸: {e}")
                        continue
                        
            except ImportError:
                logger.warning("mhnotify: iter_files å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
                # å¤‡ç”¨æ–¹æ¡ˆï¼šæ‰‹åŠ¨é€’å½’éå†
                removed_count, removed_size = self._remove_small_files_recursive(client, cid, min_size)
            except Exception as e:
                logger.warning(f"mhnotify: iter_files è°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
                removed_count, removed_size = self._remove_small_files_recursive(client, cid, min_size)
            
            if removed_count > 0:
                logger.info(f"mhnotify: äº‘ä¸‹è½½å°æ–‡ä»¶æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾ç©ºé—´ {removed_size/1024/1024:.2f}MB")
            else:
                logger.info(f"mhnotify: äº‘ä¸‹è½½ç›®å½•ä¸­æ²¡æœ‰å°äº10MBçš„æ–‡ä»¶éœ€è¦åˆ é™¤")
            
            return removed_count, removed_size
                
        except Exception as e:
            logger.error(f"mhnotify: åˆ é™¤å°æ–‡ä»¶å¼‚å¸¸: {e}", exc_info=True)
            return 0, 0

    def _remove_small_files_recursive(self, client, cid: int, min_size: int) -> Tuple[int, int]:
        """
        å¤‡ç”¨æ–¹æ¡ˆï¼šæ‰‹åŠ¨é€’å½’éå†ç›®å½•åˆ é™¤å°æ–‡ä»¶
        :param client: P115Clientå®ä¾‹
        :param cid: ç›®å½•ID
        :param min_size: æœ€å°æ–‡ä»¶å¤§å°é˜ˆå€¼ï¼ˆå­—èŠ‚ï¼‰
        :return: (åˆ é™¤æ•°é‡, åˆ é™¤å¤§å°)
        """
        removed_count = 0
        removed_size = 0
        
        # ä½¿ç”¨æ ˆå®ç°éé€’å½’éå†ï¼Œé¿å…æ·±å±‚é€’å½’å¯¼è‡´æ ˆæº¢å‡º
        dir_stack = [cid]
        
        while dir_stack:
            current_cid = dir_stack.pop()
            logger.debug(f"mhnotify: éå†ç›®å½• cid={current_cid}")
            
            offset = 0
            limit = 1000
            
            while True:
                try:
                    # è°ƒç”¨ fs_files è·å–ç›®å½•å†…å®¹
                    resp = client.fs_files(cid=current_cid, limit=limit, offset=offset)
                except Exception as e:
                    logger.warning(f"mhnotify: fs_files è°ƒç”¨å¤±è´¥ (cid={current_cid}): {e}")
                    break
                
                # å¤„ç†å“åº”
                items = []
                if isinstance(resp, dict):
                    items = resp.get('data', []) or resp.get('files', [])
                elif hasattr(resp, '__iter__'):
                    try:
                        items = list(resp)
                    except:
                        break
                
                if not items:
                    break
                
                for item in items:
                    if not isinstance(item, dict):
                        continue
                    
                    # åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
                    # æ ¹æ® p115client çš„é€»è¾‘ï¼š
                    # - å¦‚æœæœ‰ 'n' å­—æ®µ: æ²¡æœ‰ 'fid' çš„æ˜¯ç›®å½•
                    # - å¦‚æœæœ‰ 'fn' å­—æ®µ: fc == "0" æ˜¯ç›®å½•ï¼Œfc == "1" æ˜¯æ–‡ä»¶
                    is_dir = False
                    if 'n' in item:
                        # æ–°æ ¼å¼ï¼šæ²¡æœ‰ fid çš„æ˜¯ç›®å½•
                        is_dir = 'fid' not in item
                    elif 'fn' in item:
                        # è€æ ¼å¼ï¼šfc å­—æ®µ
                        fc = item.get('fc')
                        is_dir = (fc == '0' or fc == 0)
                    else:
                        # å…¶ä»–æ ¼å¼ï¼šæ£€æŸ¥ file_category
                        fc = item.get('file_category')
                        is_dir = (fc == 0 or fc == '0')
                    
                    if is_dir:
                        # æ˜¯ç›®å½•ï¼Œè·å–ç›®å½•IDå¹¶åŠ å…¥æ ˆ
                        sub_cid = item.get('cid') or item.get('id') or item.get('category_id')
                        if sub_cid:
                            try:
                                sub_cid = int(sub_cid)
                                dir_stack.append(sub_cid)
                                dir_name = item.get('n') or item.get('fn') or item.get('name') or item.get('category_name') or ''
                                logger.debug(f"mhnotify: å‘ç°å­ç›®å½•: {dir_name} (cid={sub_cid})")
                            except:
                                pass
                    else:
                        # æ˜¯æ–‡ä»¶ï¼Œæ£€æŸ¥å¤§å°
                        file_id = item.get('fid') or item.get('file_id') or item.get('id')
                        file_name = item.get('n') or item.get('fn') or item.get('name') or item.get('file_name') or ''
                        file_size = item.get('s') or item.get('fs') or item.get('size') or item.get('file_size') or 0
                        
                        if isinstance(file_size, str):
                            try:
                                file_size = int(file_size)
                            except:
                                file_size = 0
                        
                        if not file_id:
                            continue
                        
                        logger.debug(f"mhnotify: æ£€æŸ¥æ–‡ä»¶: {file_name}, å¤§å°: {file_size/1024/1024:.2f}MB")
                        
                        if file_size < min_size:
                            try:
                                logger.info(f"mhnotify: å‡†å¤‡åˆ é™¤å°æ–‡ä»¶: {file_name} ({file_size/1024/1024:.2f}MB)")
                                client.fs_delete(file_id)
                                removed_count += 1
                                removed_size += file_size
                                logger.info(f"mhnotify: æˆåŠŸåˆ é™¤å°æ–‡ä»¶: {file_name}")
                            except Exception as e:
                                logger.warning(f"mhnotify: åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_name}: {e}")
                
                if len(items) < limit:
                    break
                offset += limit
        
        return removed_count, removed_size

    def _send_cloud_download_notification(self, task_name: str, removed_count: int, removed_size_mb: float):
        """
        å‘é€äº‘ä¸‹è½½å®Œæˆé€šçŸ¥
        :param task_name: ä»»åŠ¡åç§°
        :param removed_count: åˆ é™¤çš„å°æ–‡ä»¶æ•°é‡
        :param removed_size_mb: åˆ é™¤çš„æ–‡ä»¶æ€»å¤§å°(MB)
        """
        try:
            # æ„å»ºé€šçŸ¥æ¶ˆæ¯
            title = "âœ… 115äº‘ä¸‹è½½å®Œæˆ"
            text_parts = [f"ğŸ“¦ ä»»åŠ¡: {task_name}"]
            
            if removed_count > 0:
                text_parts.append(f"ğŸ§¹ æ¸…ç†å°æ–‡ä»¶: {removed_count} ä¸ª")
                text_parts.append(f"ğŸ’¾ é‡Šæ”¾ç©ºé—´: {removed_size_mb:.2f} MB")
            
            text = "\n".join(text_parts)
            
            # å‘é€é€šçŸ¥
            self.post_message(
                mtype=None,
                title=title,
                text=text
            )
            logger.info(f"mhnotify: äº‘ä¸‹è½½å®Œæˆé€šçŸ¥å·²å‘é€: {task_name}")
        except Exception as e:
            logger.error(f"mhnotify: å‘é€äº‘ä¸‹è½½é€šçŸ¥å¤±è´¥: {e}", exc_info=True)

    def _get_mh_access_token(self) -> Optional[str]:
        """
        è·å–MH access token
        :return: access tokenæˆ–None
        """
        try:
            login_url = f"{self._mh_domain}/api/v1/auth/login"
            login_payload = {
                "username": self._mh_username,
                "password": self._mh_password
            }
            headers = {
                "Accept": "application/json, text/plain, */*",
                "Content-Type": "application/json;charset=UTF-8",
                "Origin": self._mh_domain,
                "Accept-Language": "zh-CN",
                "User-Agent": "MoviePilot/Plugin MHNotify"
            }
            login_res = RequestUtils(headers=headers).post(login_url, json=login_payload)
            if not login_res or login_res.status_code != 200:
                logger.error(f"mhnotify: MHç™»å½•å¤±è´¥")
                return None
            
            try:
                login_data = login_res.json()
                access_token = login_data.get("data", {}).get("access_token")
                return access_token
            except Exception:
                logger.error(f"mhnotify: è§£æMHç™»å½•å“åº”å¤±è´¥")
                return None
        except Exception as e:
            logger.error(f"mhnotify: è·å–MH access tokenå¼‚å¸¸: {e}")
            return None

    def _organize_cloud_download(self, access_token: str, target_path: str):
        """
        äº‘ä¸‹è½½å®Œæˆåç§»åŠ¨åˆ°MHé»˜è®¤ç›®å½•å¹¶æ•´ç†
        :param access_token: MH access token
        :param target_path: äº‘ä¸‹è½½ç›®æ ‡è·¯å¾„
        """
        try:
            logger.info(f"mhnotify: å¼€å§‹äº‘ä¸‹è½½ç§»åŠ¨æ•´ç†æµç¨‹ï¼Œç›®æ ‡è·¯å¾„: {target_path}")
            
            # 1. è·å–115ç½‘ç›˜è´¦æˆ·ä¿¡æ¯
            cloud_url = f"{self._mh_domain}/api/v1/cloud-accounts?active_only=true"
            headers = {
                "Accept": "application/json, text/plain, */*",
                "Authorization": f"Bearer {access_token}",
                "User-Agent": "MoviePilot/Plugin MHNotify",
                "Accept-Language": "zh-CN"
            }
            
            logger.info(f"mhnotify: æ­£åœ¨è·å–äº‘è´¦æˆ·åˆ—è¡¨...")
            cloud_res = RequestUtils(headers=headers).get_res(cloud_url)
            
            if not cloud_res:
                logger.error(f"mhnotify: è·å–äº‘è´¦æˆ·åˆ—è¡¨å¤±è´¥ - å“åº”ä¸ºç©º")
                return
            
            if cloud_res.status_code != 200:
                logger.error(f"mhnotify: è·å–äº‘è´¦æˆ·åˆ—è¡¨å¤±è´¥ - çŠ¶æ€ç : {cloud_res.status_code}, å“åº”: {cloud_res.text[:500]}")
                return
            
            try:
                cloud_data = cloud_res.json()
                logger.debug(f"mhnotify: äº‘è´¦æˆ·å“åº”æ•°æ®: {cloud_data}")
            except Exception as e:
                logger.error(f"mhnotify: è§£æäº‘è´¦æˆ·å“åº”å¤±è´¥ - {e}, åŸå§‹å“åº”: {cloud_res.text[:500]}")
                return
            
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª115ç½‘ç›˜è´¦æˆ·
            accounts = cloud_data.get("data", {}).get("accounts", [])
            logger.info(f"mhnotify: æ‰¾åˆ° {len(accounts)} ä¸ªäº‘è´¦æˆ·")
            
            drive115_account = None
            for account in accounts:
                account_type = account.get("cloud_type")
                account_name = account.get("name")
                logger.debug(f"mhnotify: æ£€æŸ¥è´¦æˆ·: {account_name} (ç±»å‹: {account_type})")
                if account_type == "drive115":
                    drive115_account = account
                    break
            
            if not drive115_account:
                logger.error(f"mhnotify: æœªæ‰¾åˆ°115ç½‘ç›˜è´¦æˆ·ï¼Œå¯ç”¨è´¦æˆ·ç±»å‹: {[a.get('cloud_type') for a in accounts]}")
                return
            
            account_identifier = drive115_account.get("external_id")
            logger.info(f"mhnotify: æ‰¾åˆ°115ç½‘ç›˜è´¦æˆ·: {drive115_account.get('name')}, ID: {account_identifier}")
            
            # 2. æäº¤ç½‘ç›˜ç›®å½•åˆ†æä»»åŠ¡
            analyze_url = f"{self._mh_domain}/api/v1/library-tool/analyze-cloud-directory-async"
            analyze_payload = {
                "cloud_type": "drive115",
                "account_identifier": account_identifier,
                "cloud_path": target_path
            }
            
            logger.info(f"mhnotify: æ­£åœ¨æäº¤ç½‘ç›˜åˆ†æä»»åŠ¡...")
            logger.debug(f"mhnotify: åˆ†æä»»åŠ¡å‚æ•°: {analyze_payload}")
            
            analyze_res = RequestUtils(headers=headers).post_res(analyze_url, json=analyze_payload)
            
            if not analyze_res:
                logger.error(f"mhnotify: æäº¤ç½‘ç›˜åˆ†æä»»åŠ¡å¤±è´¥ - å“åº”ä¸ºç©º")
                return
            
            if analyze_res.status_code != 200:
                logger.error(f"mhnotify: æäº¤ç½‘ç›˜åˆ†æä»»åŠ¡å¤±è´¥ - çŠ¶æ€ç : {analyze_res.status_code}, å“åº”: {analyze_res.text[:500]}")
                return
            
            try:
                analyze_data = analyze_res.json()
                logger.debug(f"mhnotify: åˆ†æä»»åŠ¡å“åº”æ•°æ®: {analyze_data}")
            except Exception as e:
                logger.error(f"mhnotify: è§£æåˆ†æä»»åŠ¡å“åº”å¤±è´¥ - {e}, åŸå§‹å“åº”: {analyze_res.text[:500]}")
                return
            
            task_id = analyze_data.get("data", {}).get("task_id")
            if not task_id:
                message = analyze_data.get("message", "")
                logger.error(f"mhnotify: æœªè·å–åˆ°åˆ†æä»»åŠ¡ID - message: {message}, å®Œæ•´å“åº”: {analyze_data}")
                return
            
            logger.info(f"mhnotify: ç½‘ç›˜åˆ†æä»»åŠ¡å·²æäº¤ï¼Œtask_id: {task_id}")
            
            # 3. å¾ªç¯æŸ¥è¯¢è¿›åº¦ç›´åˆ°å®Œæˆ
            import time
            max_wait = 300  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
            elapsed = 0
            
            while elapsed < max_wait:
                time.sleep(2)
                elapsed += 2
                
                progress_url = f"{self._mh_domain}/api/v1/library-tool/analysis-task/{task_id}/progress"
                progress_res = RequestUtils(headers=headers).get_res(progress_url)
                
                if not progress_res or progress_res.status_code != 200:
                    logger.warning(f"mhnotify: æŸ¥è¯¢åˆ†æè¿›åº¦å¤±è´¥ï¼Œç»§ç»­ç­‰å¾…...")
                    continue
                
                try:
                    progress_data = progress_res.json()
                except Exception:
                    logger.warning(f"mhnotify: è§£æè¿›åº¦å“åº”å¤±è´¥ï¼Œç»§ç»­ç­‰å¾…...")
                    continue
                
                task_info = progress_data.get("data", {})
                progress = task_info.get("progress", 0)
                status = task_info.get("status", "")
                current_step = task_info.get("current_step", "")
                
                logger.debug(f"mhnotify: åˆ†æè¿›åº¦ {progress}% - {current_step}")
                
                if progress >= 100 and status == "completed":
                    logger.info(f"mhnotify: ç½‘ç›˜åˆ†æä»»åŠ¡å®Œæˆ")
                    break
                elif status == "failed":
                    error = task_info.get("error", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"mhnotify: ç½‘ç›˜åˆ†æä»»åŠ¡å¤±è´¥: {error}")
                    return
            
            if elapsed >= max_wait:
                logger.warning(f"mhnotify: ç½‘ç›˜åˆ†æä»»åŠ¡è¶…æ—¶ï¼Œè·³è¿‡ç§»åŠ¨æ•´ç†")
                return
            
            # ç­‰å¾…3ç§’åå†è¿›è¡Œä¸‹ä¸€æ­¥ï¼Œç¡®ä¿åç«¯å¤„ç†å®Œæˆ
            logger.info(f"mhnotify: ç½‘ç›˜åˆ†æå®Œæˆï¼Œç­‰å¾…3ç§’åç»§ç»­...")
            time.sleep(3)
            
            # 4. è·å–é»˜è®¤ç›®å½•é…ç½®
            defaults_url = f"{self._mh_domain}/api/v1/subscription/config/cloud-defaults"
            logger.info(f"mhnotify: æ­£åœ¨è·å–é»˜è®¤ç›®å½•é…ç½®...")
            defaults_res = RequestUtils(headers=headers).get_res(defaults_url)
            
            if not defaults_res:
                logger.error(f"mhnotify: è·å–é»˜è®¤ç›®å½•é…ç½®å¤±è´¥ - å“åº”ä¸ºç©º")
                return
            
            if defaults_res.status_code != 200:
                logger.error(f"mhnotify: è·å–é»˜è®¤ç›®å½•é…ç½®å¤±è´¥ - çŠ¶æ€ç : {defaults_res.status_code}, å“åº”: {defaults_res.text[:500]}")
                return
            
            try:
                defaults_data = defaults_res.json()
                logger.debug(f"mhnotify: é»˜è®¤ç›®å½•é…ç½®æ•°æ®: {defaults_data}")
            except Exception as e:
                logger.error(f"mhnotify: è§£æé»˜è®¤ç›®å½•é…ç½®å¤±è´¥ - {e}, åŸå§‹å“åº”: {defaults_res.text[:500]}")
                return
            
            account_configs = defaults_data.get("data", {}).get("account_configs", {})
            account_config = account_configs.get(account_identifier, {})
            default_directory = account_config.get("default_directory", "/å½±è§†")
            
            logger.info(f"mhnotify: è·å–åˆ°é»˜è®¤ç›®å½•: {default_directory}")
            logger.debug(f"mhnotify: è´¦æˆ·é…ç½®: {account_config}")
            
            # 5. æäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡
            logger.info(f"mhnotify: ç­‰å¾…3ç§’åæäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡...")
            time.sleep(3)
            
            organize_url = f"{self._mh_domain}/api/v1/library-tool/organize-files-async"
            organize_payload = {
                "task_id": task_id,  # ä½¿ç”¨ç½‘ç›˜åˆ†æä»»åŠ¡çš„task_id
                "cloud_type": "drive115",
                "source_path": target_path,
                "account_identifier": account_identifier,
                "target_folder_path": default_directory,
                "is_share_link": False,
                "operation_mode": "move",
                "include_series": True,
                "include_movies": True
            }
            
            logger.info(f"mhnotify: å‡†å¤‡æäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡")
            logger.info(f"mhnotify: è¯·æ±‚URL: {organize_url}")
            logger.info(f"mhnotify: è¯·æ±‚å‚æ•°: {organize_payload}")
            logger.info(f"mhnotify: è¯·æ±‚å¤´Authorization: Bearer {access_token[:20]}...")
            
            try:
                organize_res = RequestUtils(headers=headers).post_res(organize_url, json=organize_payload)
                
                # æ£€æŸ¥å“åº”å¯¹è±¡
                if organize_res is None:
                    logger.error(f"mhnotify: æäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡å¤±è´¥ - RequestUtilsè¿”å›None")
                    logger.error(f"mhnotify: è¿™å¯èƒ½æ˜¯ç½‘ç»œé”™è¯¯æˆ–è¯·æ±‚è¶…æ—¶")
                    return
                
                # æ‰“å°å“åº”çš„åŸºæœ¬ä¿¡æ¯
                logger.info(f"mhnotify: å“åº”å¯¹è±¡ç±»å‹: {type(organize_res)}")
                logger.info(f"mhnotify: å“åº”å¯¹è±¡å±æ€§: {dir(organize_res)}")
                
                # å°è¯•è·å–çŠ¶æ€ç 
                try:
                    status_code = organize_res.status_code
                    logger.info(f"mhnotify: æ–‡ä»¶æ•´ç†ä»»åŠ¡å“åº”çŠ¶æ€ç : {status_code}")
                except Exception as e:
                    logger.error(f"mhnotify: æ— æ³•è·å–å“åº”çŠ¶æ€ç : {e}")
                    return
                
                # å°è¯•è·å–å“åº”å†…å®¹
                try:
                    response_text = organize_res.text
                    logger.info(f"mhnotify: å“åº”å†…å®¹é•¿åº¦: {len(response_text)} å­—èŠ‚")
                    logger.info(f"mhnotify: å“åº”å†…å®¹: {response_text[:1000]}")
                except Exception as e:
                    logger.error(f"mhnotify: æ— æ³•è·å–å“åº”å†…å®¹: {e}")
                    return
                
            except Exception as e:
                logger.error(f"mhnotify: æäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡è¯·æ±‚å¼‚å¸¸: {e}", exc_info=True)
                return
            
            if status_code != 200:
                try:
                    error_text = response_text
                    logger.error(f"mhnotify: æäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡å¤±è´¥ - çŠ¶æ€ç : {status_code}")
                    logger.error(f"mhnotify: é”™è¯¯å“åº”å†…å®¹: {error_text}")
                except:
                    logger.error(f"mhnotify: æäº¤æ–‡ä»¶æ•´ç†ä»»åŠ¡å¤±è´¥ - çŠ¶æ€ç : {status_code}, æ— æ³•è¯»å–å“åº”å†…å®¹")
                return
            
            try:
                organize_data = organize_res.json()
                logger.info(f"mhnotify: æ•´ç†ä»»åŠ¡å“åº”JSON: {organize_data}")
            except Exception as e:
                logger.error(f"mhnotify: è§£ææ•´ç†ä»»åŠ¡å“åº”å¤±è´¥ - {e}")
                logger.error(f"mhnotify: åŸå§‹å“åº”: {response_text}")
                return
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            # æ¥å£å¯èƒ½è¿”å› success å­—æ®µï¼Œä¹Ÿå¯èƒ½è¿”å› code å­—æ®µè¡¨ç¤ºæˆåŠŸ
            success = organize_data.get("success", False)
            code = organize_data.get("code", "")
            message = organize_data.get("message", "")
            
            # code == 200 æˆ– code == "200" ä¹Ÿè§†ä¸ºæˆåŠŸ
            if not success and str(code) != "200":
                logger.error(f"mhnotify: æ–‡ä»¶æ•´ç†ä»»åŠ¡æäº¤å¤±è´¥ - code: {code}, message: {message}")
                return
            
            organize_task_id = organize_data.get("data", {}).get("task_id")
            
            if not organize_task_id:
                logger.info(f"mhnotify: æ–‡ä»¶æ•´ç†ä»»åŠ¡å·²åˆ›å»º: {message}")
            else:
                logger.info(f"mhnotify: æ–‡ä»¶æ•´ç†ä»»åŠ¡å·²æäº¤ï¼Œtask_id: {organize_task_id}, message: {message}")
            
        except Exception as e:
            logger.error(f"mhnotify: äº‘ä¸‹è½½ç§»åŠ¨æ•´ç†å¼‚å¸¸: {e}", exc_info=True)

    def _query_downloading_task_by_hash(self, client, info_hash: str) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨115 Web APIæŸ¥è¯¢æ­£åœ¨ä¸‹è½½çš„ç¦»çº¿ä»»åŠ¡ï¼ˆé€šè¿‡info_hashåŒ¹é…ï¼‰
        :param client: P115Clientå®ä¾‹
        :param info_hash: ä»»åŠ¡hash
        :return: ä»»åŠ¡ä¿¡æ¯å­—å…¸æˆ–None
        """
        try:
            # æ„é€ è¯·æ±‚å‚æ•°
            # å‚è€ƒ 115-downing.txtï¼Œstat=12 è¡¨ç¤ºæŸ¥è¯¢æ­£åœ¨ä¸‹è½½çš„ä»»åŠ¡
            import time as time_module
            import hashlib
            
            # è·å–ç”¨æˆ·ID
            uid = self._get_115_uid()
            if not uid:
                logger.warning(f"mhnotify: æ— æ³•è·å–115ç”¨æˆ·ID")
                return None
            
            # æ„é€ ç­¾å
            timestamp = int(time_module.time())
            sign_str = f"{uid}{timestamp}"
            sign = hashlib.md5(sign_str.encode()).hexdigest()
            
            # è°ƒç”¨ç¦»çº¿ä»»åŠ¡åˆ—è¡¨APIï¼ˆstat=12 è¡¨ç¤ºæ­£åœ¨ä¸‹è½½ï¼‰
            url = "https://115.com/web/lixian/?ct=lixian&ac=task_lists"
            params = {
                'page': 1,
                'stat': 12,  # 12=æ­£åœ¨ä¸‹è½½
                'uid': uid,
                'sign': sign,
                'time': timestamp
            }
            
            # ä½¿ç”¨RequestUtilså‘é€è¯·æ±‚
            headers = {
                "Accept": "application/json, text/javascript, */*; q=0.01",
                "Cookie": self._p115_cookie,
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            
            response = RequestUtils(headers=headers).post_res(url, data=params)
            if not response or response.status_code != 200:
                logger.debug(f"mhnotify: æŸ¥è¯¢æ­£åœ¨ä¸‹è½½ä»»åŠ¡å¤±è´¥: {response.status_code if response else 'No response'}")
                return None
            
            result = response.json()
            if not result or not result.get('state'):
                logger.debug(f"mhnotify: æ­£åœ¨ä¸‹è½½ä»»åŠ¡åˆ—è¡¨å“åº”å¼‚å¸¸: {result}")
                return None
            
            # æŸ¥æ‰¾åŒ¹é…çš„ä»»åŠ¡
            tasks = result.get('tasks', [])
            for task in tasks:
                if task.get('info_hash', '').lower() == info_hash.lower():
                    return task
            
            return None
            
        except Exception as e:
            logger.debug(f"mhnotify: æŸ¥è¯¢æ­£åœ¨ä¸‹è½½ä»»åŠ¡å¼‚å¸¸: {e}")
            return None

    def _get_115_uid(self) -> Optional[str]:
        """
        ä» cookie ä¸­è·å– 115 ç”¨æˆ· ID
        :return: ç”¨æˆ·IDæˆ–None
        """
        try:
            cookie_dict = {}
            for item in self._p115_cookie.split(';'):
                item = item.strip()
                if '=' in item:
                    k, v = item.split('=', 1)
                    cookie_dict[k.strip()] = v.strip()
            
            uid_str = cookie_dict.get('UID', '')
            if uid_str and '_' in uid_str:
                return uid_str.split('_')[0]
            
            return None
        except Exception as e:
            logger.warning(f"mhnotify: è§£æUIDå¤±è´¥: {e}")
            return None

    def _send_cloud_download_deleted_notification(self, task_name: str):
        """
        å‘é€äº‘ä¸‹è½½ä»»åŠ¡è¢«åˆ é™¤é€šçŸ¥
        :param task_name: ä»»åŠ¡åç§°
        """
        try:
            title = "âš ï¸ 115äº‘ä¸‹è½½ä»»åŠ¡å·²è¢«åˆ é™¤"
            text = f"ğŸ“¦ ä»»åŠ¡: {task_name}\n\nä»»åŠ¡åœ¨ç›‘æ§æœŸé—´è¢«åˆ é™¤ï¼Œå·²åœæ­¢ç›‘æ§ã€‚"
            
            self.post_message(
                mtype=None,
                title=title,
                text=text
            )
            logger.info(f"mhnotify: äº‘ä¸‹è½½ä»»åŠ¡åˆ é™¤é€šçŸ¥å·²å‘é€: {task_name}")
        except Exception as e:
            logger.error(f"mhnotify: å‘é€äº‘ä¸‹è½½åˆ é™¤é€šçŸ¥å¤±è´¥: {e}", exc_info=True)

    def _send_cloud_download_failed_notification(self, task_name: str):
        """
        å‘é€äº‘ä¸‹è½½ä»»åŠ¡å¤±è´¥é€šçŸ¥
        :param task_name: ä»»åŠ¡åç§°
        """
        try:
            title = "âŒ 115äº‘ä¸‹è½½å¤±è´¥"
            text = f"ğŸ“¦ ä»»åŠ¡: {task_name}\n\nä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥115ç½‘ç›˜ã€‚"
            
            self.post_message(
                mtype=None,
                title=title,
                text=text
            )
            logger.info(f"mhnotify: äº‘ä¸‹è½½å¤±è´¥é€šçŸ¥å·²å‘é€: {task_name}")
        except Exception as e:
            logger.error(f"mhnotify: å‘é€äº‘ä¸‹è½½å¤±è´¥é€šçŸ¥å¤±è´¥: {e}", exc_info=True)

    @eventmanager.register(EventType.PluginAction)
    def handle_cloud_download(self, event: Event):
        """è¿œç¨‹å‘½ä»¤è§¦å‘ï¼šæ·»åŠ 115äº‘ä¸‹è½½ä»»åŠ¡"""
        if not event:
            return
        event_data = event.event_data
        if not event_data or event_data.get("action") != "mh_add_offline":
            return

        # æ£€æŸ¥åŠŸèƒ½æ˜¯å¦å¯ç”¨
        if not self._cloud_download_enabled:
            self.post_message(
                channel=event_data.get("channel"),
                title="äº‘ä¸‹è½½åŠŸèƒ½æœªå¯ç”¨",
                text="è¯·å…ˆåœ¨æ’ä»¶é…ç½®ä¸­å¯ç”¨115äº‘ä¸‹è½½åŠŸèƒ½",
                userid=event_data.get("user")
            )
            return

        # æ£€æŸ¥115 Cookieæ˜¯å¦é…ç½®
        if not self._p115_cookie:
            self.post_message(
                channel=event_data.get("channel"),
                title="115 Cookieæœªé…ç½®",
                text="è¯·å…ˆåœ¨æ’ä»¶é…ç½®ä¸­å¡«å†™115 Cookie",
                userid=event_data.get("user")
            )
            return

        # è·å–ä¸‹è½½é“¾æ¥ï¼ˆæ”¯æŒå¤šä¸ªé“¾æ¥ï¼Œç”¨é€—å·ã€ç©ºæ ¼æˆ–æ¢è¡Œåˆ†éš”ï¼‰
        download_urls_raw = event_data.get("arg_str")
        if not download_urls_raw or not download_urls_raw.strip():
            self.post_message(
                channel=event_data.get("channel"),
                title="å‚æ•°é”™è¯¯",
                text="ç”¨æ³•: /mhol <ä¸‹è½½é“¾æ¥>\næ”¯æŒå¤šä¸ªé“¾æ¥ï¼Œç”¨é€—å·åˆ†éš”: /mhol url1,url2,url3",
                userid=event_data.get("user")
            )
            return

        # è§£æå¤šä¸ªURLï¼ˆæ”¯æŒé€—å·ã€ç©ºæ ¼ã€æ¢è¡Œåˆ†éš”ï¼‰
        import re
        download_urls = re.split(r'[,\s]+', download_urls_raw.strip())
        download_urls = [url.strip() for url in download_urls if url.strip()]
        
        if not download_urls:
            self.post_message(
                channel=event_data.get("channel"),
                title="å‚æ•°é”™è¯¯",
                text="æœªè§£æåˆ°æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥",
                userid=event_data.get("user")
            )
            return

        logger.info(f"mhnotify: æ”¶åˆ°äº‘ä¸‹è½½å‘½ä»¤ï¼Œå…± {len(download_urls)} ä¸ªé“¾æ¥")

        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰¹é‡ç›‘æ§
        is_batch = len(download_urls) > 1
        need_monitor = self._cloud_download_remove_small_files or self._cloud_download_organize

        # æ‰§è¡Œäº‘ä¸‹è½½
        success_count = 0
        fail_count = 0
        results = []
        batch_tasks = []  # ç”¨äºæ‰¹é‡ç›‘æ§çš„ä»»åŠ¡åˆ—è¡¨
        last_message = ""
        
        for idx, download_url in enumerate(download_urls, 1):
            logger.info(f"mhnotify: å¤„ç†ç¬¬ {idx}/{len(download_urls)} ä¸ªé“¾æ¥: {download_url[:80]}...")
            # æ‰¹é‡æ¨¡å¼ä¸‹ä¸å¯åŠ¨å•ç‹¬çš„ç›‘æ§çº¿ç¨‹ï¼Œç”±ç»Ÿä¸€çš„æ‰¹é‡ç›‘æ§å¤„ç†
            success, message, task_info = self._add_offline_download(download_url, start_monitor=(not is_batch))
            last_message = message
            if success:
                success_count += 1
                results.append(f"âœ… é“¾æ¥{idx}: æˆåŠŸ")
                # æ”¶é›†ä»»åŠ¡ä¿¡æ¯ç”¨äºæ‰¹é‡ç›‘æ§
                if is_batch and need_monitor and task_info.get("info_hash"):
                    batch_tasks.append(task_info)
            else:
                fail_count += 1
                results.append(f"âŒ é“¾æ¥{idx}: {message}")

        # å‘é€ç»“æœæ¶ˆæ¯
        if len(download_urls) == 1:
            # å•ä¸ªé“¾æ¥ï¼Œä¿æŒåŸæœ‰æ ¼å¼
            if success_count == 1:
                self.post_message(
                    channel=event_data.get("channel"),
                    title="äº‘ä¸‹è½½ä»»åŠ¡æ·»åŠ æˆåŠŸ",
                    text=last_message,
                    userid=event_data.get("user")
                )
            else:
                self.post_message(
                    channel=event_data.get("channel"),
                    title="äº‘ä¸‹è½½ä»»åŠ¡æ·»åŠ å¤±è´¥",
                    text=last_message,
                    userid=event_data.get("user")
                )
        else:
            # å¤šä¸ªé“¾æ¥ï¼Œæ±‡æ€»ç»“æœ
            summary = f"å…± {len(download_urls)} ä¸ªé“¾æ¥\næˆåŠŸ: {success_count} | å¤±è´¥: {fail_count}\n\n" + "\n".join(results)
            if need_monitor and batch_tasks:
                summary += f"\n\nâ³ å°†ç»Ÿä¸€ç›‘æ§ {len(batch_tasks)} ä¸ªä»»åŠ¡ï¼Œå®Œæˆåæ‰§è¡Œæ¸…ç†å’Œæ•´ç†"
            title = "äº‘ä¸‹è½½æ‰¹é‡ä»»åŠ¡å·²æäº¤" if fail_count == 0 else f"äº‘ä¸‹è½½æ‰¹é‡ä»»åŠ¡å·²æäº¤ï¼ˆ{fail_count}ä¸ªå¤±è´¥ï¼‰"
            self.post_message(
                channel=event_data.get("channel"),
                title=title,
                text=summary,
                userid=event_data.get("user")
            )
            
            # å¯åŠ¨æ‰¹é‡ç›‘æ§çº¿ç¨‹
            if need_monitor and batch_tasks:
                try:
                    import threading
                    logger.info(f"mhnotify: å¯åŠ¨æ‰¹é‡ç›‘æ§çº¿ç¨‹ï¼Œç›‘æ§ {len(batch_tasks)} ä¸ªä»»åŠ¡")
                    threading.Thread(
                        target=self._monitor_batch_downloads,
                        args=(batch_tasks,),
                        daemon=True
                    ).start()
                except Exception as e:
                    logger.warning(f"mhnotify: å¯åŠ¨æ‰¹é‡ç›‘æ§çº¿ç¨‹å¤±è´¥: {e}")

    def __finish_mp_subscribe(self, subscribe):
        try:
            # ç”Ÿæˆå…ƒæ•°æ®
            from app.core.metainfo import MetaInfo
            from app.schemas.types import MediaType
            from app.chain.subscribe import SubscribeChain
            from app.core.context import MediaInfo
            meta = MetaInfo(subscribe.name)
            meta.year = subscribe.year
            meta.begin_season = subscribe.season or None
            try:
                meta.type = MediaType(subscribe.type)
            except Exception:
                pass
            # æ„é€ æœ€å°å¯ç”¨çš„ mediainfoï¼ˆç”¨äºå®Œæˆè®¢é˜…æ—¥å¿—ä¸é€šçŸ¥ï¼‰
            mediainfo = MediaInfo()
            try:
                # ç±»å‹æ˜ å°„
                st = (subscribe.type or "").strip().lower()
                if st in {"ç”µå½±", "movie", "movies"}:
                    mediainfo.type = MediaType.MOVIE
                elif st in {"ç”µè§†å‰§", "tv", "series"}:
                    mediainfo.type = MediaType.TV
                else:
                    mediainfo.type = meta.type or MediaType.MOVIE
                mediainfo.title = subscribe.name
                mediainfo.year = subscribe.year
                mediainfo.tmdb_id = getattr(subscribe, 'tmdbid', None)
                mediainfo.poster_path = getattr(subscribe, 'poster', None)
                mediainfo.backdrop_path = getattr(subscribe, 'backdrop', None)
                mediainfo.overview = getattr(subscribe, 'description', None)
                mediainfo.vote_average = getattr(subscribe, 'vote', None)
            except Exception:
                pass
            # å®Œæˆè®¢é˜…
            SubscribeChain().finish_subscribe_or_not(
                subscribe=subscribe,
                meta=meta,
                mediainfo=mediainfo,
                downloads=None,
                lefts={},
                force=True
            )
        except Exception as e:
            logger.error(f"mhnotify: å®ŒæˆMPè®¢é˜…å¤±è´¥: {e}")

    # HDHive æ¨¡å—ç¼“å­˜
    _hdhive_module: Any = None
    _hdhive_module_checked: bool = False
    
    def __get_hdhive_extension_filename(self) -> Optional[str]:
        """
        æ ¹æ®å½“å‰å¹³å°è·å– hdhive æ‰©å±•æ¨¡å—çš„æ–‡ä»¶å
        
        :return: æ–‡ä»¶åï¼Œå¦‚æœå¹³å°ä¸æ”¯æŒåˆ™è¿”å› None
        """
        import platform
        machine = platform.machine().lower()
        system = platform.system().lower()
        
        # æ˜ å°„æ¶æ„åç§°
        arch_map = {
            "x86_64": "x86_64",
            "amd64": "x86_64",
            "aarch64": "aarch64",
            "arm64": "aarch64",
        }
        arch = arch_map.get(machine, machine)
        
        if system == "windows":
            return f"hdhive.cp312-win_{arch}.pyd"
        elif system == "darwin":
            return "hdhive.cpython-312-darwin.so"
        elif system == "linux":
            return f"hdhive.cpython-312-{arch}-linux-gnu.so"
        else:
            return None
    
    def __download_hdhive_module(self) -> bool:
        """
        æ£€æŸ¥å¹¶ä¸‹è½½ hdhive æ‰©å±•æ¨¡å—
        
        :return: æ˜¯å¦æˆåŠŸè·å–æ¨¡å—
        """
        import platform
        import os
        from pathlib import Path
        import urllib.request
        import urllib.error
        
        # è·å–æ’ä»¶ç›®å½•ä¸‹çš„ lib æ–‡ä»¶å¤¹
        plugin_dir = Path(__file__).parent
        lib_dir = plugin_dir / "lib"
        lib_dir.mkdir(parents=True, exist_ok=True)
        
        system = platform.system().lower()
        machine = platform.machine().lower()
        
        ext_filename = self.__get_hdhive_extension_filename()
        if not ext_filename:
            logger.warning(f"mhnotify: ä¸æ”¯æŒçš„å¹³å°: {system}/{machine}ï¼ŒHDHive æ¨¡å—åŠŸèƒ½æ— æ³•ä½¿ç”¨")
            return False
        
        target_path = lib_dir / ext_filename
        
        # æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨
        if target_path.exists():
            logger.debug(f"mhnotify: hdhive æ‰©å±•æ¨¡å—å·²å­˜åœ¨: {target_path}")
            return True
        
        # ä» GitHub ä¸‹è½½
        base_url = "https://raw.githubusercontent.com/mrtian2016/hdhive_resource/main"
        download_url = f"{base_url}/{ext_filename}"
        
        logger.info(f"mhnotify: æœ¬åœ°æœªæ‰¾åˆ° hdhive æ‰©å±•æ¨¡å—ï¼Œå°è¯•ä¸‹è½½: {download_url}")
        
        try:
            proxy = getattr(settings, "PROXY", None)
            if proxy:
                if isinstance(proxy, dict):
                    proxy_handler = urllib.request.ProxyHandler(proxy)
                else:
                    proxy_handler = urllib.request.ProxyHandler({"http": proxy, "https": proxy})
                opener = urllib.request.build_opener(proxy_handler)
                logger.debug(f"mhnotify: ä¸‹è½½ hdhive ä½¿ç”¨ä»£ç†: {proxy}")
                response = opener.open(download_url, timeout=120)
            else:
                response = urllib.request.urlopen(download_url, timeout=120)
            
            with response:
                content = response.read()
            
            with open(target_path, "wb") as f:
                f.write(content)
            
            # é Windows å¹³å°è®¾ç½®å¯æ‰§è¡Œæƒé™
            if system != "windows":
                os.chmod(target_path, 0o755)
            
            logger.info(f"mhnotify: âœ“ hdhive æ‰©å±•æ¨¡å—ä¸‹è½½æˆåŠŸ: {target_path}")
            return True
            
        except urllib.error.HTTPError as e:
            if e.code == 404:
                logger.warning(f"mhnotify: âš ï¸ hdhive æ‰©å±•æ¨¡å—æš‚ä¸æ”¯æŒå½“å‰å¹³å° ({system}/{machine})ï¼Œå°†ä½¿ç”¨ HTTP API æ¨¡å¼")
            else:
                logger.error(f"mhnotify: ä¸‹è½½ hdhive æ‰©å±•æ¨¡å—å¤±è´¥ (HTTP {e.code}): {e}")
            return False
        except urllib.error.URLError as e:
            logger.error(f"mhnotify: ä¸‹è½½ hdhive æ‰©å±•æ¨¡å—å¤±è´¥ï¼ˆç½‘ç»œé”™è¯¯ï¼‰: {e}")
            return False
        except Exception as e:
            logger.error(f"mhnotify: ä¸‹è½½ hdhive æ‰©å±•æ¨¡å—å¤±è´¥: {e}")
            return False
    
    def __load_hdhive_module(self) -> Optional[Any]:
        """
        åŠ è½½ hdhive æ¨¡å—ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°ä¸‹è½½çš„æ¨¡å—
        
        :return: hdhive æ¨¡å—å¯¹è±¡ï¼Œå¤±è´¥è¿”å› None
        """
        if self._hdhive_module_checked:
            return self._hdhive_module
        
        self._hdhive_module_checked = True
        
        # å°è¯•ä¸‹è½½æ¨¡å—
        if not self.__download_hdhive_module():
            return None
        
        # åŠ¨æ€åŠ è½½æ¨¡å—
        import sys
        import importlib.util
        from pathlib import Path
        
        plugin_dir = Path(__file__).parent
        lib_dir = plugin_dir / "lib"
        
        ext_filename = self.__get_hdhive_extension_filename()
        if not ext_filename:
            return None
        
        module_path = lib_dir / ext_filename
        if not module_path.exists():
            return None
        
        try:
            # å°† lib ç›®å½•æ·»åŠ åˆ° sys.path
            lib_dir_str = str(lib_dir)
            if lib_dir_str not in sys.path:
                sys.path.insert(0, lib_dir_str)
            
            # åŠ è½½æ¨¡å—
            spec = importlib.util.spec_from_file_location("hdhive", str(module_path))
            if spec and spec.loader:
                module = importlib.util.module_from_spec(spec)
                sys.modules["hdhive"] = module
                spec.loader.exec_module(module)
                self._hdhive_module = module
                logger.info(f"mhnotify: âœ“ hdhive æ¨¡å—åŠ è½½æˆåŠŸ")
                return module
            else:
                logger.error("mhnotify: æ— æ³•åˆ›å»º hdhive æ¨¡å— spec")
                return None
        except Exception as e:
            logger.error(f"mhnotify: åŠ è½½ hdhive æ¨¡å—å¤±è´¥: {type(e).__name__}: {e}")
            return None
    
    def __fetch_hdhive_links(self, tmdb_id: Optional[int], media_type: Optional[str]) -> List[str]:
        """
        æ ¹æ®é…ç½®ä» HDHive æŸ¥è¯¢å…è´¹115åˆ†äº«é“¾æ¥ï¼Œè¿”å› URL åˆ—è¡¨
        ä¼˜å…ˆä½¿ç”¨ hdhive æ¨¡å—ï¼ˆLinux/macOSï¼‰ï¼Œä¸å¯ç”¨æ—¶å›é€€åˆ° HTTP API æ¨¡å¼
        """
        results: List[str] = []
        try:
            logger.debug(f"mhnotify: HDHive æŸ¥è¯¢å¼€å§‹ tmdb_id={tmdb_id} media_type={media_type} enabled={self._hdhive_enabled}")
            if not self._hdhive_enabled:
                logger.debug("mhnotify: HDHive æœªå¯ç”¨ï¼Œè·³è¿‡æŸ¥è¯¢")
                return results
            if not tmdb_id:
                logger.warning("mhnotify: ç¼ºå°‘ TMDB IDï¼Œæ— æ³•ä½¿ç”¨ HDHive æŸ¥è¯¢")
                return results
            
            # å°è¯•åŠ è½½ hdhive æ¨¡å—
            hdhive_mod = self.__load_hdhive_module()
            
            if hdhive_mod:
                # ä½¿ç”¨ hdhive æ¨¡å—æŸ¥è¯¢
                return self.__fetch_hdhive_links_with_module(tmdb_id, media_type, hdhive_mod)
            else:
                # å›é€€åˆ° HTTP API æ¨¡å¼
                logger.debug("mhnotify: hdhive æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ HTTP API æ¨¡å¼")
                return self.__fetch_hdhive_links_with_http(tmdb_id, media_type)
                
        except Exception as e:
            logger.error(f"mhnotify: __fetch_hdhive_links å¼‚å¸¸: {type(e).__name__}: {e}", exc_info=True)
            return []
    
    def __fetch_hdhive_links_with_module(self, tmdb_id: int, media_type: str, hdhive_mod: Any) -> List[str]:
        """
        ä½¿ç”¨ hdhive æ¨¡å—æŸ¥è¯¢ HDHive èµ„æº
        """
        results: List[str] = []
        try:
            h_type_str = "movie" if (media_type or "movie").lower() == "movie" else "tv"
            
            # è·å– MediaType æšä¸¾
            MediaType = getattr(hdhive_mod, 'MediaType', None)
            if MediaType is None:
                logger.error("mhnotify: hdhive æ¨¡å—ç¼ºå°‘ MediaType ç±»")
                return self.__fetch_hdhive_links_with_http(tmdb_id, media_type)
            
            h_type = MediaType.MOVIE if h_type_str == "movie" else MediaType.TV
            
            cookie = self._hdhive_cookie or ""
            
            # Cookie æœ‰æ•ˆæ€§æ£€æŸ¥å’Œåˆ·æ–°
            if self._hdhive_auto_refresh and self._hdhive_username and self._hdhive_password:
                is_valid, reason = self.__check_hdhive_cookie_valid(cookie, self._hdhive_refresh_before)
                if not cookie or not is_valid:
                    logger.info(f"HDHive: Cookie éœ€è¦åˆ·æ–° - {reason}")
                    new_cookie = self.__refresh_hdhive_cookie(self._hdhive_username, self._hdhive_password)
                    if new_cookie:
                        cookie = new_cookie
                        self._hdhive_cookie = new_cookie
                        cfg = self.get_config()
                        if isinstance(cfg, dict):
                            cfg["hdhive_cookie"] = new_cookie
                            self.update_config(cfg)
                        logger.info("HDHive: Cookie åˆ·æ–°æˆåŠŸ")
            
            if not cookie:
                if self._hdhive_username and self._hdhive_password:
                    new_cookie = self.__refresh_hdhive_cookie(self._hdhive_username, self._hdhive_password)
                    if new_cookie:
                        cookie = new_cookie
                        self._hdhive_cookie = new_cookie
                        cfg = self.get_config()
                        if isinstance(cfg, dict):
                            cfg["hdhive_cookie"] = new_cookie
                            self.update_config(cfg)
                    else:
                        logger.warning("HDHive: æ— æ³•è·å–æœ‰æ•ˆ Cookie")
                        return results
                else:
                    logger.warning("HDHive: éœ€è¦é…ç½® Cookie æˆ–ç”¨æˆ·åå¯†ç ")
                    return results
            
            proxy = getattr(settings, "PROXY", None)
            create_client = getattr(hdhive_mod, 'create_client', None)
            
            if create_client is None:
                logger.error("mhnotify: hdhive æ¨¡å—ç¼ºå°‘ create_client å‡½æ•°")
                return self.__fetch_hdhive_links_with_http(tmdb_id, media_type)
            
            logger.debug(f"mhnotify: ä½¿ç”¨ hdhive æ¨¡å—æŸ¥è¯¢ tmdb_id={tmdb_id}")
            
            with create_client(cookie=cookie, proxy=proxy) as client:
                media = client.get_media_by_tmdb_id(tmdb_id, h_type)
                if not media:
                    logger.info(f"mhnotify: HDHive æœªæ‰¾åˆ°åª’ä½“ tmdb_id={tmdb_id}")
                    return results
                
                logger.debug(f"mhnotify: HDHive æ‰¾åˆ°åª’ä½“ slug={getattr(media, 'slug', None)}")
                
                res = client.get_resources(media.slug, h_type, media_id=media.id)
                if not res or not res.success:
                    logger.info(f"mhnotify: HDHive è·å–èµ„æºå¤±è´¥")
                    return results
                
                logger.debug(f"mhnotify: HDHive è·å–åˆ°èµ„æºæ•°é‡={len(res.resources) if hasattr(res, 'resources') else 0}")
                
                for item in res.resources:
                    website_val = getattr(item.website, 'value', '') if hasattr(item, 'website') else ''
                    is_free = getattr(item, 'is_free', False)
                    
                    if website_val == '115' and is_free:
                        share = client.get_share_url(item.slug)
                        if share and share.url:
                            logger.info(f"mhnotify: HDHive è·å–åˆ°å…è´¹åˆ†äº«é“¾æ¥: {share.url}")
                            results.append(share.url)
            
            return results
            
        except Exception as e:
            logger.error(f"mhnotify: hdhive æ¨¡å—æŸ¥è¯¢å¤±è´¥: {type(e).__name__}: {e}", exc_info=True)
            # å›é€€åˆ° HTTP API
            return self.__fetch_hdhive_links_with_http(tmdb_id, media_type)
    
    def __fetch_hdhive_links_with_http(self, tmdb_id: int, media_type: str) -> List[str]:
        """
        ä½¿ç”¨ HTTP API ç›´æ¥æŸ¥è¯¢ HDHive èµ„æºï¼ˆæ— éœ€ hdhive æ¨¡å—ï¼‰
        """
        results: List[str] = []
        try:
            import requests
            
            base_url = "https://hdhive.com"
            h_type = "movie" if (media_type or "movie").lower() == "movie" else "tv"
            logger.debug(f"mhnotify: HDHive HTTP API æŸ¥è¯¢ tmdb_id={tmdb_id} h_type={h_type}")

            # API æ¨¡å¼éœ€è¦ Cookie
            query_mode = (self._hdhive_query_mode or "api").lower()
            logger.debug(f"mhnotify: HDHive æŸ¥è¯¢æ¨¡å¼: {query_mode}")
            
            cookie = self._hdhive_cookie or ""
            
            # è‡ªåŠ¨åˆ·æ–° Cookieï¼ˆè‹¥å¼€å¯ä¸” Cookie æ— æ•ˆï¼‰
            if self._hdhive_auto_refresh and self._hdhive_username and self._hdhive_password:
                is_valid, reason = self.__check_hdhive_cookie_valid(cookie, self._hdhive_refresh_before)
                logger.debug(f"mhnotify: Cookie æœ‰æ•ˆæ€§æ£€æŸ¥: valid={is_valid}, reason={reason}")
                if not cookie or not is_valid:
                    logger.info(f"HDHive: Cookie éœ€è¦åˆ·æ–° - {reason}")
                    new_cookie = self.__refresh_hdhive_cookie(self._hdhive_username, self._hdhive_password)
                    if new_cookie:
                        cookie = new_cookie
                        self._hdhive_cookie = new_cookie
                        cfg = self.get_config()
                        if isinstance(cfg, dict):
                            cfg["hdhive_cookie"] = new_cookie
                            self.update_config(cfg)
                        logger.info("HDHive: Cookie åˆ·æ–°æˆåŠŸå¹¶å·²ä¿å­˜åˆ°é…ç½®")
                    else:
                        logger.warning("mhnotify: Cookie åˆ·æ–°å¤±è´¥")
            
            if not cookie:
                # å°è¯• Playwright æ¨¡å¼ç™»å½•è·å– Cookie
                if query_mode == "playwright" and self._hdhive_username and self._hdhive_password:
                    logger.info("mhnotify: HDHive æ— æœ‰æ•ˆ Cookieï¼Œå°è¯• Playwright ç™»å½•...")
                    new_cookie = self.__refresh_hdhive_cookie(self._hdhive_username, self._hdhive_password)
                    if new_cookie:
                        cookie = new_cookie
                        self._hdhive_cookie = new_cookie
                        cfg = self.get_config()
                        if isinstance(cfg, dict):
                            cfg["hdhive_cookie"] = new_cookie
                            self.update_config(cfg)
                        logger.info("HDHive: Playwright ç™»å½•æˆåŠŸï¼ŒCookie å·²ä¿å­˜")
                    else:
                        logger.warning("HDHive: Playwright ç™»å½•å¤±è´¥")
                        return results
                else:
                    logger.warning("HDHive: éœ€è¦æœ‰æ•ˆçš„ Cookie æˆ–é…ç½®ç”¨æˆ·åå¯†ç ä½¿ç”¨ Playwright æ¨¡å¼")
                    return results
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Referer": base_url,
                "Cookie": cookie,
            }
            
            # ä» Cookie ä¸­æå– csrf_access_tokenï¼ˆç”¨äº API è¯·æ±‚ï¼‰
            csrf_token = ""
            for part in cookie.split(';'):
                part = part.strip()
                if part.startswith('csrf_access_token='):
                    csrf_token = part.split('=', 1)[1]
                    break
            if csrf_token:
                headers["X-CSRF-TOKEN"] = csrf_token
            
            proxy = getattr(settings, "PROXY", None)
            proxies = None
            if proxy:
                if isinstance(proxy, dict):
                    proxies = proxy
                else:
                    proxies = {"http": proxy, "https": proxy}
            
            session = requests.Session()
            session.headers.update(headers)
            if proxies:
                session.proxies.update(proxies)
            
            try:
                # 1. é€šè¿‡ TMDB ID æŸ¥è¯¢åª’ä½“ä¿¡æ¯
                search_url = f"{base_url}/api/media/tmdb/{tmdb_id}?type={h_type}"
                logger.debug(f"mhnotify: HDHive æŸ¥è¯¢åª’ä½“ GET {search_url}")
                
                resp = session.get(search_url, timeout=30)
                if resp.status_code != 200:
                    logger.info(f"mhnotify: HDHive æŸ¥è¯¢åª’ä½“å¤±è´¥ï¼ŒçŠ¶æ€ç ={resp.status_code}")
                    return results
                
                media_data = resp.json()
                if not media_data:
                    logger.info(f"mhnotify: HDHive æœªæ‰¾åˆ°åª’ä½“ tmdb_id={tmdb_id}")
                    return results
                
                media_slug = media_data.get("slug")
                media_id = media_data.get("id")
                logger.debug(f"mhnotify: HDHive æ‰¾åˆ°åª’ä½“ slug={media_slug} id={media_id}")
                
                if not media_slug:
                    logger.info(f"mhnotify: HDHive åª’ä½“æ•°æ®æ—  slug")
                    return results
                
                # 2. è·å–èµ„æºåˆ—è¡¨
                resources_url = f"{base_url}/api/resource/{h_type}/{media_slug}"
                if media_id:
                    resources_url += f"?media_id={media_id}"
                logger.debug(f"mhnotify: HDHive è·å–èµ„æº GET {resources_url}")
                
                resp = session.get(resources_url, timeout=30)
                if resp.status_code != 200:
                    logger.info(f"mhnotify: HDHive è·å–èµ„æºå¤±è´¥ï¼ŒçŠ¶æ€ç ={resp.status_code}")
                    return results
                
                resources_data = resp.json()
                if not resources_data or not resources_data.get("success"):
                    logger.info(f"mhnotify: HDHive è·å–èµ„æºè¿”å› success=False")
                    return results
                
                resources = resources_data.get("resources", [])
                logger.debug(f"mhnotify: HDHive è·å–åˆ°èµ„æºæ•°é‡={len(resources)}")
                
                # 3. ç­›é€‰å…è´¹çš„ 115 èµ„æºå¹¶è·å–åˆ†äº«é“¾æ¥
                for item in resources:
                    website = item.get("website", "")
                    is_free = item.get("is_free", False)
                    res_slug = item.get("slug", "")
                    logger.debug(f"mhnotify: HDHive èµ„æºé¡¹ slug={res_slug} website={website} is_free={is_free}")
                    
                    if website == "115" and is_free and res_slug:
                        # è·å–åˆ†äº«é“¾æ¥
                        share_url_api = f"{base_url}/api/resource/{res_slug}/share"
                        logger.debug(f"mhnotify: HDHive è·å–åˆ†äº«é“¾æ¥ GET {share_url_api}")
                        
                        try:
                            share_resp = session.get(share_url_api, timeout=30)
                            if share_resp.status_code == 200:
                                share_data = share_resp.json()
                                share_link = share_data.get("url") or share_data.get("share_url")
                                if share_link:
                                    logger.info(f"mhnotify: HDHive è·å–åˆ°å…è´¹åˆ†äº«é“¾æ¥: {share_link}")
                                    results.append(share_link)
                                else:
                                    logger.debug(f"mhnotify: HDHive åˆ†äº«é“¾æ¥å“åº”æ—  url å­—æ®µ: {share_data}")
                            else:
                                logger.debug(f"mhnotify: HDHive è·å–åˆ†äº«é“¾æ¥å¤±è´¥ status={share_resp.status_code}")
                        except Exception as e:
                            logger.debug(f"mhnotify: HDHive è·å–åˆ†äº«é“¾æ¥å¼‚å¸¸: {e}")
                
                logger.debug(f"mhnotify: HDHive æŸ¥è¯¢ç»“æŸï¼Œç»“æœæ•°é‡={len(results)}")
                return results
                
            except requests.exceptions.RequestException as e:
                logger.error(f"HDHive API è¯·æ±‚å¤±è´¥: {type(e).__name__}: {e}")
                return results
                
        except Exception as e:
            logger.error(f"mhnotify: __fetch_hdhive_links å¼‚å¸¸: {type(e).__name__}: {e}", exc_info=True)
            return []
    
    def __check_hdhive_cookie_valid(self, cookie: str, refresh_before: int = 3600) -> Tuple[bool, str]:
        """
        æ£€æŸ¥ HDHive Cookie æ˜¯å¦æœ‰æ•ˆ
        
        :param cookie: Cookie å­—ç¬¦ä¸²
        :param refresh_before: åœ¨è¿‡æœŸå‰å¤šå°‘ç§’è§†ä¸ºéœ€è¦åˆ·æ–°
        :return: (æ˜¯å¦æœ‰æ•ˆ, åŸå› è¯´æ˜)
        """
        import base64
        import json
        
        if not cookie:
            return False, "Cookie ä¸ºç©º"
        
        # ä» Cookie ä¸­æå– token
        token = None
        for part in cookie.split(';'):
            part = part.strip()
            if part.startswith('token='):
                token = part.split('=', 1)[1]
                break
        
        if not token:
            return False, "Cookie ä¸­æ—  token"
        
        try:
            # JWT æ ¼å¼: header.payload.signature
            parts = token.split('.')
            if len(parts) != 3:
                return False, "token æ ¼å¼é”™è¯¯"
            
            # è§£ç  payloadï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰
            payload = parts[1]
            # è¡¥é½ base64 padding
            padding = 4 - len(payload) % 4
            if padding != 4:
                payload += '=' * padding
            
            decoded = base64.urlsafe_b64decode(payload)
            payload_data = json.loads(decoded)
            
            exp = payload_data.get('exp')
            if not exp:
                return False, "token æ— è¿‡æœŸæ—¶é—´"
            
            import time
            now = time.time()
            time_left = exp - now
            
            if time_left <= 0:
                return False, "Cookie å·²è¿‡æœŸ"
            
            if time_left < refresh_before:
                hours_left = time_left / 3600
                return False, f"Cookie å°†åœ¨ {hours_left:.1f} å°æ—¶åè¿‡æœŸ"
            
            return True, f"Cookie æœ‰æ•ˆï¼Œè¿˜æœ‰ {time_left / 3600:.1f} å°æ—¶"
            
        except Exception as e:
            logger.debug(f"mhnotify: è§£æ HDHive Cookie å¤±è´¥: {e}")
            return False, f"è§£æå¤±è´¥: {e}"
    
    def __refresh_hdhive_cookie(self, username: str, password: str) -> Optional[str]:
        """
        ä½¿ç”¨ Playwright ç™»å½• HDHive è·å–æ–° Cookie
        
        :param username: HDHive ç”¨æˆ·å
        :param password: HDHive å¯†ç 
        :return: æ–°çš„ Cookie å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            from playwright.sync_api import sync_playwright
        except ImportError:
            logger.error("Playwright æœªå®‰è£…ï¼Œæ— æ³•è‡ªåŠ¨åˆ·æ–° HDHive Cookie")
            logger.info("è¯·è¿è¡Œ: pip install playwright && playwright install chromium")
            return None
        
        try:
            base_url = "https://hdhive.com"
            login_url = f"{base_url}/login"
            proxy = getattr(settings, "PROXY", None)
            
            with sync_playwright() as pw:
                launch_options = {"headless": True}
                context_options = {}
                
                if proxy:
                    if isinstance(proxy, dict):
                        proxy_url = proxy.get("http") or proxy.get("https")
                    else:
                        proxy_url = proxy
                    if proxy_url:
                        context_options["proxy"] = {"server": proxy_url}
                        logger.debug(f"HDHive Cookie åˆ·æ–°ä½¿ç”¨ä»£ç†: {proxy_url}")
                
                browser = pw.chromium.launch(**launch_options)
                context = browser.new_context(**context_options)
                page = context.new_page()
                
                logger.info("HDHive: è®¿é—®ç™»å½•é¡µ...")
                page.goto(login_url, wait_until="domcontentloaded", timeout=30000)
                page.wait_for_timeout(2000)
                
                # å¡«å†™ç”¨æˆ·å
                username_selectors = ['#username', 'input[name="username"]', 'input[name="email"]', 'input[type="email"]']
                username_filled = False
                for sel in username_selectors:
                    try:
                        if page.query_selector(sel):
                            page.fill(sel, username)
                            logger.debug("HDHive: âœ“ å¡«å†™ç”¨æˆ·å")
                            username_filled = True
                            break
                    except Exception:
                        continue
                
                if not username_filled:
                    logger.error("HDHive: æœªæ‰¾åˆ°ç”¨æˆ·åè¾“å…¥æ¡†")
                    context.close()
                    browser.close()
                    return None
                
                # å¡«å†™å¯†ç 
                password_selectors = ['#password', 'input[name="password"]', 'input[type="password"]']
                password_filled = False
                for sel in password_selectors:
                    try:
                        if page.query_selector(sel):
                            page.fill(sel, password)
                            logger.debug("HDHive: âœ“ å¡«å†™å¯†ç ")
                            password_filled = True
                            break
                    except Exception:
                        continue
                
                if not password_filled:
                    logger.error("HDHive: æœªæ‰¾åˆ°å¯†ç è¾“å…¥æ¡†")
                    context.close()
                    browser.close()
                    return None
                
                # æäº¤ç™»å½•
                page.wait_for_timeout(500)
                try:
                    btn = page.query_selector('button[type="submit"]')
                    if btn:
                        btn.click()
                        logger.debug("HDHive: âœ“ ç‚¹å‡»ç™»å½•æŒ‰é’®")
                    else:
                        page.keyboard.press("Enter")
                        logger.debug("HDHive: âœ“ æŒ‰ Enter é”®æäº¤")
                except Exception:
                    page.keyboard.press("Enter")
                
                # ç­‰å¾…ç™»å½•å®Œæˆ
                try:
                    page.wait_for_load_state("domcontentloaded", timeout=15000)
                except Exception:
                    pass
                
                page.wait_for_timeout(3000)
                
                # æ£€æŸ¥ç™»å½•ç»“æœ
                current_url = page.url
                logger.debug(f"HDHive: ç™»å½•å URL: {current_url}")
                
                if "/login" in current_url:
                    logger.warning("HDHive: ç™»å½•å¯èƒ½å¤±è´¥ï¼Œä»åœ¨ç™»å½•é¡µé¢")
                
                # è·å– Cookie
                cookies = context.cookies()
                cookie_parts = []
                for c in cookies:
                    if c.get("domain", "").endswith("hdhive.com"):
                        cookie_parts.append(f"{c['name']}={c['value']}")
                
                context.close()
                browser.close()
                
                if cookie_parts:
                    cookie_str = "; ".join(cookie_parts)
                    logger.info(f"HDHive: è·å– Cookie æˆåŠŸï¼Œé•¿åº¦={len(cookie_str)}")
                    return cookie_str
                else:
                    logger.warning("HDHive: æœªè·å–åˆ°æœ‰æ•ˆ Cookie")
                    return None
                    
        except Exception as e:
            logger.error(f"HDHive Playwright ç™»å½•å¤±è´¥: {type(e).__name__}: {e}", exc_info=True)
            return None
